{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeiRi-zc0NuZ"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/04b_TVM_Tutorial_VTA_ResNet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following block to ensure TVM is setup for this notebook, each notebook may have its own runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    ! gsutil cp \"gs://tvm-fcrc-binaries-7f775516ff9dfab922c304049f294cec/tvm.tar.gz\" /tmp/tvm.tar.gz\n",
    "    ! mkdir -p /tvm\n",
    "    ! tar -xf /tmp/tvm.tar.gz --strip-components=4 --directory /tvm\n",
    "    ! ls -la /tvm\n",
    "    ! pip install mxnet\n",
    "    ! bash /tvm/package.sh\n",
    "    # Add TVM to the Python path.\n",
    "    import sys\n",
    "    sys.path.append('/tvm/python')\n",
    "    sys.path.append('/tvm/topi/python')\n",
    "    sys.path.append('/tvm/nnvm/python')\n",
    "    sys.path.append('/tvm/vta/python')\n",
    "else:\n",
    "    print(\"Notebook executing locally, skipping Colab setup ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Deploy Pretrained ResNet Model from MxNet on VTA\n",
    "================================================\n",
    "**Author**: `Thierry Moreau <https://homes.cs.washington.edu/~moreau/>`_\n",
    "\n",
    "This tutorial provides an end-to-end demo, on how to run ResNet-18 inference\n",
    "onto the VTA accelerator design to perform ImageNet classification tasks.\n",
    "It showcases Relay as a front end compiler that can perform quantization (VTA\n",
    "only supports int8/32 inference) as well as graph packing (in order to enable\n",
    "tensorization in the core) to massage the compute graph for the hardware target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import argparse, json, os, requests, time\n",
    "from io import BytesIO\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tvm\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, util, download\n",
    "from tvm.contrib.debugger import debug_runtime\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.module.enabled(\"rpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the platform and model targets\n",
    "-------------------------------------\n",
    "Execute on CPU vs. VTA, and define the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VTA parameters from the vta/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "\n",
    "# Set device=arm_cpu to run inference on the CPU\n",
    "# or device=vta to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "# The start_pack and stop_pack labels indicate where\n",
    "# to start and end the graph packing relay pass: in other words\n",
    "# where to start and finish offloading to VTA.\n",
    "model = \"resnet18_v1\"\n",
    "start_pack=\"nn.max_pool2d\"\n",
    "stop_pack=\"nn.global_avg_pool2d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain an execution remote\n",
    "---------------------------------\n",
    "When target is `pynq`, reconfigure FPGA and runtime.\n",
    "Otherwise, if target is `sim`, execute locally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env.TARGET != \"sim\":\n",
    "\n",
    "    # Get remote from tracker node if environment variable is set.\n",
    "    # To set up the tracker, you'll need to follow the \"Auto-tuning\n",
    "    # a convolutional network for VTA\" tutorial.\n",
    "    tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", None)\n",
    "    tracker_port = int(os.environ.get(\"TVM_TRACKER_PORT\", None))\n",
    "    # Otherwise if you have a device you want to program directly from\n",
    "    # the host, make sure you've set the variables below to the IP of\n",
    "    # your board.\n",
    "    device_host = os.environ.get(\"VTA_PYNQ_RPC_HOST\", \"192.168.2.99\")\n",
    "    device_port = int(os.environ.get(\"VTA_PYNQ_RPC_PORT\", \"9091\"))\n",
    "    if not tracker_host or not tracker_port:\n",
    "        remote = rpc.connect(device_host, device_port)\n",
    "    else:\n",
    "        remote = autotvm.measure.request_remote(env.TARGET, tracker_host, tracker_port, timeout=10000)\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    reconfig_start = time.time()\n",
    "    vta.reconfig_runtime(remote)\n",
    "    vta.program_fpga(remote, bitstream=None)\n",
    "    reconfig_time = time.time() - reconfig_start\n",
    "    print(\"Reconfigured FPGA and RPC runtime in {0:.2f}s!\".format(reconfig_time))\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the inference graph runtime\n",
    "---------------------------------\n",
    "Grab ResNet-18 model from Gluon model zoo and compile with Relay.\n",
    "The compilation steps are:\n",
    "   1. Front end translation from MxNet into Relay module.\n",
    "   2. Apply 8-bit quantization: here we skip the first conv layer,\n",
    "      and dense layer which will both be executed in fp32 on the CPU.\n",
    "   3. Perform graph packing to alter the data layout for tensorization.\n",
    "   4. Perform constant folding to reduce number of operators (e.g. eliminate\n",
    "      batch norm multiply).\n",
    "   5. Perform relay build to object file.\n",
    "   6. Load the object file onto remote (FPGA device).\n",
    "   7. Generate graph runtime, `m`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-configured AutoTVM schedules\n",
    "with autotvm.tophub.context(target):\n",
    "\n",
    "    # Populate the shape and data type dictionary for ResNet input\n",
    "    dtype_dict = {\"data\": 'float32'}\n",
    "    shape_dict = {\"data\": (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "    # Get off the shelf gluon model, and convert to relay\n",
    "    gluon_model = vision.get_model(model, pretrained=True)\n",
    "\n",
    "    # Measure build start time\n",
    "    build_start = time.time()\n",
    "\n",
    "    # Start front end compilation\n",
    "    mod, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "\n",
    "    # Update shape and type dictionary\n",
    "    shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "    dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
    "\n",
    "    # Perform quantization in Relay\n",
    "    with relay.quantize.qconfig(global_scale=8.0,\n",
    "                                skip_k_conv=1,\n",
    "                                skip_k_dense=1,\n",
    "                                target_vta=True):\n",
    "        relay_prog = relay.quantize.quantize(mod[mod.entry_func], params=params)\n",
    "\n",
    "    # Perform graph packing and constant folding for VTA target\n",
    "    if target.device_name == \"vta\":\n",
    "        assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "        relay_prog = graph_pack(\n",
    "            relay_prog,\n",
    "            env.BATCH,\n",
    "            env.BLOCK_OUT,\n",
    "            env.WGT_WIDTH,\n",
    "            start_name=start_pack,\n",
    "            stop_name=stop_pack)\n",
    "        relay_prog = relay.ir_pass.fold_constant(relay_prog)\n",
    "\n",
    "    # Compile Relay program with AlterOpLayout disabled\n",
    "    with relay.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "        if target.device_name != \"vta\":\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target,\n",
    "                params=params, target_host=env.target_host)\n",
    "        else:\n",
    "            with vta.build_config():\n",
    "                graph, lib, params = relay.build(\n",
    "                    relay_prog, target=target,\n",
    "                    params=params, target_host=env.target_host)\n",
    "\n",
    "    # Measure Relay build time\n",
    "    build_time = time.time() - build_start\n",
    "    print(model + \" inference graph built in {0:.2f}s!\".format(build_time))\n",
    "\n",
    "    # Send the inference library over to the remote RPC server\n",
    "    temp = util.tempdir()\n",
    "    lib.save(temp.relpath(\"graphlib.o\"))\n",
    "    remote.upload(temp.relpath(\"graphlib.o\"))\n",
    "    lib = remote.load_module(\"graphlib.o\")\n",
    "\n",
    "    # Graph runtime\n",
    "    m = graph_runtime.create(graph, lib, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform ResNet-18 inference\n",
    "---------------------------\n",
    "We run classification on an image sample from ImageNet\n",
    "We just need to download the categories files, `synset.txt`\n",
    "and an input test image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ImageNet categories\n",
    "categ_url = \"https://github.com/uwsaml/web-data/raw/master/vta/models/\"\n",
    "categ_fn = \"synset.txt\"\n",
    "download.download(join(categ_url, categ_fn), categ_fn)\n",
    "synset = eval(open(categ_fn).read())\n",
    "\n",
    "# Download test image\n",
    "image_url = 'https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg'\n",
    "response = requests.get(image_url)\n",
    "\n",
    "# Prepare test image for inference\n",
    "image = Image.open(BytesIO(response.content)).resize((224, 224))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = np.array(image) - np.array([123., 117., 104.])\n",
    "image /= np.array([58.395, 57.12, 57.375])\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image[np.newaxis, :]\n",
    "image = np.repeat(image, env.BATCH, axis=0)\n",
    "\n",
    "# Set the network parameters and inputs\n",
    "m.set_input(**params)\n",
    "m.set_input('data', image)\n",
    "\n",
    "# Perform inference: we run the module 4 times,\n",
    "# and repeat 3 times to get error bounds\n",
    "timer = m.module.time_evaluator(\"run\", ctx, number=4, repeat=3)\n",
    "tcost = timer()\n",
    "\n",
    "# Get classification results\n",
    "tvm_output = m.get_output(0, tvm.nd.empty((env.BATCH, 1000), \"float32\", remote.cpu(0)))\n",
    "top_categories = np.argsort(tvm_output.asnumpy()[0])\n",
    "\n",
    "# Report top-5 classification results\n",
    "std = np.std(tcost.results) * 1000 / env.BATCH\n",
    "mean = tcost.mean * 1000 / env.BATCH\n",
    "print(\"%s prediction\" % model)\n",
    "print(\"                     #1:\", synset[top_categories[-1]])\n",
    "print(\"                     #2:\", synset[top_categories[-2]])\n",
    "print(\"                     #3:\", synset[top_categories[-3]])\n",
    "print(\"                     #4:\", synset[top_categories[-4]])\n",
    "print(\"                     #5:\", synset[top_categories[-5]])\n",
    "print(\"Performed inference in %.2fms/sample (std = %.2f)\" % (mean, std))\n",
    "\n",
    "# This just checks that one of the 5 top categories\n",
    "# is one variety of cat; this is by no means an accurate\n",
    "# assessment of how quantization affects classification\n",
    "# accuracy but is meant to catch changes to the\n",
    "# quantization pass that would accuracy in the CI.\n",
    "cat_detected = False\n",
    "for k in top_categories[-5:]:\n",
    "    if \"cat\" in synset[k]:\n",
    "        cat_detected = True\n",
    "assert(cat_detected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
