{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeiRi-zc0NuZ"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/04b_TVM_Tutorial_VTA_ResNet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following block to ensure TVM is setup for this notebook, each notebook may have its own runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook executing locally, skipping Colab setup ...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    ! gsutil cp \"gs://tvm-fcrc-binaries-7f775516ff9dfab922c304049f294cec/tvm.tar.gz\" /tmp/tvm.tar.gz\n",
    "    ! mkdir -p /tvm\n",
    "    ! tar -xf /tmp/tvm.tar.gz --strip-components=4 --directory /tvm\n",
    "    ! ls -la /tvm\n",
    "    ! pip install mxnet\n",
    "    ! bash /tvm/package.sh\n",
    "    # Add TVM to the Python path.\n",
    "    import sys\n",
    "    sys.path.append('/tvm/python')\n",
    "    sys.path.append('/tvm/topi/python')\n",
    "    sys.path.append('/tvm/nnvm/python')\n",
    "    sys.path.append('/tvm/vta/python')\n",
    "else:\n",
    "    print(\"Notebook executing locally, skipping Colab setup ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Deploy Pretrained ResNet Model from MxNet on VTA\n",
    "================================================\n",
    "**Author**: [Thierry Moreau](https://homes.cs.washington.edu/~moreau/)\n",
    "\n",
    "This tutorial provides an end-to-end demo, on how to run ResNet-18 inference\n",
    "onto the VTA accelerator design to perform ImageNet classification tasks.\n",
    "It showcases Relay as a front end compiler that can perform quantization (VTA only supports int8/32 inference) as well as graph packing (in order to enable tensorization in the core) to massage the compute graph for the hardware target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import argparse, json, os, requests, time\n",
    "from io import BytesIO\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tvm\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, util, download\n",
    "from tvm.contrib.debugger import debug_runtime\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.module.enabled(\"rpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the platform and model targets\n",
    "-------------------------------------\n",
    "Execute on CPU vs. VTA, and define the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim\n"
     ]
    }
   ],
   "source": [
    "# Load VTA parameters from the vta/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "print(env.TARGET)\n",
    "\n",
    "# Set device=arm_cpu to run inference on the CPU\n",
    "# or device=vta to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "model = \"resnet18_v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain an execution remote\n",
    "---------------------------------\n",
    "When target is `pynq`, reconfigure FPGA and runtime.\n",
    "Otherwise, if target is `sim`, execute locally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env.TARGET != \"sim\":\n",
    "    \n",
    "    # Get remote to board\n",
    "    device_host = os.environ.get(\"VTA_PYNQ_RPC_HOST\", \"192.168.2.99\")\n",
    "    device_port = int(os.environ.get(\"VTA_PYNQ_RPC_PORT\", \"9091\"))\n",
    "    remote = rpc.connect(device_host, device_port)\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    vta.reconfig_runtime(remote)\n",
    "    vta.program_fpga(remote, bitstream=None)\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the inference graph runtime\n",
    "---------------------------------\n",
    "Grab ResNet-18 model from Gluon model zoo and compile with Relay.\n",
    "The compilation steps are:\n",
    "   1. Front end translation from MxNet into Relay module.\n",
    "   2. Apply 8-bit quantization: here we skip the first conv layer,\n",
    "      and dense layer which will both be executed in fp32 on the CPU.\n",
    "   3. Perform graph packing to alter the data layout for tensorization.\n",
    "   4. Perform constant folding to reduce number of operators (e.g. eliminate batch norm multiply).\n",
    "   5. Perform relay build to object file.\n",
    "   6. Load the object file onto remote (FPGA device).\n",
    "   7. Generate graph runtime, `m`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32], %resnetv11_conv0_weight: Tensor[(64, 3, 7, 7), float32], %resnetv11_batchnorm0_gamma: Tensor[(64,), float32], %resnetv11_batchnorm0_beta: Tensor[(64,), float32], %resnetv11_batchnorm0_running_mean: Tensor[(64,), float32], %resnetv11_batchnorm0_running_var: Tensor[(64,), float32], %resnetv11_stage1_conv0_weight: Tensor[(64, 64, 3, 3), float32], %resnetv11_stage1_batchnorm0_gamma: Tensor[(64,), float32], %resnetv11_stage1_batchnorm0_beta: Tensor[(64,), float32], %resnetv11_stage1_batchnorm0_running_mean: Tensor[(64,), float32], %resnetv11_stage1_batchnorm0_running_var: Tensor[(64,), float32], %resnetv11_stage1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %resnetv11_stage1_batchnorm1_gamma: Tensor[(64,), float32], %resnetv11_stage1_batchnorm1_beta: Tensor[(64,), float32], %resnetv11_stage1_batchnorm1_running_mean: Tensor[(64,), float32], %resnetv11_stage1_batchnorm1_running_var: Tensor[(64,), float32], %resnetv11_stage1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %resnetv11_stage1_batchnorm2_gamma: Tensor[(64,), float32], %resnetv11_stage1_batchnorm2_beta: Tensor[(64,), float32], %resnetv11_stage1_batchnorm2_running_mean: Tensor[(64,), float32], %resnetv11_stage1_batchnorm2_running_var: Tensor[(64,), float32], %resnetv11_stage1_conv3_weight: Tensor[(64, 64, 3, 3), float32], %resnetv11_stage1_batchnorm3_gamma: Tensor[(64,), float32], %resnetv11_stage1_batchnorm3_beta: Tensor[(64,), float32], %resnetv11_stage1_batchnorm3_running_mean: Tensor[(64,), float32], %resnetv11_stage1_batchnorm3_running_var: Tensor[(64,), float32], %resnetv11_stage2_conv2_weight: Tensor[(128, 64, 1, 1), float32], %resnetv11_stage2_batchnorm2_gamma: Tensor[(128,), float32], %resnetv11_stage2_batchnorm2_beta: Tensor[(128,), float32], %resnetv11_stage2_batchnorm2_running_mean: Tensor[(128,), float32], %resnetv11_stage2_batchnorm2_running_var: Tensor[(128,), float32], %resnetv11_stage2_conv0_weight: Tensor[(128, 64, 3, 3), float32], %resnetv11_stage2_batchnorm0_gamma: Tensor[(128,), float32], %resnetv11_stage2_batchnorm0_beta: Tensor[(128,), float32], %resnetv11_stage2_batchnorm0_running_mean: Tensor[(128,), float32], %resnetv11_stage2_batchnorm0_running_var: Tensor[(128,), float32], %resnetv11_stage2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %resnetv11_stage2_batchnorm1_gamma: Tensor[(128,), float32], %resnetv11_stage2_batchnorm1_beta: Tensor[(128,), float32], %resnetv11_stage2_batchnorm1_running_mean: Tensor[(128,), float32], %resnetv11_stage2_batchnorm1_running_var: Tensor[(128,), float32], %resnetv11_stage2_conv3_weight: Tensor[(128, 128, 3, 3), float32], %resnetv11_stage2_batchnorm3_gamma: Tensor[(128,), float32], %resnetv11_stage2_batchnorm3_beta: Tensor[(128,), float32], %resnetv11_stage2_batchnorm3_running_mean: Tensor[(128,), float32], %resnetv11_stage2_batchnorm3_running_var: Tensor[(128,), float32], %resnetv11_stage2_conv4_weight: Tensor[(128, 128, 3, 3), float32], %resnetv11_stage2_batchnorm4_gamma: Tensor[(128,), float32], %resnetv11_stage2_batchnorm4_beta: Tensor[(128,), float32], %resnetv11_stage2_batchnorm4_running_mean: Tensor[(128,), float32], %resnetv11_stage2_batchnorm4_running_var: Tensor[(128,), float32], %resnetv11_stage3_conv2_weight: Tensor[(256, 128, 1, 1), float32], %resnetv11_stage3_batchnorm2_gamma: Tensor[(256,), float32], %resnetv11_stage3_batchnorm2_beta: Tensor[(256,), float32], %resnetv11_stage3_batchnorm2_running_mean: Tensor[(256,), float32], %resnetv11_stage3_batchnorm2_running_var: Tensor[(256,), float32], %resnetv11_stage3_conv0_weight: Tensor[(256, 128, 3, 3), float32], %resnetv11_stage3_batchnorm0_gamma: Tensor[(256,), float32], %resnetv11_stage3_batchnorm0_beta: Tensor[(256,), float32], %resnetv11_stage3_batchnorm0_running_mean: Tensor[(256,), float32], %resnetv11_stage3_batchnorm0_running_var: Tensor[(256,), float32], %resnetv11_stage3_conv1_weight: Tensor[(256, 256, 3, 3), float32], %resnetv11_stage3_batchnorm1_gamma: Tensor[(256,), float32], %resnetv11_stage3_batchnorm1_beta: Tensor[(256,), float32], %resnetv11_stage3_batchnorm1_running_mean: Tensor[(256,), float32], %resnetv11_stage3_batchnorm1_running_var: Tensor[(256,), float32], %resnetv11_stage3_conv3_weight: Tensor[(256, 256, 3, 3), float32], %resnetv11_stage3_batchnorm3_gamma: Tensor[(256,), float32], %resnetv11_stage3_batchnorm3_beta: Tensor[(256,), float32], %resnetv11_stage3_batchnorm3_running_mean: Tensor[(256,), float32], %resnetv11_stage3_batchnorm3_running_var: Tensor[(256,), float32], %resnetv11_stage3_conv4_weight: Tensor[(256, 256, 3, 3), float32], %resnetv11_stage3_batchnorm4_gamma: Tensor[(256,), float32], %resnetv11_stage3_batchnorm4_beta: Tensor[(256,), float32], %resnetv11_stage3_batchnorm4_running_mean: Tensor[(256,), float32], %resnetv11_stage3_batchnorm4_running_var: Tensor[(256,), float32], %resnetv11_stage4_conv2_weight: Tensor[(512, 256, 1, 1), float32], %resnetv11_stage4_batchnorm2_gamma: Tensor[(512,), float32], %resnetv11_stage4_batchnorm2_beta: Tensor[(512,), float32], %resnetv11_stage4_batchnorm2_running_mean: Tensor[(512,), float32], %resnetv11_stage4_batchnorm2_running_var: Tensor[(512,), float32], %resnetv11_stage4_conv0_weight: Tensor[(512, 256, 3, 3), float32], %resnetv11_stage4_batchnorm0_gamma: Tensor[(512,), float32], %resnetv11_stage4_batchnorm0_beta: Tensor[(512,), float32], %resnetv11_stage4_batchnorm0_running_mean: Tensor[(512,), float32], %resnetv11_stage4_batchnorm0_running_var: Tensor[(512,), float32], %resnetv11_stage4_conv1_weight: Tensor[(512, 512, 3, 3), float32], %resnetv11_stage4_batchnorm1_gamma: Tensor[(512,), float32], %resnetv11_stage4_batchnorm1_beta: Tensor[(512,), float32], %resnetv11_stage4_batchnorm1_running_mean: Tensor[(512,), float32], %resnetv11_stage4_batchnorm1_running_var: Tensor[(512,), float32], %resnetv11_stage4_conv3_weight: Tensor[(512, 512, 3, 3), float32], %resnetv11_stage4_batchnorm3_gamma: Tensor[(512,), float32], %resnetv11_stage4_batchnorm3_beta: Tensor[(512,), float32], %resnetv11_stage4_batchnorm3_running_mean: Tensor[(512,), float32], %resnetv11_stage4_batchnorm3_running_var: Tensor[(512,), float32], %resnetv11_stage4_conv4_weight: Tensor[(512, 512, 3, 3), float32], %resnetv11_stage4_batchnorm4_gamma: Tensor[(512,), float32], %resnetv11_stage4_batchnorm4_beta: Tensor[(512,), float32], %resnetv11_stage4_batchnorm4_running_mean: Tensor[(512,), float32], %resnetv11_stage4_batchnorm4_running_var: Tensor[(512,), float32], %resnetv11_dense0_weight: Tensor[(1000, 512), float32], %resnetv11_dense0_bias: Tensor[(1000,), float32]) {\n",
      "  %0 = nn.conv2d(%data, %resnetv11_conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7])\n",
      "  %1 = nn.batch_norm(%0, %resnetv11_batchnorm0_gamma, %resnetv11_batchnorm0_beta, %resnetv11_batchnorm0_running_mean, %resnetv11_batchnorm0_running_var)\n",
      "  %2 = %1.0\n",
      "  %3 = nn.relu(%2)\n",
      "  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1])\n",
      "  %5 = nn.conv2d(%4, %resnetv11_stage1_conv0_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %6 = nn.batch_norm(%5, %resnetv11_stage1_batchnorm0_gamma, %resnetv11_stage1_batchnorm0_beta, %resnetv11_stage1_batchnorm0_running_mean, %resnetv11_stage1_batchnorm0_running_var)\n",
      "  %7 = %6.0\n",
      "  %8 = nn.relu(%7)\n",
      "  %9 = nn.conv2d(%8, %resnetv11_stage1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %10 = nn.batch_norm(%9, %resnetv11_stage1_batchnorm1_gamma, %resnetv11_stage1_batchnorm1_beta, %resnetv11_stage1_batchnorm1_running_mean, %resnetv11_stage1_batchnorm1_running_var)\n",
      "  %11 = %10.0\n",
      "  %12 = add(%4, %11)\n",
      "  %13 = nn.relu(%12)\n",
      "  %14 = nn.conv2d(%13, %resnetv11_stage1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %15 = nn.batch_norm(%14, %resnetv11_stage1_batchnorm2_gamma, %resnetv11_stage1_batchnorm2_beta, %resnetv11_stage1_batchnorm2_running_mean, %resnetv11_stage1_batchnorm2_running_var)\n",
      "  %16 = %15.0\n",
      "  %17 = nn.relu(%16)\n",
      "  %18 = nn.conv2d(%17, %resnetv11_stage1_conv3_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %19 = nn.batch_norm(%18, %resnetv11_stage1_batchnorm3_gamma, %resnetv11_stage1_batchnorm3_beta, %resnetv11_stage1_batchnorm3_running_mean, %resnetv11_stage1_batchnorm3_running_var)\n",
      "  %20 = %19.0\n",
      "  %21 = add(%13, %20)\n",
      "  %22 = nn.relu(%21)\n",
      "  %23 = nn.conv2d(%22, %resnetv11_stage2_conv2_weight, strides=[2, 2], channels=128, kernel_size=[1, 1])\n",
      "  %24 = nn.batch_norm(%23, %resnetv11_stage2_batchnorm2_gamma, %resnetv11_stage2_batchnorm2_beta, %resnetv11_stage2_batchnorm2_running_mean, %resnetv11_stage2_batchnorm2_running_var)\n",
      "  %25 = %24.0\n",
      "  %26 = nn.conv2d(%22, %resnetv11_stage2_conv0_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %27 = nn.batch_norm(%26, %resnetv11_stage2_batchnorm0_gamma, %resnetv11_stage2_batchnorm0_beta, %resnetv11_stage2_batchnorm0_running_mean, %resnetv11_stage2_batchnorm0_running_var)\n",
      "  %28 = %27.0\n",
      "  %29 = nn.relu(%28)\n",
      "  %30 = nn.conv2d(%29, %resnetv11_stage2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %31 = nn.batch_norm(%30, %resnetv11_stage2_batchnorm1_gamma, %resnetv11_stage2_batchnorm1_beta, %resnetv11_stage2_batchnorm1_running_mean, %resnetv11_stage2_batchnorm1_running_var)\n",
      "  %32 = %31.0\n",
      "  %33 = add(%25, %32)\n",
      "  %34 = nn.relu(%33)\n",
      "  %35 = nn.conv2d(%34, %resnetv11_stage2_conv3_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %36 = nn.batch_norm(%35, %resnetv11_stage2_batchnorm3_gamma, %resnetv11_stage2_batchnorm3_beta, %resnetv11_stage2_batchnorm3_running_mean, %resnetv11_stage2_batchnorm3_running_var)\n",
      "  %37 = %36.0\n",
      "  %38 = nn.relu(%37)\n",
      "  %39 = nn.conv2d(%38, %resnetv11_stage2_conv4_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %40 = nn.batch_norm(%39, %resnetv11_stage2_batchnorm4_gamma, %resnetv11_stage2_batchnorm4_beta, %resnetv11_stage2_batchnorm4_running_mean, %resnetv11_stage2_batchnorm4_running_var)\n",
      "  %41 = %40.0\n",
      "  %42 = add(%34, %41)\n",
      "  %43 = nn.relu(%42)\n",
      "  %44 = nn.conv2d(%43, %resnetv11_stage3_conv2_weight, strides=[2, 2], channels=256, kernel_size=[1, 1])\n",
      "  %45 = nn.batch_norm(%44, %resnetv11_stage3_batchnorm2_gamma, %resnetv11_stage3_batchnorm2_beta, %resnetv11_stage3_batchnorm2_running_mean, %resnetv11_stage3_batchnorm2_running_var)\n",
      "  %46 = %45.0\n",
      "  %47 = nn.conv2d(%43, %resnetv11_stage3_conv0_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %48 = nn.batch_norm(%47, %resnetv11_stage3_batchnorm0_gamma, %resnetv11_stage3_batchnorm0_beta, %resnetv11_stage3_batchnorm0_running_mean, %resnetv11_stage3_batchnorm0_running_var)\n",
      "  %49 = %48.0\n",
      "  %50 = nn.relu(%49)\n",
      "  %51 = nn.conv2d(%50, %resnetv11_stage3_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %52 = nn.batch_norm(%51, %resnetv11_stage3_batchnorm1_gamma, %resnetv11_stage3_batchnorm1_beta, %resnetv11_stage3_batchnorm1_running_mean, %resnetv11_stage3_batchnorm1_running_var)\n",
      "  %53 = %52.0\n",
      "  %54 = add(%46, %53)\n",
      "  %55 = nn.relu(%54)\n",
      "  %56 = nn.conv2d(%55, %resnetv11_stage3_conv3_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %57 = nn.batch_norm(%56, %resnetv11_stage3_batchnorm3_gamma, %resnetv11_stage3_batchnorm3_beta, %resnetv11_stage3_batchnorm3_running_mean, %resnetv11_stage3_batchnorm3_running_var)\n",
      "  %58 = %57.0\n",
      "  %59 = nn.relu(%58)\n",
      "  %60 = nn.conv2d(%59, %resnetv11_stage3_conv4_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %61 = nn.batch_norm(%60, %resnetv11_stage3_batchnorm4_gamma, %resnetv11_stage3_batchnorm4_beta, %resnetv11_stage3_batchnorm4_running_mean, %resnetv11_stage3_batchnorm4_running_var)\n",
      "  %62 = %61.0\n",
      "  %63 = add(%55, %62)\n",
      "  %64 = nn.relu(%63)\n",
      "  %65 = nn.conv2d(%64, %resnetv11_stage4_conv2_weight, strides=[2, 2], channels=512, kernel_size=[1, 1])\n",
      "  %66 = nn.batch_norm(%65, %resnetv11_stage4_batchnorm2_gamma, %resnetv11_stage4_batchnorm2_beta, %resnetv11_stage4_batchnorm2_running_mean, %resnetv11_stage4_batchnorm2_running_var)\n",
      "  %67 = %66.0\n",
      "  %68 = nn.conv2d(%64, %resnetv11_stage4_conv0_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %69 = nn.batch_norm(%68, %resnetv11_stage4_batchnorm0_gamma, %resnetv11_stage4_batchnorm0_beta, %resnetv11_stage4_batchnorm0_running_mean, %resnetv11_stage4_batchnorm0_running_var)\n",
      "  %70 = %69.0\n",
      "  %71 = nn.relu(%70)\n",
      "  %72 = nn.conv2d(%71, %resnetv11_stage4_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %73 = nn.batch_norm(%72, %resnetv11_stage4_batchnorm1_gamma, %resnetv11_stage4_batchnorm1_beta, %resnetv11_stage4_batchnorm1_running_mean, %resnetv11_stage4_batchnorm1_running_var)\n",
      "  %74 = %73.0\n",
      "  %75 = add(%67, %74)\n",
      "  %76 = nn.relu(%75)\n",
      "  %77 = nn.conv2d(%76, %resnetv11_stage4_conv3_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %78 = nn.batch_norm(%77, %resnetv11_stage4_batchnorm3_gamma, %resnetv11_stage4_batchnorm3_beta, %resnetv11_stage4_batchnorm3_running_mean, %resnetv11_stage4_batchnorm3_running_var)\n",
      "  %79 = %78.0\n",
      "  %80 = nn.relu(%79)\n",
      "  %81 = nn.conv2d(%80, %resnetv11_stage4_conv4_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %82 = nn.batch_norm(%81, %resnetv11_stage4_batchnorm4_gamma, %resnetv11_stage4_batchnorm4_beta, %resnetv11_stage4_batchnorm4_running_mean, %resnetv11_stage4_batchnorm4_running_var)\n",
      "  %83 = %82.0\n",
      "  %84 = add(%76, %83)\n",
      "  %85 = nn.relu(%84)\n",
      "  %86 = nn.global_avg_pool2d(%85)\n",
      "  %87 = nn.batch_flatten(%86)\n",
      "  %88 = nn.dense(%87, %resnetv11_dense0_weight, units=1000)\n",
      "  nn.bias_add(%88, %resnetv11_dense0_bias, axis=-1)\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32]) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */ /* ty=Tensor[(64, 3, 7, 7), float32] */, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  %1 = add(%0, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  %3 = nn.max_pool2d(%2, pool_size=[3, 3], strides=[2, 2], padding=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %4 = reshape(%3, newshape=[1, 1, 4, 16, 56, 56]) /* ty=Tensor[(1, 1, 4, 16, 56, 56), float32] */\n",
      "  %5 = transpose(%4, axes=[0, 2, 4, 5, 1, 3]) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %6 = force_cast(%5) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %7 = stop_fusion(%6) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %8 = multiply(%7, 16f /* ty=float32 */) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %9 = round(%8) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %10 = clip(%9, a_min=-127, a_max=127) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %11 = cast(%10, dtype=\"int8\") /* ty=Tensor[(1, 4, 56, 56, 1, 16), int8] */\n",
      "  %12 = force_cast(%5) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %13 = stop_fusion(%12) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %14 = multiply(%13, 16f /* ty=float32 */) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %15 = round(%14) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %16 = clip(%15, a_min=-127, a_max=127) /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */\n",
      "  %17 = cast(%16, dtype=\"int8\") /* ty=Tensor[(1, 4, 56, 56, 1, 16), int8] */\n",
      "  %18 = nn.conv2d(%17, meta[relay.Constant][2], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %19 = add(%18, meta[relay.Constant][3])\n",
      "  %20 = nn.relu(%19)\n",
      "  %21 = add(%20, 64 /* ty=int32 */)\n",
      "  %22 = right_shift(%21, 7 /* ty=int32 */)\n",
      "  %23 = clip(%22, a_min=-127, a_max=127)\n",
      "  %24 = cast(%23, dtype=\"int8\")\n",
      "  %25 = copy(%24)\n",
      "  %26 = stop_fusion(%25)\n",
      "  %27 = nn.conv2d(%26, meta[relay.Constant][4], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %28 = add(%27, meta[relay.Constant][5])\n",
      "  %29 = add(%28, 32 /* ty=int32 */)\n",
      "  %30 = right_shift(%29, 6 /* ty=int32 */)\n",
      "  %31 = clip(%30, a_min=-127, a_max=127)\n",
      "  %32 = cast(%31, dtype=\"int8\")\n",
      "  %33 = copy(%32)\n",
      "  %34 = stop_fusion(%33)\n",
      "  %35 = add(%11, %34)\n",
      "  %36 = nn.relu(%35)\n",
      "  %37 = cast(%36, dtype=\"int8\")\n",
      "  %38 = cast(%36, dtype=\"int8\")\n",
      "  %39 = nn.conv2d(%38, meta[relay.Constant][6], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %40 = add(%39, meta[relay.Constant][7])\n",
      "  %41 = nn.relu(%40)\n",
      "  %42 = add(%41, 256 /* ty=int32 */)\n",
      "  %43 = right_shift(%42, 9 /* ty=int32 */)\n",
      "  %44 = clip(%43, a_min=-127, a_max=127)\n",
      "  %45 = cast(%44, dtype=\"int8\")\n",
      "  %46 = copy(%45)\n",
      "  %47 = stop_fusion(%46)\n",
      "  %48 = nn.conv2d(%47, meta[relay.Constant][8], padding=[1, 1], channels=64, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %49 = add(%48, meta[relay.Constant][9])\n",
      "  %50 = add(%49, 32 /* ty=int32 */)\n",
      "  %51 = right_shift(%50, 6 /* ty=int32 */)\n",
      "  %52 = clip(%51, a_min=-127, a_max=127)\n",
      "  %53 = cast(%52, dtype=\"int8\")\n",
      "  %54 = copy(%53)\n",
      "  %55 = stop_fusion(%54)\n",
      "  %56 = add(%37, %55)\n",
      "  %57 = nn.relu(%56)\n",
      "  %58 = cast(%57, dtype=\"int8\")\n",
      "  %59 = nn.conv2d(%58, meta[relay.Constant][10], strides=[2, 2], channels=128, kernel_size=[1, 1], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %60 = add(%59, meta[relay.Constant][11])\n",
      "  %61 = add(%60, 64 /* ty=int32 */)\n",
      "  %62 = right_shift(%61, 7 /* ty=int32 */)\n",
      "  %63 = clip(%62, a_min=-127, a_max=127)\n",
      "  %64 = cast(%63, dtype=\"int8\")\n",
      "  %65 = copy(%64)\n",
      "  %66 = stop_fusion(%65)\n",
      "  %67 = cast(%66, dtype=\"int8\")\n",
      "  %68 = cast(%57, dtype=\"int8\")\n",
      "  %69 = nn.conv2d(%68, meta[relay.Constant][12], strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %70 = add(%69, meta[relay.Constant][13])\n",
      "  %71 = nn.relu(%70)\n",
      "  %72 = add(%71, 256 /* ty=int32 */)\n",
      "  %73 = right_shift(%72, 9 /* ty=int32 */)\n",
      "  %74 = clip(%73, a_min=-127, a_max=127)\n",
      "  %75 = cast(%74, dtype=\"int8\")\n",
      "  %76 = copy(%75)\n",
      "  %77 = stop_fusion(%76)\n",
      "  %78 = nn.conv2d(%77, meta[relay.Constant][14], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %79 = add(%78, meta[relay.Constant][15])\n",
      "  %80 = add(%79, 64 /* ty=int32 */)\n",
      "  %81 = right_shift(%80, 7 /* ty=int32 */)\n",
      "  %82 = clip(%81, a_min=-127, a_max=127)\n",
      "  %83 = cast(%82, dtype=\"int8\")\n",
      "  %84 = copy(%83)\n",
      "  %85 = stop_fusion(%84)\n",
      "  %86 = add(%67, %85)\n",
      "  %87 = nn.relu(%86)\n",
      "  %88 = cast(%87, dtype=\"int8\")\n",
      "  %89 = cast(%87, dtype=\"int8\")\n",
      "  %90 = nn.conv2d(%89, meta[relay.Constant][16], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %91 = add(%90, meta[relay.Constant][17])\n",
      "  %92 = nn.relu(%91)\n",
      "  %93 = add(%92, 128 /* ty=int32 */)\n",
      "  %94 = right_shift(%93, 8 /* ty=int32 */)\n",
      "  %95 = clip(%94, a_min=-127, a_max=127)\n",
      "  %96 = cast(%95, dtype=\"int8\")\n",
      "  %97 = copy(%96)\n",
      "  %98 = stop_fusion(%97)\n",
      "  %99 = nn.conv2d(%98, meta[relay.Constant][18], padding=[1, 1], channels=128, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %100 = add(%99, meta[relay.Constant][19])\n",
      "  %101 = add(%100, 64 /* ty=int32 */)\n",
      "  %102 = right_shift(%101, 7 /* ty=int32 */)\n",
      "  %103 = clip(%102, a_min=-127, a_max=127)\n",
      "  %104 = cast(%103, dtype=\"int8\")\n",
      "  %105 = copy(%104)\n",
      "  %106 = stop_fusion(%105)\n",
      "  %107 = add(%88, %106)\n",
      "  %108 = nn.relu(%107)\n",
      "  %109 = cast(%108, dtype=\"int8\")\n",
      "  %110 = nn.conv2d(%109, meta[relay.Constant][20], strides=[2, 2], channels=256, kernel_size=[1, 1], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %111 = add(%110, meta[relay.Constant][21])\n",
      "  %112 = add(%111, 128 /* ty=int32 */)\n",
      "  %113 = right_shift(%112, 8 /* ty=int32 */)\n",
      "  %114 = clip(%113, a_min=-127, a_max=127)\n",
      "  %115 = cast(%114, dtype=\"int8\")\n",
      "  %116 = copy(%115)\n",
      "  %117 = stop_fusion(%116)\n",
      "  %118 = cast(%117, dtype=\"int8\")\n",
      "  %119 = cast(%108, dtype=\"int8\")\n",
      "  %120 = nn.conv2d(%119, meta[relay.Constant][22], strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %121 = add(%120, meta[relay.Constant][23])\n",
      "  %122 = nn.relu(%121)\n",
      "  %123 = add(%122, 256 /* ty=int32 */)\n",
      "  %124 = right_shift(%123, 9 /* ty=int32 */)\n",
      "  %125 = clip(%124, a_min=-127, a_max=127)\n",
      "  %126 = cast(%125, dtype=\"int8\")\n",
      "  %127 = copy(%126)\n",
      "  %128 = stop_fusion(%127)\n",
      "  %129 = nn.conv2d(%128, meta[relay.Constant][24], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %130 = add(%129, meta[relay.Constant][25])\n",
      "  %131 = add(%130, 64 /* ty=int32 */)\n",
      "  %132 = right_shift(%131, 7 /* ty=int32 */)\n",
      "  %133 = clip(%132, a_min=-127, a_max=127)\n",
      "  %134 = cast(%133, dtype=\"int8\")\n",
      "  %135 = copy(%134)\n",
      "  %136 = stop_fusion(%135)\n",
      "  %137 = add(%118, %136)\n",
      "  %138 = nn.relu(%137)\n",
      "  %139 = cast(%138, dtype=\"int8\")\n",
      "  %140 = cast(%138, dtype=\"int8\")\n",
      "  %141 = nn.conv2d(%140, meta[relay.Constant][26], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %142 = add(%141, meta[relay.Constant][27])\n",
      "  %143 = nn.relu(%142)\n",
      "  %144 = add(%143, 128 /* ty=int32 */)\n",
      "  %145 = right_shift(%144, 8 /* ty=int32 */)\n",
      "  %146 = clip(%145, a_min=-127, a_max=127)\n",
      "  %147 = cast(%146, dtype=\"int8\")\n",
      "  %148 = copy(%147)\n",
      "  %149 = stop_fusion(%148)\n",
      "  %150 = nn.conv2d(%149, meta[relay.Constant][28], padding=[1, 1], channels=256, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %151 = add(%150, meta[relay.Constant][29])\n",
      "  %152 = add(%151, 64 /* ty=int32 */)\n",
      "  %153 = right_shift(%152, 7 /* ty=int32 */)\n",
      "  %154 = clip(%153, a_min=-127, a_max=127)\n",
      "  %155 = cast(%154, dtype=\"int8\")\n",
      "  %156 = copy(%155)\n",
      "  %157 = stop_fusion(%156)\n",
      "  %158 = add(%139, %157)\n",
      "  %159 = nn.relu(%158)\n",
      "  %160 = cast(%159, dtype=\"int8\")\n",
      "  %161 = nn.conv2d(%160, meta[relay.Constant][30], strides=[2, 2], channels=512, kernel_size=[1, 1], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %162 = add(%161, meta[relay.Constant][31])\n",
      "  %163 = add(%162, 32 /* ty=int32 */)\n",
      "  %164 = right_shift(%163, 6 /* ty=int32 */)\n",
      "  %165 = clip(%164, a_min=-127, a_max=127)\n",
      "  %166 = cast(%165, dtype=\"int8\")\n",
      "  %167 = copy(%166)\n",
      "  %168 = stop_fusion(%167)\n",
      "  %169 = cast(%168, dtype=\"int8\")\n",
      "  %170 = cast(%159, dtype=\"int8\")\n",
      "  %171 = nn.conv2d(%170, meta[relay.Constant][32], strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %172 = add(%171, meta[relay.Constant][33])\n",
      "  %173 = nn.relu(%172)\n",
      "  %174 = add(%173, 128 /* ty=int32 */)\n",
      "  %175 = right_shift(%174, 8 /* ty=int32 */)\n",
      "  %176 = clip(%175, a_min=-127, a_max=127)\n",
      "  %177 = cast(%176, dtype=\"int8\")\n",
      "  %178 = copy(%177)\n",
      "  %179 = stop_fusion(%178)\n",
      "  %180 = nn.conv2d(%179, meta[relay.Constant][34], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %181 = add(%180, meta[relay.Constant][35])\n",
      "  %182 = add(%181, 32 /* ty=int32 */)\n",
      "  %183 = right_shift(%182, 6 /* ty=int32 */)\n",
      "  %184 = clip(%183, a_min=-127, a_max=127)\n",
      "  %185 = cast(%184, dtype=\"int8\")\n",
      "  %186 = copy(%185)\n",
      "  %187 = stop_fusion(%186)\n",
      "  %188 = add(%169, %187)\n",
      "  %189 = nn.relu(%188)\n",
      "  %190 = cast(%189, dtype=\"int8\")\n",
      "  %191 = cast(%189, dtype=\"int8\")\n",
      "  %192 = nn.conv2d(%191, meta[relay.Constant][36], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %193 = add(%192, meta[relay.Constant][37])\n",
      "  %194 = nn.relu(%193)\n",
      "  %195 = add(%194, 128 /* ty=int32 */)\n",
      "  %196 = right_shift(%195, 8 /* ty=int32 */)\n",
      "  %197 = clip(%196, a_min=-127, a_max=127)\n",
      "  %198 = cast(%197, dtype=\"int8\")\n",
      "  %199 = copy(%198)\n",
      "  %200 = stop_fusion(%199)\n",
      "  %201 = nn.conv2d(%200, meta[relay.Constant][38], padding=[1, 1], channels=512, kernel_size=[3, 3], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\", out_dtype=\"int32\")\n",
      "  %202 = add(%201, meta[relay.Constant][39])\n",
      "  %203 = add(%202, 8 /* ty=int32 */)\n",
      "  %204 = right_shift(%203, 4 /* ty=int32 */)\n",
      "  %205 = clip(%204, a_min=-127, a_max=127)\n",
      "  %206 = cast(%205, dtype=\"int8\")\n",
      "  %207 = copy(%206)\n",
      "  %208 = stop_fusion(%207)\n",
      "  %209 = add(%190, %208)\n",
      "  %210 = nn.relu(%209)\n",
      "  %211 = cast(%210, dtype=\"int8\")\n",
      "  %212 = cast(%211, dtype=\"float32\")\n",
      "  %213 = multiply(%212, 0.0625f /* ty=float32 */)\n",
      "  %214 = transpose(%213, axes=[0, 4, 1, 5, 2, 3])\n",
      "  %215 = reshape(%214, newshape=[1, 512, 7, 7])\n",
      "  %216 = nn.global_avg_pool2d(%215)\n",
      "  %217 = nn.batch_flatten(%216)\n",
      "  %218 = nn.dense(%217, meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */ /* ty=Tensor[(1000, 512), float32] */, units=1000)\n",
      "  add(%218, meta[relay.Constant][41] /* ty=Tensor[(1000,), float32] */ /* ty=Tensor[(1000,), float32] */)\n",
      "}\n",
      "// meta data omitted. you can use show_meta_data=True to include meta data\n"
     ]
    }
   ],
   "source": [
    "# Populate the shape and data type dictionary for ResNet input\n",
    "dtype_dict = {\"data\": 'float32'}\n",
    "shape_dict = {\"data\": (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "# Get off the shelf gluon model, and convert to relay\n",
    "gluon_model = vision.get_model(model, pretrained=True)\n",
    "\n",
    "# Start front end compilation\n",
    "relay_prog, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "\n",
    "# Update shape and type dictionary\n",
    "shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
    "\n",
    "# Print the off the shelf model\n",
    "print(relay_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quantization in Relay\n",
    "with relay.quantize.qconfig(global_scale=8.0,\n",
    "                            skip_k_conv=1,\n",
    "                            skip_k_dense=1,\n",
    "                            target_vta=True):\n",
    "    relay_prog = relay.quantize.quantize(relay_prog, params=params)\n",
    "\n",
    "# Perform graph packing and constant folding for VTA target\n",
    "if target.device_name == \"vta\":\n",
    "    assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "    relay_prog = graph_pack(\n",
    "        relay_prog,\n",
    "        env.BATCH,\n",
    "        env.BLOCK_OUT,\n",
    "        env.WGT_WIDTH,\n",
    "        start_name=\"nn.max_pool2d\",\n",
    "        stop_name=\"nn.global_avg_pool2d\")\n",
    "    relay_prog = relay.ir_pass.fold_constant(relay_prog)\n",
    "\n",
    "# Print the transformed model\n",
    "print(relay_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph runtime\n",
    "m = None\n",
    "\n",
    "# Load pre-configured AutoTVM schedules\n",
    "with autotvm.tophub.context(target):\n",
    "    \n",
    "    # Compile Relay program with AlterOpLayout disabled\n",
    "    with relay.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "        if target.device_name != \"vta\":\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target,\n",
    "                params=params, target_host=env.target_host)\n",
    "        else:\n",
    "            with vta.build_config():\n",
    "                graph, lib, params = relay.build(\n",
    "                    relay_prog, target=target,\n",
    "                    params=params, target_host=env.target_host)\n",
    "\n",
    "    # Send the inference library over to the remote RPC server\n",
    "    temp = util.tempdir()\n",
    "    lib.save(temp.relpath(\"graphlib.o\"))\n",
    "    remote.upload(temp.relpath(\"graphlib.o\"))\n",
    "    lib = remote.load_module(\"graphlib.o\")\n",
    "\n",
    "    # Graph runtime\n",
    "    if env.TARGET == \"sim\":\n",
    "        m = graph_runtime.create(graph, lib, ctx)\n",
    "    elif env.TARGET == \"pynq\":\n",
    "        # In hardware we'll use the debug runtime\n",
    "        from tvm.contrib.debugger import debug_runtime\n",
    "        m = debug_runtime.create(graph, lib, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform ResNet-18 inference\n",
    "---------------------------\n",
    "We run classification on an image sample from ImageNet\n",
    "We just need to download the categories files, `synset.txt`\n",
    "and an input test image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ImageNet categories\n",
    "categ_url = \"https://github.com/uwsaml/web-data/raw/master/vta/models/\"\n",
    "categ_fn = \"synset.txt\"\n",
    "download.download(join(categ_url, categ_fn), categ_fn)\n",
    "synset = eval(open(categ_fn).read())\n",
    "\n",
    "# Download test image\n",
    "image_url = 'https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg'\n",
    "response = requests.get(image_url)\n",
    "\n",
    "# Prepare test image for inference\n",
    "image = Image.open(BytesIO(response.content)).resize((224, 224))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = np.array(image) - np.array([123., 117., 104.])\n",
    "image /= np.array([58.395, 57.12, 57.375])\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image[np.newaxis, :]\n",
    "image = np.repeat(image, env.BATCH, axis=0)\n",
    "\n",
    "# Set the network parameters and inputs\n",
    "m.set_input(**params)\n",
    "m.set_input('data', image)\n",
    "\n",
    "# Perform inference: we run the module 4 times,\n",
    "# and repeat 3 times to get error bounds\n",
    "timer = m.module.time_evaluator(\"run\", ctx, number=4, repeat=3)\n",
    "tcost = timer()\n",
    "\n",
    "# Get classification results\n",
    "tvm_output = m.get_output(0, tvm.nd.empty((env.BATCH, 1000), \"float32\", remote.cpu(0)))\n",
    "top_categories = np.argsort(tvm_output.asnumpy()[0])\n",
    "\n",
    "# Report top-5 classification results\n",
    "std = np.std(tcost.results) * 1000 / env.BATCH\n",
    "mean = tcost.mean * 1000 / env.BATCH\n",
    "print(\"%s prediction\" % model)\n",
    "print(\"                     #1:\", synset[top_categories[-1]])\n",
    "print(\"                     #2:\", synset[top_categories[-2]])\n",
    "print(\"                     #3:\", synset[top_categories[-3]])\n",
    "print(\"                     #4:\", synset[top_categories[-4]])\n",
    "print(\"                     #5:\", synset[top_categories[-5]])\n",
    "print(\"Performed inference in %.2fms/sample (std = %.2f)\" % (mean, std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the debug runtime to get a per-operator runtime breakdown\n",
    "if env.TARGET == \"pynq\":\n",
    "    m.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
