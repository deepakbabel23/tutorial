{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/02_TVM_Tutorial_Relay.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the introduction of the TVM tutorial before running this. \n",
    "The below code assumes you have already setup TVM, and merely loads it from your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "[[ ! -e /tools/google-cloud-sdk ]] && exit\n",
    "echo \"Installing Dependencies ...\"\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y -q llvm-6.0 libglfw3-dev libtinfo-dev libffi-dev zlib1g-dev clinfo\n",
    "cd \"/content/gdrive/My Drive\"\n",
    "if [[ ! -e tvm ]]; then\n",
    "    echo \"Cloning TVM ...\"\n",
    "    git clone --recursive https://github.com/dmlc/tvm\n",
    "fi\n",
    "echo \"Configuring Build ...\"\n",
    "cd tvm\n",
    "mkdir -p build\n",
    "cp cmake/config.cmake build\n",
    "# sed -i -e 's/USE_OPONGL OFF/USE_OPONGL ON/g' build/config.cmake\n",
    "sed -i -e 's/USE_CUDA OFF/USE_CUDA ON/g' build/config.cmake\n",
    "sed -i -e 's/USE_CUDNN OFF/USE_CUDNN ON/g' build/config.cmake\n",
    "sed -i -e 's/USE_LLVM OFF/USE_LLVM ON/g' build/config.cmake\n",
    "sed -i -e 's/USE_VTA_TSIM OFF/USE_VTA_TSIM ON/g' build/config.cmake\n",
    "cat build/config.cmake\n",
    "echo \"Running CMake ...\"\n",
    "cd build\n",
    "cmake ..\n",
    "echo \"Building TVM ...\"\n",
    "make -j4\n",
    "cd ..\n",
    "echo \"Installing Python libraries ...\"\n",
    "cd \"/content/gdrive/My Drive/tvm/\"\n",
    "cd python; python setup.py install; cd ..\n",
    "cd topi/python; python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relay: an extensible deep learning IR\n",
    "\n",
    "TODO fill in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hetergenous Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32], %bn_data_gamma: Tensor[(3,), float32], %bn_data_beta: Tensor[(3,), float32], %bn_data_moving_mean: Tensor[(3,), float32], %bn_data_moving_var: Tensor[(3,), float32], %conv0_weight: Tensor[(64, 3, 7, 7), float32], %bn0_gamma: Tensor[(64,), float32], %bn0_beta: Tensor[(64,), float32], %bn0_moving_mean: Tensor[(64,), float32], %bn0_moving_var: Tensor[(64,), float32], %stage1_unit1_bn1_gamma: Tensor[(64,), float32], %stage1_unit1_bn1_beta: Tensor[(64,), float32], %stage1_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn1_moving_var: Tensor[(64,), float32], %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_bn2_gamma: Tensor[(64,), float32], %stage1_unit1_bn2_beta: Tensor[(64,), float32], %stage1_unit1_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn2_moving_var: Tensor[(64,), float32], %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32], %stage1_unit2_bn1_gamma: Tensor[(64,), float32], %stage1_unit2_bn1_beta: Tensor[(64,), float32], %stage1_unit2_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn1_moving_var: Tensor[(64,), float32], %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit2_bn2_gamma: Tensor[(64,), float32], %stage1_unit2_bn2_beta: Tensor[(64,), float32], %stage1_unit2_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn2_moving_var: Tensor[(64,), float32], %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage2_unit1_bn1_gamma: Tensor[(64,), float32], %stage2_unit1_bn1_beta: Tensor[(64,), float32], %stage2_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage2_unit1_bn1_moving_var: Tensor[(64,), float32], %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32], %stage2_unit1_bn2_gamma: Tensor[(128,), float32], %stage2_unit1_bn2_beta: Tensor[(128,), float32], %stage2_unit1_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit1_bn2_moving_var: Tensor[(128,), float32], %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32], %stage2_unit2_bn1_gamma: Tensor[(128,), float32], %stage2_unit2_bn1_beta: Tensor[(128,), float32], %stage2_unit2_bn1_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn1_moving_var: Tensor[(128,), float32], %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit2_bn2_gamma: Tensor[(128,), float32], %stage2_unit2_bn2_beta: Tensor[(128,), float32], %stage2_unit2_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn2_moving_var: Tensor[(128,), float32], %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage3_unit1_bn1_gamma: Tensor[(128,), float32], %stage3_unit1_bn1_beta: Tensor[(128,), float32], %stage3_unit1_bn1_moving_mean: Tensor[(128,), float32], %stage3_unit1_bn1_moving_var: Tensor[(128,), float32], %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32], %stage3_unit1_bn2_gamma: Tensor[(256,), float32], %stage3_unit1_bn2_beta: Tensor[(256,), float32], %stage3_unit1_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit1_bn2_moving_var: Tensor[(256,), float32], %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32], %stage3_unit2_bn1_gamma: Tensor[(256,), float32], %stage3_unit2_bn1_beta: Tensor[(256,), float32], %stage3_unit2_bn1_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn1_moving_var: Tensor[(256,), float32], %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit2_bn2_gamma: Tensor[(256,), float32], %stage3_unit2_bn2_beta: Tensor[(256,), float32], %stage3_unit2_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn2_moving_var: Tensor[(256,), float32], %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage4_unit1_bn1_gamma: Tensor[(256,), float32], %stage4_unit1_bn1_beta: Tensor[(256,), float32], %stage4_unit1_bn1_moving_mean: Tensor[(256,), float32], %stage4_unit1_bn1_moving_var: Tensor[(256,), float32], %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32], %stage4_unit1_bn2_gamma: Tensor[(512,), float32], %stage4_unit1_bn2_beta: Tensor[(512,), float32], %stage4_unit1_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit1_bn2_moving_var: Tensor[(512,), float32], %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32], %stage4_unit2_bn1_gamma: Tensor[(512,), float32], %stage4_unit2_bn1_beta: Tensor[(512,), float32], %stage4_unit2_bn1_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn1_moving_var: Tensor[(512,), float32], %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit2_bn2_gamma: Tensor[(512,), float32], %stage4_unit2_bn2_beta: Tensor[(512,), float32], %stage4_unit2_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn2_moving_var: Tensor[(512,), float32], %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32], %bn1_gamma: Tensor[(512,), float32], %bn1_beta: Tensor[(512,), float32], %bn1_moving_mean: Tensor[(512,), float32], %bn1_moving_var: Tensor[(512,), float32], %fc1_weight: Tensor[(1000, 512), float32], %fc1_bias: Tensor[(1000,), float32]) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05, scale=False) /* ty=(Tensor[(1, 3, 224, 224), float32], Tensor[(3,), float32], Tensor[(3,), float32]) */\n",
      "  %1 = %0.0\n",
      "  %2 = nn.conv2d(%1, %conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  %3 = nn.batch_norm(%2, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 112, 112), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %4 = %3.0\n",
      "  %5 = nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  %6 = nn.max_pool2d(%5, pool_size=[3, 3], strides=[2, 2], padding=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %7 = nn.batch_norm(%6, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %8 = %7.0\n",
      "  %9 = nn.relu(%8) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %10 = nn.conv2d(%9, %stage1_unit1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %11 = nn.batch_norm(%10, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %12 = %11.0\n",
      "  %13 = nn.relu(%12) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %14 = nn.conv2d(%13, %stage1_unit1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %15 = nn.conv2d(%9, %stage1_unit1_sc_weight, channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %16 = add(%14, %15) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %17 = nn.batch_norm(%16, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %18 = %17.0\n",
      "  %19 = nn.relu(%18) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %20 = nn.conv2d(%19, %stage1_unit2_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %21 = nn.batch_norm(%20, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %22 = %21.0\n",
      "  %23 = nn.relu(%22) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %24 = nn.conv2d(%23, %stage1_unit2_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %25 = add(%24, %16) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %26 = nn.batch_norm(%25, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %27 = %26.0\n",
      "  %28 = nn.relu(%27) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %29 = nn.conv2d(%28, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %30 = nn.batch_norm(%29, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %31 = %30.0\n",
      "  %32 = nn.relu(%31) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %33 = nn.conv2d(%32, %stage2_unit1_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %34 = nn.conv2d(%28, %stage2_unit1_sc_weight, strides=[2, 2], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %35 = add(%33, %34) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %36 = nn.batch_norm(%35, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %37 = %36.0\n",
      "  %38 = nn.relu(%37) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %39 = nn.conv2d(%38, %stage2_unit2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %40 = nn.batch_norm(%39, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %41 = %40.0\n",
      "  %42 = nn.relu(%41) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %43 = nn.conv2d(%42, %stage2_unit2_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %44 = add(%43, %35) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %45 = nn.batch_norm(%44, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %46 = %45.0\n",
      "  %47 = nn.relu(%46) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %48 = nn.conv2d(%47, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %49 = nn.batch_norm(%48, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %50 = %49.0\n",
      "  %51 = nn.relu(%50) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %52 = nn.conv2d(%51, %stage3_unit1_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %53 = nn.conv2d(%47, %stage3_unit1_sc_weight, strides=[2, 2], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %54 = add(%52, %53) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %55 = nn.batch_norm(%54, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %56 = %55.0\n",
      "  %57 = nn.relu(%56) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %58 = nn.conv2d(%57, %stage3_unit2_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %59 = nn.batch_norm(%58, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %60 = %59.0\n",
      "  %61 = nn.relu(%60) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %62 = nn.conv2d(%61, %stage3_unit2_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %63 = add(%62, %54) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %64 = nn.batch_norm(%63, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %65 = %64.0\n",
      "  %66 = nn.relu(%65) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %67 = nn.conv2d(%66, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %68 = nn.batch_norm(%67, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %69 = %68.0\n",
      "  %70 = nn.relu(%69) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %71 = nn.conv2d(%70, %stage4_unit1_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %72 = nn.conv2d(%66, %stage4_unit1_sc_weight, strides=[2, 2], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %73 = add(%71, %72) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %74 = nn.batch_norm(%73, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %75 = %74.0\n",
      "  %76 = nn.relu(%75) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %77 = nn.conv2d(%76, %stage4_unit2_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %78 = nn.batch_norm(%77, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %79 = %78.0\n",
      "  %80 = nn.relu(%79) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %81 = nn.conv2d(%80, %stage4_unit2_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %82 = add(%81, %73) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %83 = nn.batch_norm(%82, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %84 = %83.0\n",
      "  %85 = nn.relu(%84) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %86 = nn.global_avg_pool2d(%85) /* ty=Tensor[(1, 512, 1, 1), float32] */\n",
      "  %87 = nn.batch_flatten(%86) /* ty=Tensor[(1, 512), float32] */\n",
      "  %88 = nn.dense(%87, %fc1_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */\n",
      "  %89 = nn.bias_add(%88, %fc1_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */\n",
      "  nn.softmax(%89) /* ty=Tensor[(1, 1000), float32] */\n",
      "}\n",
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32], %bn_data_gamma: Tensor[(3,), float32], %bn_data_beta: Tensor[(3,), float32], %bn_data_moving_mean: Tensor[(3,), float32], %bn_data_moving_var: Tensor[(3,), float32], %conv0_weight: Tensor[(64, 3, 7, 7), float32], %bn0_gamma: Tensor[(64,), float32], %bn0_beta: Tensor[(64,), float32], %bn0_moving_mean: Tensor[(64,), float32], %bn0_moving_var: Tensor[(64,), float32], %stage1_unit1_bn1_gamma: Tensor[(64,), float32], %stage1_unit1_bn1_beta: Tensor[(64,), float32], %stage1_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn1_moving_var: Tensor[(64,), float32], %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_bn2_gamma: Tensor[(64,), float32], %stage1_unit1_bn2_beta: Tensor[(64,), float32], %stage1_unit1_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn2_moving_var: Tensor[(64,), float32], %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32], %stage1_unit2_bn1_gamma: Tensor[(64,), float32], %stage1_unit2_bn1_beta: Tensor[(64,), float32], %stage1_unit2_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn1_moving_var: Tensor[(64,), float32], %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit2_bn2_gamma: Tensor[(64,), float32], %stage1_unit2_bn2_beta: Tensor[(64,), float32], %stage1_unit2_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn2_moving_var: Tensor[(64,), float32], %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage2_unit1_bn1_gamma: Tensor[(64,), float32], %stage2_unit1_bn1_beta: Tensor[(64,), float32], %stage2_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage2_unit1_bn1_moving_var: Tensor[(64,), float32], %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32], %stage2_unit1_bn2_gamma: Tensor[(128,), float32], %stage2_unit1_bn2_beta: Tensor[(128,), float32], %stage2_unit1_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit1_bn2_moving_var: Tensor[(128,), float32], %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32], %stage2_unit2_bn1_gamma: Tensor[(128,), float32], %stage2_unit2_bn1_beta: Tensor[(128,), float32], %stage2_unit2_bn1_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn1_moving_var: Tensor[(128,), float32], %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit2_bn2_gamma: Tensor[(128,), float32], %stage2_unit2_bn2_beta: Tensor[(128,), float32], %stage2_unit2_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn2_moving_var: Tensor[(128,), float32], %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage3_unit1_bn1_gamma: Tensor[(128,), float32], %stage3_unit1_bn1_beta: Tensor[(128,), float32], %stage3_unit1_bn1_moving_mean: Tensor[(128,), float32], %stage3_unit1_bn1_moving_var: Tensor[(128,), float32], %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32], %stage3_unit1_bn2_gamma: Tensor[(256,), float32], %stage3_unit1_bn2_beta: Tensor[(256,), float32], %stage3_unit1_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit1_bn2_moving_var: Tensor[(256,), float32], %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32], %stage3_unit2_bn1_gamma: Tensor[(256,), float32], %stage3_unit2_bn1_beta: Tensor[(256,), float32], %stage3_unit2_bn1_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn1_moving_var: Tensor[(256,), float32], %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit2_bn2_gamma: Tensor[(256,), float32], %stage3_unit2_bn2_beta: Tensor[(256,), float32], %stage3_unit2_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn2_moving_var: Tensor[(256,), float32], %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage4_unit1_bn1_gamma: Tensor[(256,), float32], %stage4_unit1_bn1_beta: Tensor[(256,), float32], %stage4_unit1_bn1_moving_mean: Tensor[(256,), float32], %stage4_unit1_bn1_moving_var: Tensor[(256,), float32], %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32], %stage4_unit1_bn2_gamma: Tensor[(512,), float32], %stage4_unit1_bn2_beta: Tensor[(512,), float32], %stage4_unit1_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit1_bn2_moving_var: Tensor[(512,), float32], %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32], %stage4_unit2_bn1_gamma: Tensor[(512,), float32], %stage4_unit2_bn1_beta: Tensor[(512,), float32], %stage4_unit2_bn1_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn1_moving_var: Tensor[(512,), float32], %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit2_bn2_gamma: Tensor[(512,), float32], %stage4_unit2_bn2_beta: Tensor[(512,), float32], %stage4_unit2_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn2_moving_var: Tensor[(512,), float32], %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32], %bn1_gamma: Tensor[(512,), float32], %bn1_beta: Tensor[(512,), float32], %bn1_moving_mean: Tensor[(512,), float32], %bn1_moving_var: Tensor[(512,), float32], %fc1_weight: Tensor[(1000, 512), float32], %fc1_bias: Tensor[(1000,), float32]) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05, scale=False)\n",
      "  %1 = %0.0\n",
      "  %2 = nn.conv2d(%1, %conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7])\n",
      "  %3 = on_device(%2, meta[relay.attrs.OnDeviceAttrs][0])\n",
      "  %4 = nn.batch_norm(%3, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05)\n",
      "  %5 = %4.0\n",
      "  %6 = nn.relu(%5)\n",
      "  %7 = nn.max_pool2d(%6, pool_size=[3, 3], strides=[2, 2], padding=[1, 1])\n",
      "  %8 = nn.batch_norm(%7, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %9 = %8.0\n",
      "  %10 = nn.relu(%9)\n",
      "  %11 = nn.conv2d(%10, %stage1_unit1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %12 = on_device(%11, meta[relay.attrs.OnDeviceAttrs][1])\n",
      "  %13 = nn.batch_norm(%12, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %14 = %13.0\n",
      "  %15 = nn.relu(%14)\n",
      "  %16 = nn.conv2d(%15, %stage1_unit1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %17 = on_device(%16, meta[relay.attrs.OnDeviceAttrs][2])\n",
      "  %18 = nn.conv2d(%10, %stage1_unit1_sc_weight, channels=64, kernel_size=[1, 1])\n",
      "  %19 = on_device(%18, meta[relay.attrs.OnDeviceAttrs][3])\n",
      "  %20 = add(%17, %19)\n",
      "  %21 = nn.batch_norm(%20, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %22 = %21.0\n",
      "  %23 = nn.relu(%22)\n",
      "  %24 = nn.conv2d(%23, %stage1_unit2_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %25 = on_device(%24, meta[relay.attrs.OnDeviceAttrs][4])\n",
      "  %26 = nn.batch_norm(%25, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %27 = %26.0\n",
      "  %28 = nn.relu(%27)\n",
      "  %29 = nn.conv2d(%28, %stage1_unit2_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %30 = on_device(%29, meta[relay.attrs.OnDeviceAttrs][5])\n",
      "  %31 = add(%30, %20)\n",
      "  %32 = nn.batch_norm(%31, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %33 = %32.0\n",
      "  %34 = nn.relu(%33)\n",
      "  %35 = nn.conv2d(%34, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %36 = on_device(%35, meta[relay.attrs.OnDeviceAttrs][6])\n",
      "  %37 = nn.batch_norm(%36, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %38 = %37.0\n",
      "  %39 = nn.relu(%38)\n",
      "  %40 = nn.conv2d(%39, %stage2_unit1_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %41 = on_device(%40, meta[relay.attrs.OnDeviceAttrs][7])\n",
      "  %42 = nn.conv2d(%34, %stage2_unit1_sc_weight, strides=[2, 2], channels=128, kernel_size=[1, 1])\n",
      "  %43 = on_device(%42, meta[relay.attrs.OnDeviceAttrs][8])\n",
      "  %44 = add(%41, %43)\n",
      "  %45 = nn.batch_norm(%44, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %46 = %45.0\n",
      "  %47 = nn.relu(%46)\n",
      "  %48 = nn.conv2d(%47, %stage2_unit2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %49 = on_device(%48, meta[relay.attrs.OnDeviceAttrs][9])\n",
      "  %50 = nn.batch_norm(%49, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %51 = %50.0\n",
      "  %52 = nn.relu(%51)\n",
      "  %53 = nn.conv2d(%52, %stage2_unit2_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %54 = on_device(%53, meta[relay.attrs.OnDeviceAttrs][10])\n",
      "  %55 = add(%54, %44)\n",
      "  %56 = nn.batch_norm(%55, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %57 = %56.0\n",
      "  %58 = nn.relu(%57)\n",
      "  %59 = nn.conv2d(%58, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %60 = on_device(%59, meta[relay.attrs.OnDeviceAttrs][11])\n",
      "  %61 = nn.batch_norm(%60, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %62 = %61.0\n",
      "  %63 = nn.relu(%62)\n",
      "  %64 = nn.conv2d(%63, %stage3_unit1_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %65 = on_device(%64, meta[relay.attrs.OnDeviceAttrs][12])\n",
      "  %66 = nn.conv2d(%58, %stage3_unit1_sc_weight, strides=[2, 2], channels=256, kernel_size=[1, 1])\n",
      "  %67 = on_device(%66, meta[relay.attrs.OnDeviceAttrs][13])\n",
      "  %68 = add(%65, %67)\n",
      "  %69 = nn.batch_norm(%68, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %70 = %69.0\n",
      "  %71 = nn.relu(%70)\n",
      "  %72 = nn.conv2d(%71, %stage3_unit2_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %73 = on_device(%72, meta[relay.attrs.OnDeviceAttrs][14])\n",
      "  %74 = nn.batch_norm(%73, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %75 = %74.0\n",
      "  %76 = nn.relu(%75)\n",
      "  %77 = nn.conv2d(%76, %stage3_unit2_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %78 = on_device(%77, meta[relay.attrs.OnDeviceAttrs][15])\n",
      "  %79 = add(%78, %68)\n",
      "  %80 = nn.batch_norm(%79, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %81 = %80.0\n",
      "  %82 = nn.relu(%81)\n",
      "  %83 = nn.conv2d(%82, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %84 = on_device(%83, meta[relay.attrs.OnDeviceAttrs][16])\n",
      "  %85 = nn.batch_norm(%84, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %86 = %85.0\n",
      "  %87 = nn.relu(%86)\n",
      "  %88 = nn.conv2d(%87, %stage4_unit1_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %89 = on_device(%88, meta[relay.attrs.OnDeviceAttrs][17])\n",
      "  %90 = nn.conv2d(%82, %stage4_unit1_sc_weight, strides=[2, 2], channels=512, kernel_size=[1, 1])\n",
      "  %91 = on_device(%90, meta[relay.attrs.OnDeviceAttrs][18])\n",
      "  %92 = add(%89, %91)\n",
      "  %93 = nn.batch_norm(%92, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %94 = %93.0\n",
      "  %95 = nn.relu(%94)\n",
      "  %96 = nn.conv2d(%95, %stage4_unit2_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %97 = on_device(%96, meta[relay.attrs.OnDeviceAttrs][19])\n",
      "  %98 = nn.batch_norm(%97, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %99 = %98.0\n",
      "  %100 = nn.relu(%99)\n",
      "  %101 = nn.conv2d(%100, %stage4_unit2_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %102 = on_device(%101, meta[relay.attrs.OnDeviceAttrs][20])\n",
      "  %103 = add(%102, %92)\n",
      "  %104 = nn.batch_norm(%103, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05)\n",
      "  %105 = %104.0\n",
      "  %106 = nn.relu(%105)\n",
      "  %107 = nn.global_avg_pool2d(%106)\n",
      "  %108 = nn.batch_flatten(%107)\n",
      "  %109 = nn.dense(%108, %fc1_weight, units=1000)\n",
      "  %110 = nn.bias_add(%109, %fc1_bias, axis=-1)\n",
      "  nn.softmax(%110)\n",
      "}\n",
      "// meta data omitted. you can use show_meta_data=True to include meta data\n",
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32], %bn_data_gamma: Tensor[(3,), float32], %bn_data_beta: Tensor[(3,), float32], %bn_data_moving_mean: Tensor[(3,), float32], %bn_data_moving_var: Tensor[(3,), float32], %conv0_weight: Tensor[(64, 3, 7, 7), float32], %bn0_gamma: Tensor[(64,), float32], %bn0_beta: Tensor[(64,), float32], %bn0_moving_mean: Tensor[(64,), float32], %bn0_moving_var: Tensor[(64,), float32], %stage1_unit1_bn1_gamma: Tensor[(64,), float32], %stage1_unit1_bn1_beta: Tensor[(64,), float32], %stage1_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn1_moving_var: Tensor[(64,), float32], %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_bn2_gamma: Tensor[(64,), float32], %stage1_unit1_bn2_beta: Tensor[(64,), float32], %stage1_unit1_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn2_moving_var: Tensor[(64,), float32], %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32], %stage1_unit2_bn1_gamma: Tensor[(64,), float32], %stage1_unit2_bn1_beta: Tensor[(64,), float32], %stage1_unit2_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn1_moving_var: Tensor[(64,), float32], %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit2_bn2_gamma: Tensor[(64,), float32], %stage1_unit2_bn2_beta: Tensor[(64,), float32], %stage1_unit2_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn2_moving_var: Tensor[(64,), float32], %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage2_unit1_bn1_gamma: Tensor[(64,), float32], %stage2_unit1_bn1_beta: Tensor[(64,), float32], %stage2_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage2_unit1_bn1_moving_var: Tensor[(64,), float32], %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32], %stage2_unit1_bn2_gamma: Tensor[(128,), float32], %stage2_unit1_bn2_beta: Tensor[(128,), float32], %stage2_unit1_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit1_bn2_moving_var: Tensor[(128,), float32], %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32], %stage2_unit2_bn1_gamma: Tensor[(128,), float32], %stage2_unit2_bn1_beta: Tensor[(128,), float32], %stage2_unit2_bn1_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn1_moving_var: Tensor[(128,), float32], %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit2_bn2_gamma: Tensor[(128,), float32], %stage2_unit2_bn2_beta: Tensor[(128,), float32], %stage2_unit2_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn2_moving_var: Tensor[(128,), float32], %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage3_unit1_bn1_gamma: Tensor[(128,), float32], %stage3_unit1_bn1_beta: Tensor[(128,), float32], %stage3_unit1_bn1_moving_mean: Tensor[(128,), float32], %stage3_unit1_bn1_moving_var: Tensor[(128,), float32], %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32], %stage3_unit1_bn2_gamma: Tensor[(256,), float32], %stage3_unit1_bn2_beta: Tensor[(256,), float32], %stage3_unit1_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit1_bn2_moving_var: Tensor[(256,), float32], %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32], %stage3_unit2_bn1_gamma: Tensor[(256,), float32], %stage3_unit2_bn1_beta: Tensor[(256,), float32], %stage3_unit2_bn1_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn1_moving_var: Tensor[(256,), float32], %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit2_bn2_gamma: Tensor[(256,), float32], %stage3_unit2_bn2_beta: Tensor[(256,), float32], %stage3_unit2_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn2_moving_var: Tensor[(256,), float32], %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage4_unit1_bn1_gamma: Tensor[(256,), float32], %stage4_unit1_bn1_beta: Tensor[(256,), float32], %stage4_unit1_bn1_moving_mean: Tensor[(256,), float32], %stage4_unit1_bn1_moving_var: Tensor[(256,), float32], %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32], %stage4_unit1_bn2_gamma: Tensor[(512,), float32], %stage4_unit1_bn2_beta: Tensor[(512,), float32], %stage4_unit1_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit1_bn2_moving_var: Tensor[(512,), float32], %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32], %stage4_unit2_bn1_gamma: Tensor[(512,), float32], %stage4_unit2_bn1_beta: Tensor[(512,), float32], %stage4_unit2_bn1_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn1_moving_var: Tensor[(512,), float32], %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit2_bn2_gamma: Tensor[(512,), float32], %stage4_unit2_bn2_beta: Tensor[(512,), float32], %stage4_unit2_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn2_moving_var: Tensor[(512,), float32], %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32], %bn1_gamma: Tensor[(512,), float32], %bn1_beta: Tensor[(512,), float32], %bn1_moving_mean: Tensor[(512,), float32], %bn1_moving_var: Tensor[(512,), float32], %fc1_weight: Tensor[(1000, 512), float32], %fc1_bias: Tensor[(1000,), float32]) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05, scale=False)\n",
      "  %1 = %0.0\n",
      "  %2 = nn.conv2d(%1, %conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7])\n",
      "  %3 = on_device(%2, meta[relay.attrs.OnDeviceAttrs][0])\n",
      "  %4 = device_copy(%3, meta[relay.attrs.DeviceCopyAttrs][0])\n",
      "  %5 = nn.batch_norm(%4, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05)\n",
      "  %6 = %5.0\n",
      "  %7 = nn.relu(%6)\n",
      "  %8 = nn.max_pool2d(%7, pool_size=[3, 3], strides=[2, 2], padding=[1, 1])\n",
      "  %9 = nn.batch_norm(%8, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %10 = %9.0\n",
      "  %11 = nn.relu(%10)\n",
      "  %12 = device_copy(%11, meta[relay.attrs.DeviceCopyAttrs][1])\n",
      "  %13 = nn.conv2d(%12, %stage1_unit1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %14 = on_device(%13, meta[relay.attrs.OnDeviceAttrs][1])\n",
      "  %15 = device_copy(%14, meta[relay.attrs.DeviceCopyAttrs][2])\n",
      "  %16 = nn.batch_norm(%15, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %17 = %16.0\n",
      "  %18 = nn.relu(%17)\n",
      "  %19 = device_copy(%18, meta[relay.attrs.DeviceCopyAttrs][3])\n",
      "  %20 = nn.conv2d(%19, %stage1_unit1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %21 = on_device(%20, meta[relay.attrs.OnDeviceAttrs][2])\n",
      "  %22 = device_copy(%21, meta[relay.attrs.DeviceCopyAttrs][4])\n",
      "  %23 = device_copy(%11, meta[relay.attrs.DeviceCopyAttrs][5])\n",
      "  %24 = nn.conv2d(%23, %stage1_unit1_sc_weight, channels=64, kernel_size=[1, 1])\n",
      "  %25 = on_device(%24, meta[relay.attrs.OnDeviceAttrs][3])\n",
      "  %26 = device_copy(%25, meta[relay.attrs.DeviceCopyAttrs][6])\n",
      "  %27 = add(%22, %26)\n",
      "  %28 = nn.batch_norm(%27, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %29 = %28.0\n",
      "  %30 = nn.relu(%29)\n",
      "  %31 = device_copy(%30, meta[relay.attrs.DeviceCopyAttrs][7])\n",
      "  %32 = nn.conv2d(%31, %stage1_unit2_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %33 = on_device(%32, meta[relay.attrs.OnDeviceAttrs][4])\n",
      "  %34 = device_copy(%33, meta[relay.attrs.DeviceCopyAttrs][8])\n",
      "  %35 = nn.batch_norm(%34, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %36 = %35.0\n",
      "  %37 = nn.relu(%36)\n",
      "  %38 = device_copy(%37, meta[relay.attrs.DeviceCopyAttrs][9])\n",
      "  %39 = nn.conv2d(%38, %stage1_unit2_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %40 = on_device(%39, meta[relay.attrs.OnDeviceAttrs][5])\n",
      "  %41 = device_copy(%40, meta[relay.attrs.DeviceCopyAttrs][10])\n",
      "  %42 = add(%41, %27)\n",
      "  %43 = nn.batch_norm(%42, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %44 = %43.0\n",
      "  %45 = nn.relu(%44)\n",
      "  %46 = device_copy(%45, meta[relay.attrs.DeviceCopyAttrs][11])\n",
      "  %47 = nn.conv2d(%46, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %48 = on_device(%47, meta[relay.attrs.OnDeviceAttrs][6])\n",
      "  %49 = device_copy(%48, meta[relay.attrs.DeviceCopyAttrs][12])\n",
      "  %50 = nn.batch_norm(%49, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %51 = %50.0\n",
      "  %52 = nn.relu(%51)\n",
      "  %53 = device_copy(%52, meta[relay.attrs.DeviceCopyAttrs][13])\n",
      "  %54 = nn.conv2d(%53, %stage2_unit1_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %55 = on_device(%54, meta[relay.attrs.OnDeviceAttrs][7])\n",
      "  %56 = device_copy(%55, meta[relay.attrs.DeviceCopyAttrs][14])\n",
      "  %57 = device_copy(%45, meta[relay.attrs.DeviceCopyAttrs][15])\n",
      "  %58 = nn.conv2d(%57, %stage2_unit1_sc_weight, strides=[2, 2], channels=128, kernel_size=[1, 1])\n",
      "  %59 = on_device(%58, meta[relay.attrs.OnDeviceAttrs][8])\n",
      "  %60 = device_copy(%59, meta[relay.attrs.DeviceCopyAttrs][16])\n",
      "  %61 = add(%56, %60)\n",
      "  %62 = nn.batch_norm(%61, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %63 = %62.0\n",
      "  %64 = nn.relu(%63)\n",
      "  %65 = device_copy(%64, meta[relay.attrs.DeviceCopyAttrs][17])\n",
      "  %66 = nn.conv2d(%65, %stage2_unit2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %67 = on_device(%66, meta[relay.attrs.OnDeviceAttrs][9])\n",
      "  %68 = device_copy(%67, meta[relay.attrs.DeviceCopyAttrs][18])\n",
      "  %69 = nn.batch_norm(%68, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %70 = %69.0\n",
      "  %71 = nn.relu(%70)\n",
      "  %72 = device_copy(%71, meta[relay.attrs.DeviceCopyAttrs][19])\n",
      "  %73 = nn.conv2d(%72, %stage2_unit2_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %74 = on_device(%73, meta[relay.attrs.OnDeviceAttrs][10])\n",
      "  %75 = device_copy(%74, meta[relay.attrs.DeviceCopyAttrs][20])\n",
      "  %76 = add(%75, %61)\n",
      "  %77 = nn.batch_norm(%76, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %78 = %77.0\n",
      "  %79 = nn.relu(%78)\n",
      "  %80 = device_copy(%79, meta[relay.attrs.DeviceCopyAttrs][21])\n",
      "  %81 = nn.conv2d(%80, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %82 = on_device(%81, meta[relay.attrs.OnDeviceAttrs][11])\n",
      "  %83 = device_copy(%82, meta[relay.attrs.DeviceCopyAttrs][22])\n",
      "  %84 = nn.batch_norm(%83, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %85 = %84.0\n",
      "  %86 = nn.relu(%85)\n",
      "  %87 = device_copy(%86, meta[relay.attrs.DeviceCopyAttrs][23])\n",
      "  %88 = nn.conv2d(%87, %stage3_unit1_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %89 = on_device(%88, meta[relay.attrs.OnDeviceAttrs][12])\n",
      "  %90 = device_copy(%89, meta[relay.attrs.DeviceCopyAttrs][24])\n",
      "  %91 = device_copy(%79, meta[relay.attrs.DeviceCopyAttrs][25])\n",
      "  %92 = nn.conv2d(%91, %stage3_unit1_sc_weight, strides=[2, 2], channels=256, kernel_size=[1, 1])\n",
      "  %93 = on_device(%92, meta[relay.attrs.OnDeviceAttrs][13])\n",
      "  %94 = device_copy(%93, meta[relay.attrs.DeviceCopyAttrs][26])\n",
      "  %95 = add(%90, %94)\n",
      "  %96 = nn.batch_norm(%95, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %97 = %96.0\n",
      "  %98 = nn.relu(%97)\n",
      "  %99 = device_copy(%98, meta[relay.attrs.DeviceCopyAttrs][27])\n",
      "  %100 = nn.conv2d(%99, %stage3_unit2_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %101 = on_device(%100, meta[relay.attrs.OnDeviceAttrs][14])\n",
      "  %102 = device_copy(%101, meta[relay.attrs.DeviceCopyAttrs][28])\n",
      "  %103 = nn.batch_norm(%102, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %104 = %103.0\n",
      "  %105 = nn.relu(%104)\n",
      "  %106 = device_copy(%105, meta[relay.attrs.DeviceCopyAttrs][29])\n",
      "  %107 = nn.conv2d(%106, %stage3_unit2_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %108 = on_device(%107, meta[relay.attrs.OnDeviceAttrs][15])\n",
      "  %109 = device_copy(%108, meta[relay.attrs.DeviceCopyAttrs][30])\n",
      "  %110 = add(%109, %95)\n",
      "  %111 = nn.batch_norm(%110, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %112 = %111.0\n",
      "  %113 = nn.relu(%112)\n",
      "  %114 = device_copy(%113, meta[relay.attrs.DeviceCopyAttrs][31])\n",
      "  %115 = nn.conv2d(%114, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %116 = on_device(%115, meta[relay.attrs.OnDeviceAttrs][16])\n",
      "  %117 = device_copy(%116, meta[relay.attrs.DeviceCopyAttrs][32])\n",
      "  %118 = nn.batch_norm(%117, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %119 = %118.0\n",
      "  %120 = nn.relu(%119)\n",
      "  %121 = device_copy(%120, meta[relay.attrs.DeviceCopyAttrs][33])\n",
      "  %122 = nn.conv2d(%121, %stage4_unit1_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %123 = on_device(%122, meta[relay.attrs.OnDeviceAttrs][17])\n",
      "  %124 = device_copy(%123, meta[relay.attrs.DeviceCopyAttrs][34])\n",
      "  %125 = device_copy(%113, meta[relay.attrs.DeviceCopyAttrs][35])\n",
      "  %126 = nn.conv2d(%125, %stage4_unit1_sc_weight, strides=[2, 2], channels=512, kernel_size=[1, 1])\n",
      "  %127 = on_device(%126, meta[relay.attrs.OnDeviceAttrs][18])\n",
      "  %128 = device_copy(%127, meta[relay.attrs.DeviceCopyAttrs][36])\n",
      "  %129 = add(%124, %128)\n",
      "  %130 = nn.batch_norm(%129, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %131 = %130.0\n",
      "  %132 = nn.relu(%131)\n",
      "  %133 = device_copy(%132, meta[relay.attrs.DeviceCopyAttrs][37])\n",
      "  %134 = nn.conv2d(%133, %stage4_unit2_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %135 = on_device(%134, meta[relay.attrs.OnDeviceAttrs][19])\n",
      "  %136 = device_copy(%135, meta[relay.attrs.DeviceCopyAttrs][38])\n",
      "  %137 = nn.batch_norm(%136, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %138 = %137.0\n",
      "  %139 = nn.relu(%138)\n",
      "  %140 = device_copy(%139, meta[relay.attrs.DeviceCopyAttrs][39])\n",
      "  %141 = nn.conv2d(%140, %stage4_unit2_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %142 = on_device(%141, meta[relay.attrs.OnDeviceAttrs][20])\n",
      "  %143 = device_copy(%142, meta[relay.attrs.DeviceCopyAttrs][40])\n",
      "  %144 = add(%143, %129)\n",
      "  %145 = nn.batch_norm(%144, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05)\n",
      "  %146 = %145.0\n",
      "  %147 = nn.relu(%146)\n",
      "  %148 = nn.global_avg_pool2d(%147)\n",
      "  %149 = nn.batch_flatten(%148)\n",
      "  %150 = nn.dense(%149, %fc1_weight, units=1000)\n",
      "  %151 = nn.bias_add(%150, %fc1_bias, axis=-1)\n",
      "  nn.softmax(%151)\n",
      "}\n",
      "// meta data omitted. you can use show_meta_data=True to include meta data\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "import tvm.relay.testing\n",
    "from tvm.relay.expr_functor import ExprMutator\n",
    "\n",
    "class ScheduleConv2d(ExprMutator):\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        super().__init__()\n",
    "\n",
    "    def visit_call(self, expr):\n",
    "        visit = super().visit_call(expr)\n",
    "        if expr.op == tvm.relay.op.get(\"nn.conv2d\"):\n",
    "            return relay.annotation.on_device(visit, self.device)\n",
    "        else:\n",
    "            return visit\n",
    "\n",
    "def schedule_conv2d_on_gpu(expr):\n",
    "    sched = ScheduleConv2d(tvm.gpu(0))\n",
    "    return sched.visit(expr)\n",
    "\n",
    "# TODO(@jroesch): use pass manager\n",
    "resnet, params = relay.testing.resnet.get_workload()\n",
    "print(resnet)\n",
    "resnet = schedule_conv2d_on_gpu(resnet)\n",
    "print(resnet)\n",
    "resnet = relay.ir_pass.rewrite_annotated_ops(resnet, 0)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
