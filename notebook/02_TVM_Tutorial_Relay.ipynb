{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeiRi-zc0NuZ"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/02_TVM_Tutorial_Relay.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYNJGUSR0Nub"
   },
   "source": [
    "Please run the following block to ensure TVM is setup for *this notebook*, each notebook may have its own runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "id": "bdiA6WVx0Nuc",
    "outputId": "949d0040-80a4-43e5-b1e9-04445c3307c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook executing locally, skipping Colab setup ...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    ! gsutil cp \"gs://tvm-fcrc-binariesd5fce43e-8373-11e9-bfb6-0242ac1c0002/tvm.tar.gz\" /tmp/tvm.tar.gz\n",
    "    ! mkdir -p /tvm\n",
    "    ! tar -xf /tmp/tvm.tar.gz --strip-components=4 --directory /tvm\n",
    "    ! ls -la /tvm\n",
    "    ! bash /tvm/package.sh\n",
    "    # Add TVM to the Python path.\n",
    "    import sys\n",
    "    sys.path.append('/tvm/python')\n",
    "    sys.path.append('/tvm/topi/python')\n",
    "    sys.path.append('/tvm/vta/python')\n",
    "else:\n",
    "    print(\"Notebook executing locally, skipping Colab setup ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Jg5xV0v0Nuh"
   },
   "source": [
    "# Relay: an Extensible Deep Learning IR\n",
    "\n",
    "Last year TVM introduced Relay IR â€“ a second generation high-level IR for deep learning. \n",
    "\n",
    "Relay's design comes from a simple insight that the critical difference between regular IRs\n",
    "and deep learning IRs are the primitive values they manipulate. Relay is designed using well\n",
    "known insights from the programming languages community coupled with TVM's existing \n",
    "infrastructure to provide state of the art performance. \n",
    "\n",
    "If you are familiar with ideas from programming languages or existing computation graph\n",
    "representations we will connect Relay to your existing knowledge during this tutorial.\n",
    "\n",
    "We will first cover the design of Relay, then elaborate on how one can use it to \n",
    "accomplish a wide variety of tasks. This piece of the tutorial focused directly \n",
    "on Relay but Relay will be present throughout all of the content today, and serves\n",
    "as the interface layer to TVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "import tvm.relay.testing\n",
    "from tvm.relay.expr_functor import ExprMutator\n",
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language \n",
    "\n",
    "We will briefly introduce the concepts of Relay below before showing how to use Relay to accomplish specific tasks.\n",
    "You can find a full language specification [here](https://docs.tvm.ai/langref/index.html).\n",
    "\n",
    "### Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single Relay variable, the string is just a hint\n",
    "x = relay.var('x')\n",
    "\n",
    "# A Relay variable with a different dtype, defaults to float32.\n",
    "x = relay.var('x', dtype='int32')\n",
    "\n",
    "# A Relay variable with a different shape.\n",
    "x = relay.var('x', shape=(10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "\n",
    "Relay provides high performance operators defined in TVM that implement the primitive operations needed by deep learning applications. Operators can be applied to arguments just like regular Python or C++ functions. Common arithemetic operations are provided both via names and operator overloading.\n",
    "\n",
    "Variables can be used to construct Relay *expressions* which replace the concept of graphs present in previous frameworks. A Relay expression can be viewed much like a graph with extra functionality as we will see as we go\n",
    "forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "free_var %x: Tensor[(10, 1), float32]\n",
      "add(%x, %x)\n"
     ]
    }
   ],
   "source": [
    "w = relay.op.add(x, x)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "free_var %x: Tensor[(10, 1), float32]\n",
      "add(%x, %x)\n"
     ]
    }
   ],
   "source": [
    "z = x + x\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "The fundamental packaging of computation in Relay is the function. A function is a combination of a set of inputs,\n",
    "and a Relay expression. One view is a function is no different than the ones in programming languages today, and another is that it replaces named subgraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%x: Tensor[(10, 1), float32]) {\n",
      "  add(%x, %x)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "f = relay.Function([x], z)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module\n",
    "\n",
    "Finally we can give functions a global name and package many of them together into a module. When we add a function to the module, it will be type checked before hand.\n",
    "\n",
    "When we print the module you can see the program annotated with all type information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "def @f(%x: Tensor[(10, 1), float32]) -> Tensor[(10, 1), float32] {\n",
      "  add(%x, %x) /* ty=Tensor[(10, 1), float32] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = relay.Module({})\n",
    "fname = relay.GlobalVar('f')\n",
    "mod[fname] = f\n",
    "\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontends\n",
    "\n",
    "Relay comes with a variety of frontends and supports most major frameworks including TensorFlow, PyTorch, MxNet, ONNX, Keras and Caffe2.\n",
    "\n",
    "Below we provide a couple examples of using these frontends to import models into Relay.\n",
    "\n",
    "You can find specific tutorials on deploying pretrained models below:  \n",
    "\n",
    "- [ONNX](https://docs.tvm.ai/tutorials/frontend/from_onnx.html#sphx-glr-tutorials-frontend-from-onnx-py)\n",
    "- [TensorFlow](https://docs.tvm.ai/tutorials/frontend/from_tensorflow.html#sphx-glr-tutorials-frontend-from-tensorflow-py)\n",
    "- [Keras](https://docs.tvm.ai/tutorials/frontend/from_keras.html#sphx-glr-tutorials-frontend-from-keras-py)\n",
    "- [PyTorch](https://tvm.ai/2019/05/30/pytorch-frontend)\n",
    "- [Caffe2](https://docs.tvm.ai/tutorials/frontend/from_caffe2.html#sphx-glr-tutorials-frontend-from-caffe2-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(10, 3, 224, 224),\n",
      "      %conv1.weight : Float(64, 3, 7, 7),\n",
      "      %bn1.weight : Float(64),\n",
      "      %bn1.bias : Float(64),\n",
      "      %bn1.running_mean : Float(64),\n",
      "      %bn1.running_var : Float(64),\n",
      "      %bn1.num_batches_tracked : Long(),\n",
      "      %layer1.0.conv1.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.0.bn1.weight : Float(64),\n",
      "      %layer1.0.bn1.bias : Float(64),\n",
      "      %layer1.0.bn1.running_mean : Float(64),\n",
      "      %layer1.0.bn1.running_var : Float(64),\n",
      "      %layer1.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer1.0.conv2.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.0.bn2.weight : Float(64),\n",
      "      %layer1.0.bn2.bias : Float(64),\n",
      "      %layer1.0.bn2.running_mean : Float(64),\n",
      "      %layer1.0.bn2.running_var : Float(64),\n",
      "      %layer1.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer1.1.conv1.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.1.bn1.weight : Float(64),\n",
      "      %layer1.1.bn1.bias : Float(64),\n",
      "      %layer1.1.bn1.running_mean : Float(64),\n",
      "      %layer1.1.bn1.running_var : Float(64),\n",
      "      %layer1.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer1.1.conv2.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.1.bn2.weight : Float(64),\n",
      "      %layer1.1.bn2.bias : Float(64),\n",
      "      %layer1.1.bn2.running_mean : Float(64),\n",
      "      %layer1.1.bn2.running_var : Float(64),\n",
      "      %layer1.1.bn2.num_batches_tracked : Long(),\n",
      "      %layer2.0.conv1.weight : Float(128, 64, 3, 3),\n",
      "      %layer2.0.bn1.weight : Float(128),\n",
      "      %layer2.0.bn1.bias : Float(128),\n",
      "      %layer2.0.bn1.running_mean : Float(128),\n",
      "      %layer2.0.bn1.running_var : Float(128),\n",
      "      %layer2.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer2.0.conv2.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.0.bn2.weight : Float(128),\n",
      "      %layer2.0.bn2.bias : Float(128),\n",
      "      %layer2.0.bn2.running_mean : Float(128),\n",
      "      %layer2.0.bn2.running_var : Float(128),\n",
      "      %layer2.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer2.0.downsample.0.weight : Float(128, 64, 1, 1),\n",
      "      %layer2.0.downsample.1.weight : Float(128),\n",
      "      %layer2.0.downsample.1.bias : Float(128),\n",
      "      %layer2.0.downsample.1.running_mean : Float(128),\n",
      "      %layer2.0.downsample.1.running_var : Float(128),\n",
      "      %layer2.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %layer2.1.conv1.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.1.bn1.weight : Float(128),\n",
      "      %layer2.1.bn1.bias : Float(128),\n",
      "      %layer2.1.bn1.running_mean : Float(128),\n",
      "      %layer2.1.bn1.running_var : Float(128),\n",
      "      %layer2.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer2.1.conv2.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.1.bn2.weight : Float(128),\n",
      "      %layer2.1.bn2.bias : Float(128),\n",
      "      %layer2.1.bn2.running_mean : Float(128),\n",
      "      %layer2.1.bn2.running_var : Float(128),\n",
      "      %layer2.1.bn2.num_batches_tracked : Long(),\n",
      "      %layer3.0.conv1.weight : Float(256, 128, 3, 3),\n",
      "      %layer3.0.bn1.weight : Float(256),\n",
      "      %layer3.0.bn1.bias : Float(256),\n",
      "      %layer3.0.bn1.running_mean : Float(256),\n",
      "      %layer3.0.bn1.running_var : Float(256),\n",
      "      %layer3.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer3.0.conv2.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.0.bn2.weight : Float(256),\n",
      "      %layer3.0.bn2.bias : Float(256),\n",
      "      %layer3.0.bn2.running_mean : Float(256),\n",
      "      %layer3.0.bn2.running_var : Float(256),\n",
      "      %layer3.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer3.0.downsample.0.weight : Float(256, 128, 1, 1),\n",
      "      %layer3.0.downsample.1.weight : Float(256),\n",
      "      %layer3.0.downsample.1.bias : Float(256),\n",
      "      %layer3.0.downsample.1.running_mean : Float(256),\n",
      "      %layer3.0.downsample.1.running_var : Float(256),\n",
      "      %layer3.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %layer3.1.conv1.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.1.bn1.weight : Float(256),\n",
      "      %layer3.1.bn1.bias : Float(256),\n",
      "      %layer3.1.bn1.running_mean : Float(256),\n",
      "      %layer3.1.bn1.running_var : Float(256),\n",
      "      %layer3.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer3.1.conv2.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.1.bn2.weight : Float(256),\n",
      "      %layer3.1.bn2.bias : Float(256),\n",
      "      %layer3.1.bn2.running_mean : Float(256),\n",
      "      %layer3.1.bn2.running_var : Float(256),\n",
      "      %layer3.1.bn2.num_batches_tracked : Long(),\n",
      "      %layer4.0.conv1.weight : Float(512, 256, 3, 3),\n",
      "      %layer4.0.bn1.weight : Float(512),\n",
      "      %layer4.0.bn1.bias : Float(512),\n",
      "      %layer4.0.bn1.running_mean : Float(512),\n",
      "      %layer4.0.bn1.running_var : Float(512),\n",
      "      %layer4.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer4.0.conv2.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.0.bn2.weight : Float(512),\n",
      "      %layer4.0.bn2.bias : Float(512),\n",
      "      %layer4.0.bn2.running_mean : Float(512),\n",
      "      %layer4.0.bn2.running_var : Float(512),\n",
      "      %layer4.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer4.0.downsample.0.weight : Float(512, 256, 1, 1),\n",
      "      %layer4.0.downsample.1.weight : Float(512),\n",
      "      %layer4.0.downsample.1.bias : Float(512),\n",
      "      %layer4.0.downsample.1.running_mean : Float(512),\n",
      "      %layer4.0.downsample.1.running_var : Float(512),\n",
      "      %layer4.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %layer4.1.conv1.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.1.bn1.weight : Float(512),\n",
      "      %layer4.1.bn1.bias : Float(512),\n",
      "      %layer4.1.bn1.running_mean : Float(512),\n",
      "      %layer4.1.bn1.running_var : Float(512),\n",
      "      %layer4.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer4.1.conv2.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.1.bn2.weight : Float(512),\n",
      "      %layer4.1.bn2.bias : Float(512),\n",
      "      %layer4.1.bn2.running_mean : Float(512),\n",
      "      %layer4.1.bn2.running_var : Float(512),\n",
      "      %layer4.1.bn2.num_batches_tracked : Long(),\n",
      "      %fc.weight : Float(1000, 512),\n",
      "      %fc.bias : Float(1000)):\n",
      "  %123 : Float(10, 64, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%0, %conv1.weight), scope: ResNet/Conv2d[conv1]\n",
      "  %124 : Float(10, 64, 112, 112) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%123, %bn1.weight, %bn1.bias, %bn1.running_mean, %bn1.running_var), scope: ResNet/BatchNorm2d[bn1]\n",
      "  %125 : Float(10, 64, 112, 112) = onnx::Relu(%124), scope: ResNet/ReLU[relu]\n",
      "  %126 : Float(10, 64, 56, 56) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%125), scope: ResNet/MaxPool2d[maxpool]\n",
      "  %127 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %layer1.0.conv1.weight), scope: ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %128 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%127, %layer1.0.bn1.weight, %layer1.0.bn1.bias, %layer1.0.bn1.running_mean, %layer1.0.bn1.running_var), scope: ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %129 : Float(10, 64, 56, 56) = onnx::Relu(%128), scope: ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]\n",
      "  %130 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%129, %layer1.0.conv2.weight), scope: ResNet/Sequential[layer1]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %131 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%130, %layer1.0.bn2.weight, %layer1.0.bn2.bias, %layer1.0.bn2.running_mean, %layer1.0.bn2.running_var), scope: ResNet/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %132 : Float(10, 64, 56, 56) = onnx::Add(%131, %126), scope: ResNet/Sequential[layer1]/BasicBlock[0]\n",
      "  %133 : Float(10, 64, 56, 56) = onnx::Relu(%132), scope: ResNet/Sequential[layer1]/BasicBlock[0]/ReLU[relu]\n",
      "  %134 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%133, %layer1.1.conv1.weight), scope: ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %135 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%134, %layer1.1.bn1.weight, %layer1.1.bn1.bias, %layer1.1.bn1.running_mean, %layer1.1.bn1.running_var), scope: ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %136 : Float(10, 64, 56, 56) = onnx::Relu(%135), scope: ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]\n",
      "  %137 : Float(10, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%136, %layer1.1.conv2.weight), scope: ResNet/Sequential[layer1]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %138 : Float(10, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%137, %layer1.1.bn2.weight, %layer1.1.bn2.bias, %layer1.1.bn2.running_mean, %layer1.1.bn2.running_var), scope: ResNet/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %139 : Float(10, 64, 56, 56) = onnx::Add(%138, %133), scope: ResNet/Sequential[layer1]/BasicBlock[1]\n",
      "  %140 : Float(10, 64, 56, 56) = onnx::Relu(%139), scope: ResNet/Sequential[layer1]/BasicBlock[1]/ReLU[relu]\n",
      "  %141 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%140, %layer2.0.conv1.weight), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %142 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%141, %layer2.0.bn1.weight, %layer2.0.bn1.bias, %layer2.0.bn1.running_mean, %layer2.0.bn1.running_var), scope: ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %143 : Float(10, 128, 28, 28) = onnx::Relu(%142), scope: ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]\n",
      "  %144 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %layer2.0.conv2.weight), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %145 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%144, %layer2.0.bn2.weight, %layer2.0.bn2.bias, %layer2.0.bn2.running_mean, %layer2.0.bn2.running_var), scope: ResNet/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %146 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%140, %layer2.0.downsample.0.weight), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %147 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%146, %layer2.0.downsample.1.weight, %layer2.0.downsample.1.bias, %layer2.0.downsample.1.running_mean, %layer2.0.downsample.1.running_var), scope: ResNet/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %148 : Float(10, 128, 28, 28) = onnx::Add(%145, %147), scope: ResNet/Sequential[layer2]/BasicBlock[0]\n",
      "  %149 : Float(10, 128, 28, 28) = onnx::Relu(%148), scope: ResNet/Sequential[layer2]/BasicBlock[0]/ReLU[relu]\n",
      "  %150 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %layer2.1.conv1.weight), scope: ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %151 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%150, %layer2.1.bn1.weight, %layer2.1.bn1.bias, %layer2.1.bn1.running_mean, %layer2.1.bn1.running_var), scope: ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %152 : Float(10, 128, 28, 28) = onnx::Relu(%151), scope: ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]\n",
      "  %153 : Float(10, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %layer2.1.conv2.weight), scope: ResNet/Sequential[layer2]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %154 : Float(10, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%153, %layer2.1.bn2.weight, %layer2.1.bn2.bias, %layer2.1.bn2.running_mean, %layer2.1.bn2.running_var), scope: ResNet/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %155 : Float(10, 128, 28, 28) = onnx::Add(%154, %149), scope: ResNet/Sequential[layer2]/BasicBlock[1]\n",
      "  %156 : Float(10, 128, 28, 28) = onnx::Relu(%155), scope: ResNet/Sequential[layer2]/BasicBlock[1]/ReLU[relu]\n",
      "  %157 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%156, %layer3.0.conv1.weight), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %158 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%157, %layer3.0.bn1.weight, %layer3.0.bn1.bias, %layer3.0.bn1.running_mean, %layer3.0.bn1.running_var), scope: ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %159 : Float(10, 256, 14, 14) = onnx::Relu(%158), scope: ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]\n",
      "  %160 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%159, %layer3.0.conv2.weight), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %161 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%160, %layer3.0.bn2.weight, %layer3.0.bn2.bias, %layer3.0.bn2.running_mean, %layer3.0.bn2.running_var), scope: ResNet/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %162 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%156, %layer3.0.downsample.0.weight), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %163 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%162, %layer3.0.downsample.1.weight, %layer3.0.downsample.1.bias, %layer3.0.downsample.1.running_mean, %layer3.0.downsample.1.running_var), scope: ResNet/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %164 : Float(10, 256, 14, 14) = onnx::Add(%161, %163), scope: ResNet/Sequential[layer3]/BasicBlock[0]\n",
      "  %165 : Float(10, 256, 14, 14) = onnx::Relu(%164), scope: ResNet/Sequential[layer3]/BasicBlock[0]/ReLU[relu]\n",
      "  %166 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %layer3.1.conv1.weight), scope: ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %167 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%166, %layer3.1.bn1.weight, %layer3.1.bn1.bias, %layer3.1.bn1.running_mean, %layer3.1.bn1.running_var), scope: ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %168 : Float(10, 256, 14, 14) = onnx::Relu(%167), scope: ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]\n",
      "  %169 : Float(10, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%168, %layer3.1.conv2.weight), scope: ResNet/Sequential[layer3]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %170 : Float(10, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%169, %layer3.1.bn2.weight, %layer3.1.bn2.bias, %layer3.1.bn2.running_mean, %layer3.1.bn2.running_var), scope: ResNet/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %171 : Float(10, 256, 14, 14) = onnx::Add(%170, %165), scope: ResNet/Sequential[layer3]/BasicBlock[1]\n",
      "  %172 : Float(10, 256, 14, 14) = onnx::Relu(%171), scope: ResNet/Sequential[layer3]/BasicBlock[1]/ReLU[relu]\n",
      "  %173 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%172, %layer4.0.conv1.weight), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %174 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%173, %layer4.0.bn1.weight, %layer4.0.bn1.bias, %layer4.0.bn1.running_mean, %layer4.0.bn1.running_var), scope: ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %175 : Float(10, 512, 7, 7) = onnx::Relu(%174), scope: ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]\n",
      "  %176 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%175, %layer4.0.conv2.weight), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %177 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%176, %layer4.0.bn2.weight, %layer4.0.bn2.bias, %layer4.0.bn2.running_mean, %layer4.0.bn2.running_var), scope: ResNet/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %178 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%172, %layer4.0.downsample.0.weight), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %179 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%178, %layer4.0.downsample.1.weight, %layer4.0.downsample.1.bias, %layer4.0.downsample.1.running_mean, %layer4.0.downsample.1.running_var), scope: ResNet/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %180 : Float(10, 512, 7, 7) = onnx::Add(%177, %179), scope: ResNet/Sequential[layer4]/BasicBlock[0]\n",
      "  %181 : Float(10, 512, 7, 7) = onnx::Relu(%180), scope: ResNet/Sequential[layer4]/BasicBlock[0]/ReLU[relu]\n",
      "  %182 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%181, %layer4.1.conv1.weight), scope: ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %183 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%182, %layer4.1.bn1.weight, %layer4.1.bn1.bias, %layer4.1.bn1.running_mean, %layer4.1.bn1.running_var), scope: ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %184 : Float(10, 512, 7, 7) = onnx::Relu(%183), scope: ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]\n",
      "  %185 : Float(10, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%184, %layer4.1.conv2.weight), scope: ResNet/Sequential[layer4]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %186 : Float(10, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%185, %layer4.1.bn2.weight, %layer4.1.bn2.bias, %layer4.1.bn2.running_mean, %layer4.1.bn2.running_var), scope: ResNet/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %187 : Float(10, 512, 7, 7) = onnx::Add(%186, %181), scope: ResNet/Sequential[layer4]/BasicBlock[1]\n",
      "  %188 : Float(10, 512, 7, 7) = onnx::Relu(%187), scope: ResNet/Sequential[layer4]/BasicBlock[1]/ReLU[relu]\n",
      "  %189 : Float(10, 512, 1, 1) = onnx::GlobalAveragePool(%188), scope: ResNet/AdaptiveAvgPool2d[avgpool]\n",
      "  %190 : Long() = onnx::Constant[value={0}](), scope: ResNet\n",
      "  %191 : Tensor = onnx::Shape(%189), scope: ResNet\n",
      "  %192 : Long() = onnx::Gather[axis=0](%191, %190), scope: ResNet\n",
      "  %193 : Long() = onnx::Constant[value={-1}](), scope: ResNet\n",
      "  %194 : Tensor = onnx::Unsqueeze[axes=[0]](%192)\n",
      "  %195 : Tensor = onnx::Unsqueeze[axes=[0]](%193)\n",
      "  %196 : Tensor = onnx::Concat[axis=0](%194, %195)\n",
      "  %197 : Float(10, 512) = onnx::Reshape(%189, %196), scope: ResNet\n",
      "  %198 : Float(10, 1000) = onnx::Gemm[alpha=1, beta=1, transB=1](%197, %fc.weight, %fc.bias), scope: ResNet/Linear[fc]\n",
      "  return (%198)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute momentum is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Constant evaluating Reshape's shape argument, may reduce performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%v0: Tensor[(10, 3, 224, 224), float32], %conv1.weight: Tensor[(64, 3, 7, 7), float32], %bn1.weight: Tensor[(64,), float32], %bn1.bias: Tensor[(64,), float32], %bn1.running_mean: Tensor[(64,), float32], %bn1.running_var: Tensor[(64,), float32], %layer1.0.conv1.weight: Tensor[(64, 64, 3, 3), float32], %layer1.0.bn1.weight: Tensor[(64,), float32], %layer1.0.bn1.bias: Tensor[(64,), float32], %layer1.0.bn1.running_mean: Tensor[(64,), float32], %layer1.0.bn1.running_var: Tensor[(64,), float32], %layer1.0.conv2.weight: Tensor[(64, 64, 3, 3), float32], %layer1.0.bn2.weight: Tensor[(64,), float32], %layer1.0.bn2.bias: Tensor[(64,), float32], %layer1.0.bn2.running_mean: Tensor[(64,), float32], %layer1.0.bn2.running_var: Tensor[(64,), float32], %layer1.1.conv1.weight: Tensor[(64, 64, 3, 3), float32], %layer1.1.bn1.weight: Tensor[(64,), float32], %layer1.1.bn1.bias: Tensor[(64,), float32], %layer1.1.bn1.running_mean: Tensor[(64,), float32], %layer1.1.bn1.running_var: Tensor[(64,), float32], %layer1.1.conv2.weight: Tensor[(64, 64, 3, 3), float32], %layer1.1.bn2.weight: Tensor[(64,), float32], %layer1.1.bn2.bias: Tensor[(64,), float32], %layer1.1.bn2.running_mean: Tensor[(64,), float32], %layer1.1.bn2.running_var: Tensor[(64,), float32], %layer2.0.conv1.weight: Tensor[(128, 64, 3, 3), float32], %layer2.0.bn1.weight: Tensor[(128,), float32], %layer2.0.bn1.bias: Tensor[(128,), float32], %layer2.0.bn1.running_mean: Tensor[(128,), float32], %layer2.0.bn1.running_var: Tensor[(128,), float32], %layer2.0.conv2.weight: Tensor[(128, 128, 3, 3), float32], %layer2.0.bn2.weight: Tensor[(128,), float32], %layer2.0.bn2.bias: Tensor[(128,), float32], %layer2.0.bn2.running_mean: Tensor[(128,), float32], %layer2.0.bn2.running_var: Tensor[(128,), float32], %layer2.0.downsample.0.weight: Tensor[(128, 64, 1, 1), float32], %layer2.0.downsample.1.weight: Tensor[(128,), float32], %layer2.0.downsample.1.bias: Tensor[(128,), float32], %layer2.0.downsample.1.running_mean: Tensor[(128,), float32], %layer2.0.downsample.1.running_var: Tensor[(128,), float32], %layer2.1.conv1.weight: Tensor[(128, 128, 3, 3), float32], %layer2.1.bn1.weight: Tensor[(128,), float32], %layer2.1.bn1.bias: Tensor[(128,), float32], %layer2.1.bn1.running_mean: Tensor[(128,), float32], %layer2.1.bn1.running_var: Tensor[(128,), float32], %layer2.1.conv2.weight: Tensor[(128, 128, 3, 3), float32], %layer2.1.bn2.weight: Tensor[(128,), float32], %layer2.1.bn2.bias: Tensor[(128,), float32], %layer2.1.bn2.running_mean: Tensor[(128,), float32], %layer2.1.bn2.running_var: Tensor[(128,), float32], %layer3.0.conv1.weight: Tensor[(256, 128, 3, 3), float32], %layer3.0.bn1.weight: Tensor[(256,), float32], %layer3.0.bn1.bias: Tensor[(256,), float32], %layer3.0.bn1.running_mean: Tensor[(256,), float32], %layer3.0.bn1.running_var: Tensor[(256,), float32], %layer3.0.conv2.weight: Tensor[(256, 256, 3, 3), float32], %layer3.0.bn2.weight: Tensor[(256,), float32], %layer3.0.bn2.bias: Tensor[(256,), float32], %layer3.0.bn2.running_mean: Tensor[(256,), float32], %layer3.0.bn2.running_var: Tensor[(256,), float32], %layer3.0.downsample.0.weight: Tensor[(256, 128, 1, 1), float32], %layer3.0.downsample.1.weight: Tensor[(256,), float32], %layer3.0.downsample.1.bias: Tensor[(256,), float32], %layer3.0.downsample.1.running_mean: Tensor[(256,), float32], %layer3.0.downsample.1.running_var: Tensor[(256,), float32], %layer3.1.conv1.weight: Tensor[(256, 256, 3, 3), float32], %layer3.1.bn1.weight: Tensor[(256,), float32], %layer3.1.bn1.bias: Tensor[(256,), float32], %layer3.1.bn1.running_mean: Tensor[(256,), float32], %layer3.1.bn1.running_var: Tensor[(256,), float32], %layer3.1.conv2.weight: Tensor[(256, 256, 3, 3), float32], %layer3.1.bn2.weight: Tensor[(256,), float32], %layer3.1.bn2.bias: Tensor[(256,), float32], %layer3.1.bn2.running_mean: Tensor[(256,), float32], %layer3.1.bn2.running_var: Tensor[(256,), float32], %layer4.0.conv1.weight: Tensor[(512, 256, 3, 3), float32], %layer4.0.bn1.weight: Tensor[(512,), float32], %layer4.0.bn1.bias: Tensor[(512,), float32], %layer4.0.bn1.running_mean: Tensor[(512,), float32], %layer4.0.bn1.running_var: Tensor[(512,), float32], %layer4.0.conv2.weight: Tensor[(512, 512, 3, 3), float32], %layer4.0.bn2.weight: Tensor[(512,), float32], %layer4.0.bn2.bias: Tensor[(512,), float32], %layer4.0.bn2.running_mean: Tensor[(512,), float32], %layer4.0.bn2.running_var: Tensor[(512,), float32], %layer4.0.downsample.0.weight: Tensor[(512, 256, 1, 1), float32], %layer4.0.downsample.1.weight: Tensor[(512,), float32], %layer4.0.downsample.1.bias: Tensor[(512,), float32], %layer4.0.downsample.1.running_mean: Tensor[(512,), float32], %layer4.0.downsample.1.running_var: Tensor[(512,), float32], %layer4.1.conv1.weight: Tensor[(512, 512, 3, 3), float32], %layer4.1.bn1.weight: Tensor[(512,), float32], %layer4.1.bn1.bias: Tensor[(512,), float32], %layer4.1.bn1.running_mean: Tensor[(512,), float32], %layer4.1.bn1.running_var: Tensor[(512,), float32], %layer4.1.conv2.weight: Tensor[(512, 512, 3, 3), float32], %layer4.1.bn2.weight: Tensor[(512,), float32], %layer4.1.bn2.bias: Tensor[(512,), float32], %layer4.1.bn2.running_mean: Tensor[(512,), float32], %layer4.1.bn2.running_var: Tensor[(512,), float32], %fc.weight: Tensor[(1000, 512), float32], %fc.bias: Tensor[(1000,), float32]) {\n",
      "  %0 = nn.conv2d(%v0, %conv1.weight, strides=[2, 2], padding=[3, 3], kernel_size=[7, 7])\n",
      "  %1 = nn.batch_norm(%0, %bn1.weight, %bn1.bias, %bn1.running_mean, %bn1.running_var, epsilon=1e-05)\n",
      "  %2 = %1.0\n",
      "  %3 = nn.relu(%2)\n",
      "  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1])\n",
      "  %5 = nn.conv2d(%4, %layer1.0.conv1.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %6 = nn.batch_norm(%5, %layer1.0.bn1.weight, %layer1.0.bn1.bias, %layer1.0.bn1.running_mean, %layer1.0.bn1.running_var, epsilon=1e-05)\n",
      "  %7 = %6.0\n",
      "  %8 = nn.relu(%7)\n",
      "  %9 = nn.conv2d(%8, %layer1.0.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %10 = nn.batch_norm(%9, %layer1.0.bn2.weight, %layer1.0.bn2.bias, %layer1.0.bn2.running_mean, %layer1.0.bn2.running_var, epsilon=1e-05)\n",
      "  %11 = %10.0\n",
      "  %12 = add(%11, %4)\n",
      "  %13 = nn.relu(%12)\n",
      "  %14 = nn.conv2d(%13, %layer1.1.conv1.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %15 = nn.batch_norm(%14, %layer1.1.bn1.weight, %layer1.1.bn1.bias, %layer1.1.bn1.running_mean, %layer1.1.bn1.running_var, epsilon=1e-05)\n",
      "  %16 = %15.0\n",
      "  %17 = nn.relu(%16)\n",
      "  %18 = nn.conv2d(%17, %layer1.1.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %19 = nn.batch_norm(%18, %layer1.1.bn2.weight, %layer1.1.bn2.bias, %layer1.1.bn2.running_mean, %layer1.1.bn2.running_var, epsilon=1e-05)\n",
      "  %20 = %19.0\n",
      "  %21 = add(%20, %13)\n",
      "  %22 = nn.relu(%21)\n",
      "  %23 = nn.conv2d(%22, %layer2.0.conv1.weight, strides=[2, 2], padding=[1, 1], kernel_size=[3, 3])\n",
      "  %24 = nn.batch_norm(%23, %layer2.0.bn1.weight, %layer2.0.bn1.bias, %layer2.0.bn1.running_mean, %layer2.0.bn1.running_var, epsilon=1e-05)\n",
      "  %25 = %24.0\n",
      "  %26 = nn.relu(%25)\n",
      "  %27 = nn.conv2d(%26, %layer2.0.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %28 = nn.batch_norm(%27, %layer2.0.bn2.weight, %layer2.0.bn2.bias, %layer2.0.bn2.running_mean, %layer2.0.bn2.running_var, epsilon=1e-05)\n",
      "  %29 = %28.0\n",
      "  %30 = nn.conv2d(%22, %layer2.0.downsample.0.weight, strides=[2, 2], kernel_size=[1, 1])\n",
      "  %31 = nn.batch_norm(%30, %layer2.0.downsample.1.weight, %layer2.0.downsample.1.bias, %layer2.0.downsample.1.running_mean, %layer2.0.downsample.1.running_var, epsilon=1e-05)\n",
      "  %32 = %31.0\n",
      "  %33 = add(%29, %32)\n",
      "  %34 = nn.relu(%33)\n",
      "  %35 = nn.conv2d(%34, %layer2.1.conv1.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %36 = nn.batch_norm(%35, %layer2.1.bn1.weight, %layer2.1.bn1.bias, %layer2.1.bn1.running_mean, %layer2.1.bn1.running_var, epsilon=1e-05)\n",
      "  %37 = %36.0\n",
      "  %38 = nn.relu(%37)\n",
      "  %39 = nn.conv2d(%38, %layer2.1.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %40 = nn.batch_norm(%39, %layer2.1.bn2.weight, %layer2.1.bn2.bias, %layer2.1.bn2.running_mean, %layer2.1.bn2.running_var, epsilon=1e-05)\n",
      "  %41 = %40.0\n",
      "  %42 = add(%41, %34)\n",
      "  %43 = nn.relu(%42)\n",
      "  %44 = nn.conv2d(%43, %layer3.0.conv1.weight, strides=[2, 2], padding=[1, 1], kernel_size=[3, 3])\n",
      "  %45 = nn.batch_norm(%44, %layer3.0.bn1.weight, %layer3.0.bn1.bias, %layer3.0.bn1.running_mean, %layer3.0.bn1.running_var, epsilon=1e-05)\n",
      "  %46 = %45.0\n",
      "  %47 = nn.relu(%46)\n",
      "  %48 = nn.conv2d(%47, %layer3.0.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %49 = nn.batch_norm(%48, %layer3.0.bn2.weight, %layer3.0.bn2.bias, %layer3.0.bn2.running_mean, %layer3.0.bn2.running_var, epsilon=1e-05)\n",
      "  %50 = %49.0\n",
      "  %51 = nn.conv2d(%43, %layer3.0.downsample.0.weight, strides=[2, 2], kernel_size=[1, 1])\n",
      "  %52 = nn.batch_norm(%51, %layer3.0.downsample.1.weight, %layer3.0.downsample.1.bias, %layer3.0.downsample.1.running_mean, %layer3.0.downsample.1.running_var, epsilon=1e-05)\n",
      "  %53 = %52.0\n",
      "  %54 = add(%50, %53)\n",
      "  %55 = nn.relu(%54)\n",
      "  %56 = nn.conv2d(%55, %layer3.1.conv1.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %57 = nn.batch_norm(%56, %layer3.1.bn1.weight, %layer3.1.bn1.bias, %layer3.1.bn1.running_mean, %layer3.1.bn1.running_var, epsilon=1e-05)\n",
      "  %58 = %57.0\n",
      "  %59 = nn.relu(%58)\n",
      "  %60 = nn.conv2d(%59, %layer3.1.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %61 = nn.batch_norm(%60, %layer3.1.bn2.weight, %layer3.1.bn2.bias, %layer3.1.bn2.running_mean, %layer3.1.bn2.running_var, epsilon=1e-05)\n",
      "  %62 = %61.0\n",
      "  %63 = add(%62, %55)\n",
      "  %64 = nn.relu(%63)\n",
      "  %65 = nn.conv2d(%64, %layer4.0.conv1.weight, strides=[2, 2], padding=[1, 1], kernel_size=[3, 3])\n",
      "  %66 = nn.batch_norm(%65, %layer4.0.bn1.weight, %layer4.0.bn1.bias, %layer4.0.bn1.running_mean, %layer4.0.bn1.running_var, epsilon=1e-05)\n",
      "  %67 = %66.0\n",
      "  %68 = nn.relu(%67)\n",
      "  %69 = nn.conv2d(%68, %layer4.0.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %70 = nn.batch_norm(%69, %layer4.0.bn2.weight, %layer4.0.bn2.bias, %layer4.0.bn2.running_mean, %layer4.0.bn2.running_var, epsilon=1e-05)\n",
      "  %71 = %70.0\n",
      "  %72 = nn.conv2d(%64, %layer4.0.downsample.0.weight, strides=[2, 2], kernel_size=[1, 1])\n",
      "  %73 = nn.batch_norm(%72, %layer4.0.downsample.1.weight, %layer4.0.downsample.1.bias, %layer4.0.downsample.1.running_mean, %layer4.0.downsample.1.running_var, epsilon=1e-05)\n",
      "  %74 = %73.0\n",
      "  %75 = add(%71, %74)\n",
      "  %76 = nn.relu(%75)\n",
      "  %77 = nn.conv2d(%76, %layer4.1.conv1.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %78 = nn.batch_norm(%77, %layer4.1.bn1.weight, %layer4.1.bn1.bias, %layer4.1.bn1.running_mean, %layer4.1.bn1.running_var, epsilon=1e-05)\n",
      "  %79 = %78.0\n",
      "  %80 = nn.relu(%79)\n",
      "  %81 = nn.conv2d(%80, %layer4.1.conv2.weight, padding=[1, 1], kernel_size=[3, 3])\n",
      "  %82 = nn.batch_norm(%81, %layer4.1.bn2.weight, %layer4.1.bn2.bias, %layer4.1.bn2.running_mean, %layer4.1.bn2.running_var, epsilon=1e-05)\n",
      "  %83 = %82.0\n",
      "  %84 = add(%83, %76)\n",
      "  %85 = nn.relu(%84)\n",
      "  %86 = nn.global_avg_pool2d(%85)\n",
      "  %87 = reshape(%86, newshape=[10, -1])\n",
      "  %88 = nn.batch_flatten(%87)\n",
      "  %89 = multiply(1f, %88)\n",
      "  %90 = nn.dense(%89, %fc.weight, units=1000)\n",
      "  %91 = multiply(1f, %fc.bias)\n",
      "  nn.bias_add(%90, %91)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "torch_resnet18 = torchvision.models.resnet18()\n",
    "dummy_input = torch.randn(10, 3, 224, 224)\n",
    "torch.onnx.export(torch_resnet18, dummy_input, \"resnet.onnx\", verbose=True)\n",
    "onnx_resnet18 = onnx.load('resnet.onnx')\n",
    "func, params = relay.frontend.from_onnx(onnx_resnet18, shape={ '0': (10, 3, 224, 224) })\n",
    "print(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Format\n",
    "\n",
    "Relay has a textual representation that can be used to write and print programs. The textual format is still being stablized but can already be of great use to users today. For example instead of providing inscrutable graph representations of programs we can produce human readable output by default.\n",
    "\n",
    "There are a few different ways to interact with the textual format. The first is to just print out a Realy expression as we have seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 1, 28, 28), float32], %fc1_weight: Tensor[(128, 784), float32], %fc1_bias: Tensor[(128,), float32], %fc2_weight: Tensor[(64, 128), float32], %fc2_bias: Tensor[(64,), float32], %fc3_weight: Tensor[(10, 64), float32], %fc3_bias: Tensor[(10,), float32]) -> Tensor[(1, 10), float32] {\n",
      "  %0 = nn.batch_flatten(%data) /* ty=Tensor[(1, 784), float32] */\n",
      "  %1 = nn.dense(%0, %fc1_weight, units=128) /* ty=Tensor[(1, 128), float32] */\n",
      "  %2 = nn.bias_add(%1, %fc1_bias, axis=-1) /* ty=Tensor[(1, 128), float32] */\n",
      "  %3 = nn.relu(%2) /* ty=Tensor[(1, 128), float32] */\n",
      "  %4 = nn.dense(%3, %fc2_weight, units=64) /* ty=Tensor[(1, 64), float32] */\n",
      "  %5 = nn.bias_add(%4, %fc2_bias, axis=-1) /* ty=Tensor[(1, 64), float32] */\n",
      "  %6 = nn.relu(%5) /* ty=Tensor[(1, 64), float32] */\n",
      "  %7 = nn.dense(%6, %fc3_weight, units=10) /* ty=Tensor[(1, 10), float32] */\n",
      "  %8 = nn.bias_add(%7, %fc3_bias, axis=-1) /* ty=Tensor[(1, 10), float32] */\n",
      "  nn.softmax(%8) /* ty=Tensor[(1, 10), float32] */\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "mlp, params = relay.testing.mlp.get_workload(1)\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the textual format prints the version of the format, and the code without metadata. The metadata section of the format contains information such as constants. Imagine we perform an optimization such as inlining the parameters into the program for further optimization. Rendering this in the textual format would be nearly unreadable, common models often have 100s of megabytes of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 1, 28, 28), float32], %fc1_weight: Tensor[(128, 784), float32], %fc1_bias: Tensor[(128,), float32], %fc2_weight: Tensor[(64, 128), float32], %fc2_bias: Tensor[(64,), float32], %fc3_weight: Tensor[(10, 64), float32], %fc3_bias: Tensor[(10,), float32]) -> Tensor[(1, 10), float32] {\n",
      "  %0 = nn.batch_flatten(%data) /* ty=Tensor[(1, 784), float32] */\n",
      "  %1 = nn.dense(%0, %fc1_weight, units=128) /* ty=Tensor[(1, 128), float32] */\n",
      "  %2 = nn.bias_add(%1, %fc1_bias, axis=-1) /* ty=Tensor[(1, 128), float32] */\n",
      "  %3 = nn.relu(%2) /* ty=Tensor[(1, 128), float32] */\n",
      "  %4 = nn.dense(%3, %fc2_weight, units=64) /* ty=Tensor[(1, 64), float32] */\n",
      "  %5 = nn.bias_add(%4, %fc2_bias, axis=-1) /* ty=Tensor[(1, 64), float32] */\n",
      "  %6 = nn.relu(%5) /* ty=Tensor[(1, 64), float32] */\n",
      "  %7 = nn.dense(%6, %fc3_weight, units=10) /* ty=Tensor[(1, 10), float32] */\n",
      "  %8 = nn.bias_add(%7, %fc3_bias, axis=-1) /* ty=Tensor[(1, 10), float32] */\n",
      "  nn.softmax(%8) /* ty=Tensor[(1, 10), float32] */\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(mlp.astext(show_meta_data=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relay's pretty printer also allows users to attach debugging output and metadata to the IR, for example you can see the type information on the example above, but we can also customize the annotation process, by passing a callback for annotating nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 1, 28, 28), float32], %fc1_weight: Tensor[(128, 784), float32], %fc1_bias: Tensor[(128,), float32], %fc2_weight: Tensor[(64, 128), float32], %fc2_bias: Tensor[(64,), float32], %fc3_weight: Tensor[(10, 64), float32], %fc3_bias: Tensor[(10,), float32]) -> Tensor[(1, 10), float32] {\n",
      "  %0 = nn.batch_flatten <expression: 1>(%data) <expression: 2>\n",
      "  %1 = nn.dense <expression: 3>(%0, %fc1_weight, units=128) <expression: 4>\n",
      "  %2 = nn.bias_add <expression: 5>(%1, %fc1_bias, axis=-1) <expression: 6>\n",
      "  %3 = nn.relu <expression: 7>(%2) <expression: 8>\n",
      "  %4 = nn.dense <expression: 3>(%3, %fc2_weight, units=64) <expression: 9>\n",
      "  %5 = nn.bias_add <expression: 5>(%4, %fc2_bias, axis=-1) <expression: 10>\n",
      "  %6 = nn.relu <expression: 7>(%5) <expression: 11>\n",
      "  %7 = nn.dense <expression: 3>(%6, %fc3_weight, units=10) <expression: 12>\n",
      "  %8 = nn.bias_add <expression: 5>(%7, %fc3_bias, axis=-1) <expression: 13>\n",
      "  nn.softmax <expression: 14>(%8) <expression: 15>\n",
      "} <expression: 16>\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "def ann(*args):\n",
    "    global i\n",
    "    i += 1\n",
    "    return f\" <expression: {i}>\"\n",
    "\n",
    "print(mlp.astext(show_meta_data=True, annotate=ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally an important part of the Relay text format is the ability to load Relay code \n",
    "like a normal programming language. We can use the Relay parser to parse code, we actually do this to define the Relay\n",
    "*prelude* the small standard library of utilities shipped in Relay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Relay\n",
    "\n",
    "Now that we have looked out how to write and manipulate a Relay program, we will show you how to run one. Relay has multiple execution mechanisms. One is a custom *debug interpreter* for Relay which can be used for experimentation and debugging, the second is TVM's older graph runtime the existing execution mechanism. The final one is the Relay VM, a newly designed execution mechanism with the goal to smoothly execute all of Relay efficiently. \n",
    "\n",
    "We provide a high level interface which imposes some wrapping overhead, but enables quick experimentation with each API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = relay.Module()\n",
    "debug_ex = relay.create_executor('debug', mod=mod)\n",
    "graph_ex = relay.create_executor('graph', mod=mod)\n",
    "vm_ex = relay.create_executor('vm', mod=mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each executor can be used to evaluate an expression given a Relay module, in this case we use an empty module, and will just evaluate the same expression, a MLP, using each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mlp = debug_ex.evaluate(mlp)\n",
    "graph_mlp = graph_ex.evaluate(mlp)\n",
    "vm_mlp = vm_ex.evaluate(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each one can be called like a normal Python function with the inputs passed as positional arguments and the parameters as keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug:  [[0.12006255 0.15952827 0.06028504 0.07578056 0.05348781 0.17940904\n",
      "  0.06953022 0.02311306 0.17301401 0.0857894 ]]\n",
      "Graph:  [[0.12006255 0.15952827 0.06028504 0.07578056 0.05348781 0.17940904\n",
      "  0.06953022 0.02311306 0.17301401 0.0857894 ]]\n",
      "VM:  [[0.12006255 0.15952827 0.06028504 0.07578056 0.05348781 0.17940904\n",
      "  0.06953022 0.02311306 0.17301401 0.0857894 ]]\n"
     ]
    }
   ],
   "source": [
    "data = numpy.random.rand(1, 1, 28, 28).astype('float32')\n",
    "print(\"Debug: \", debug_mlp(data, **params))\n",
    "print(\"Graph: \", graph_mlp(data, **params))\n",
    "print(\"VM: \", vm_mlp(data, **params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Machine\n",
    "\n",
    "In particular the Relay virtual machine is worth highlighting ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass Manager\n",
    "\n",
    "Relay has a flexible and configurable pass manager with an elegant API which be used to easily compose and schedule pass pipelines. We believe an easy to configure pipeline is important to enable intelligent exploration between a variety of \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations\n",
    "\n",
    "Defining optimizations to transform your program is straight forward and easy to do in Relay.\n",
    "\n",
    "For example let's define a constant evaluator for Relay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puVpH87g0Nui"
   },
   "source": [
    "## Heterogeneous Execution\n",
    "\n",
    "Relay supports a high-level interface for scheduling computation across multiple heterogeneous devices. An interesting property of this pass is that it is not special, it is built using Relay's standard machinery for\n",
    "passes. \n",
    "\n",
    "We implement this by using an annotation to mark which computations we would like to schedule on which device, \n",
    "and a pass inserts all the appropriate calls to synchronize memory across devices. \n",
    "\n",
    "The below pass uses this machinery to schedule all convolutions onto the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6276
    },
    "colab_type": "code",
    "id": "5sfd3Svu0Nui",
    "outputId": "bf451b82-ece9-429e-d2cf-395e1ee1b026"
   },
   "outputs": [],
   "source": [
    "class ScheduleConv2d(ExprMutator):\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        super().__init__()\n",
    "\n",
    "    def visit_call(self, expr):\n",
    "        visit = super().visit_call(expr)\n",
    "        if expr.op == tvm.relay.op.get(\"nn.conv2d\"):\n",
    "            return relay.annotation.on_device(visit, self.device)\n",
    "        else:\n",
    "            return visit\n",
    "\n",
    "def schedule_conv2d_on_gpu(expr):\n",
    "    sched = ScheduleConv2d(tvm.gpu(0))\n",
    "    return sched.visit(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab a model, we provide a few basic models in Relay's testing library. By default when printing a model we will see it rendered in Relay's textual format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32], %bn_data_gamma: Tensor[(3,), float32], %bn_data_beta: Tensor[(3,), float32], %bn_data_moving_mean: Tensor[(3,), float32], %bn_data_moving_var: Tensor[(3,), float32], %conv0_weight: Tensor[(64, 3, 7, 7), float32], %bn0_gamma: Tensor[(64,), float32], %bn0_beta: Tensor[(64,), float32], %bn0_moving_mean: Tensor[(64,), float32], %bn0_moving_var: Tensor[(64,), float32], %stage1_unit1_bn1_gamma: Tensor[(64,), float32], %stage1_unit1_bn1_beta: Tensor[(64,), float32], %stage1_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn1_moving_var: Tensor[(64,), float32], %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_bn2_gamma: Tensor[(64,), float32], %stage1_unit1_bn2_beta: Tensor[(64,), float32], %stage1_unit1_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn2_moving_var: Tensor[(64,), float32], %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32], %stage1_unit2_bn1_gamma: Tensor[(64,), float32], %stage1_unit2_bn1_beta: Tensor[(64,), float32], %stage1_unit2_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn1_moving_var: Tensor[(64,), float32], %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit2_bn2_gamma: Tensor[(64,), float32], %stage1_unit2_bn2_beta: Tensor[(64,), float32], %stage1_unit2_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn2_moving_var: Tensor[(64,), float32], %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage2_unit1_bn1_gamma: Tensor[(64,), float32], %stage2_unit1_bn1_beta: Tensor[(64,), float32], %stage2_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage2_unit1_bn1_moving_var: Tensor[(64,), float32], %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32], %stage2_unit1_bn2_gamma: Tensor[(128,), float32], %stage2_unit1_bn2_beta: Tensor[(128,), float32], %stage2_unit1_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit1_bn2_moving_var: Tensor[(128,), float32], %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32], %stage2_unit2_bn1_gamma: Tensor[(128,), float32], %stage2_unit2_bn1_beta: Tensor[(128,), float32], %stage2_unit2_bn1_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn1_moving_var: Tensor[(128,), float32], %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit2_bn2_gamma: Tensor[(128,), float32], %stage2_unit2_bn2_beta: Tensor[(128,), float32], %stage2_unit2_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn2_moving_var: Tensor[(128,), float32], %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage3_unit1_bn1_gamma: Tensor[(128,), float32], %stage3_unit1_bn1_beta: Tensor[(128,), float32], %stage3_unit1_bn1_moving_mean: Tensor[(128,), float32], %stage3_unit1_bn1_moving_var: Tensor[(128,), float32], %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32], %stage3_unit1_bn2_gamma: Tensor[(256,), float32], %stage3_unit1_bn2_beta: Tensor[(256,), float32], %stage3_unit1_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit1_bn2_moving_var: Tensor[(256,), float32], %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32], %stage3_unit2_bn1_gamma: Tensor[(256,), float32], %stage3_unit2_bn1_beta: Tensor[(256,), float32], %stage3_unit2_bn1_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn1_moving_var: Tensor[(256,), float32], %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit2_bn2_gamma: Tensor[(256,), float32], %stage3_unit2_bn2_beta: Tensor[(256,), float32], %stage3_unit2_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn2_moving_var: Tensor[(256,), float32], %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage4_unit1_bn1_gamma: Tensor[(256,), float32], %stage4_unit1_bn1_beta: Tensor[(256,), float32], %stage4_unit1_bn1_moving_mean: Tensor[(256,), float32], %stage4_unit1_bn1_moving_var: Tensor[(256,), float32], %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32], %stage4_unit1_bn2_gamma: Tensor[(512,), float32], %stage4_unit1_bn2_beta: Tensor[(512,), float32], %stage4_unit1_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit1_bn2_moving_var: Tensor[(512,), float32], %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32], %stage4_unit2_bn1_gamma: Tensor[(512,), float32], %stage4_unit2_bn1_beta: Tensor[(512,), float32], %stage4_unit2_bn1_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn1_moving_var: Tensor[(512,), float32], %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit2_bn2_gamma: Tensor[(512,), float32], %stage4_unit2_bn2_beta: Tensor[(512,), float32], %stage4_unit2_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn2_moving_var: Tensor[(512,), float32], %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32], %bn1_gamma: Tensor[(512,), float32], %bn1_beta: Tensor[(512,), float32], %bn1_moving_mean: Tensor[(512,), float32], %bn1_moving_var: Tensor[(512,), float32], %fc1_weight: Tensor[(1000, 512), float32], %fc1_bias: Tensor[(1000,), float32]) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05, scale=False) /* ty=(Tensor[(1, 3, 224, 224), float32], Tensor[(3,), float32], Tensor[(3,), float32]) */\n",
      "  %1 = %0.0\n",
      "  %2 = nn.conv2d(%1, %conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  %3 = nn.batch_norm(%2, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 112, 112), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %4 = %3.0\n",
      "  %5 = nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  %6 = nn.max_pool2d(%5, pool_size=[3, 3], strides=[2, 2], padding=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %7 = nn.batch_norm(%6, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %8 = %7.0\n",
      "  %9 = nn.relu(%8) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %10 = nn.conv2d(%9, %stage1_unit1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %11 = nn.batch_norm(%10, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %12 = %11.0\n",
      "  %13 = nn.relu(%12) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %14 = nn.conv2d(%13, %stage1_unit1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %15 = nn.conv2d(%9, %stage1_unit1_sc_weight, channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %16 = add(%14, %15) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %17 = nn.batch_norm(%16, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %18 = %17.0\n",
      "  %19 = nn.relu(%18) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %20 = nn.conv2d(%19, %stage1_unit2_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %21 = nn.batch_norm(%20, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %22 = %21.0\n",
      "  %23 = nn.relu(%22) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %24 = nn.conv2d(%23, %stage1_unit2_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %25 = add(%24, %16) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %26 = nn.batch_norm(%25, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
      "  %27 = %26.0\n",
      "  %28 = nn.relu(%27) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  %29 = nn.conv2d(%28, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %30 = nn.batch_norm(%29, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %31 = %30.0\n",
      "  %32 = nn.relu(%31) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %33 = nn.conv2d(%32, %stage2_unit1_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %34 = nn.conv2d(%28, %stage2_unit1_sc_weight, strides=[2, 2], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %35 = add(%33, %34) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %36 = nn.batch_norm(%35, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %37 = %36.0\n",
      "  %38 = nn.relu(%37) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %39 = nn.conv2d(%38, %stage2_unit2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %40 = nn.batch_norm(%39, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %41 = %40.0\n",
      "  %42 = nn.relu(%41) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %43 = nn.conv2d(%42, %stage2_unit2_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %44 = add(%43, %35) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %45 = nn.batch_norm(%44, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
      "  %46 = %45.0\n",
      "  %47 = nn.relu(%46) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
      "  %48 = nn.conv2d(%47, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %49 = nn.batch_norm(%48, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %50 = %49.0\n",
      "  %51 = nn.relu(%50) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %52 = nn.conv2d(%51, %stage3_unit1_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %53 = nn.conv2d(%47, %stage3_unit1_sc_weight, strides=[2, 2], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %54 = add(%52, %53) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %55 = nn.batch_norm(%54, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %56 = %55.0\n",
      "  %57 = nn.relu(%56) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %58 = nn.conv2d(%57, %stage3_unit2_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %59 = nn.batch_norm(%58, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %60 = %59.0\n",
      "  %61 = nn.relu(%60) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %62 = nn.conv2d(%61, %stage3_unit2_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %63 = add(%62, %54) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %64 = nn.batch_norm(%63, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
      "  %65 = %64.0\n",
      "  %66 = nn.relu(%65) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
      "  %67 = nn.conv2d(%66, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %68 = nn.batch_norm(%67, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %69 = %68.0\n",
      "  %70 = nn.relu(%69) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %71 = nn.conv2d(%70, %stage4_unit1_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %72 = nn.conv2d(%66, %stage4_unit1_sc_weight, strides=[2, 2], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %73 = add(%71, %72) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %74 = nn.batch_norm(%73, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %75 = %74.0\n",
      "  %76 = nn.relu(%75) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %77 = nn.conv2d(%76, %stage4_unit2_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %78 = nn.batch_norm(%77, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %79 = %78.0\n",
      "  %80 = nn.relu(%79) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %81 = nn.conv2d(%80, %stage4_unit2_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %82 = add(%81, %73) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %83 = nn.batch_norm(%82, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
      "  %84 = %83.0\n",
      "  %85 = nn.relu(%84) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
      "  %86 = nn.global_avg_pool2d(%85) /* ty=Tensor[(1, 512, 1, 1), float32] */\n",
      "  %87 = nn.batch_flatten(%86) /* ty=Tensor[(1, 512), float32] */\n",
      "  %88 = nn.dense(%87, %fc1_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */\n",
      "  %89 = nn.bias_add(%88, %fc1_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */\n",
      "  nn.softmax(%89) /* ty=Tensor[(1, 1000), float32] */\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# We can grab a model, we provide a few basic models in Relay's testing library.\n",
    "resnet, params = relay.testing.resnet.get_workload()\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the customized pass we defined above to schedule individual convolutions on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32], %bn_data_gamma: Tensor[(3,), float32], %bn_data_beta: Tensor[(3,), float32], %bn_data_moving_mean: Tensor[(3,), float32], %bn_data_moving_var: Tensor[(3,), float32], %conv0_weight: Tensor[(64, 3, 7, 7), float32], %bn0_gamma: Tensor[(64,), float32], %bn0_beta: Tensor[(64,), float32], %bn0_moving_mean: Tensor[(64,), float32], %bn0_moving_var: Tensor[(64,), float32], %stage1_unit1_bn1_gamma: Tensor[(64,), float32], %stage1_unit1_bn1_beta: Tensor[(64,), float32], %stage1_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn1_moving_var: Tensor[(64,), float32], %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_bn2_gamma: Tensor[(64,), float32], %stage1_unit1_bn2_beta: Tensor[(64,), float32], %stage1_unit1_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn2_moving_var: Tensor[(64,), float32], %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32], %stage1_unit2_bn1_gamma: Tensor[(64,), float32], %stage1_unit2_bn1_beta: Tensor[(64,), float32], %stage1_unit2_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn1_moving_var: Tensor[(64,), float32], %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit2_bn2_gamma: Tensor[(64,), float32], %stage1_unit2_bn2_beta: Tensor[(64,), float32], %stage1_unit2_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn2_moving_var: Tensor[(64,), float32], %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage2_unit1_bn1_gamma: Tensor[(64,), float32], %stage2_unit1_bn1_beta: Tensor[(64,), float32], %stage2_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage2_unit1_bn1_moving_var: Tensor[(64,), float32], %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32], %stage2_unit1_bn2_gamma: Tensor[(128,), float32], %stage2_unit1_bn2_beta: Tensor[(128,), float32], %stage2_unit1_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit1_bn2_moving_var: Tensor[(128,), float32], %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32], %stage2_unit2_bn1_gamma: Tensor[(128,), float32], %stage2_unit2_bn1_beta: Tensor[(128,), float32], %stage2_unit2_bn1_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn1_moving_var: Tensor[(128,), float32], %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit2_bn2_gamma: Tensor[(128,), float32], %stage2_unit2_bn2_beta: Tensor[(128,), float32], %stage2_unit2_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn2_moving_var: Tensor[(128,), float32], %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage3_unit1_bn1_gamma: Tensor[(128,), float32], %stage3_unit1_bn1_beta: Tensor[(128,), float32], %stage3_unit1_bn1_moving_mean: Tensor[(128,), float32], %stage3_unit1_bn1_moving_var: Tensor[(128,), float32], %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32], %stage3_unit1_bn2_gamma: Tensor[(256,), float32], %stage3_unit1_bn2_beta: Tensor[(256,), float32], %stage3_unit1_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit1_bn2_moving_var: Tensor[(256,), float32], %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32], %stage3_unit2_bn1_gamma: Tensor[(256,), float32], %stage3_unit2_bn1_beta: Tensor[(256,), float32], %stage3_unit2_bn1_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn1_moving_var: Tensor[(256,), float32], %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit2_bn2_gamma: Tensor[(256,), float32], %stage3_unit2_bn2_beta: Tensor[(256,), float32], %stage3_unit2_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn2_moving_var: Tensor[(256,), float32], %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage4_unit1_bn1_gamma: Tensor[(256,), float32], %stage4_unit1_bn1_beta: Tensor[(256,), float32], %stage4_unit1_bn1_moving_mean: Tensor[(256,), float32], %stage4_unit1_bn1_moving_var: Tensor[(256,), float32], %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32], %stage4_unit1_bn2_gamma: Tensor[(512,), float32], %stage4_unit1_bn2_beta: Tensor[(512,), float32], %stage4_unit1_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit1_bn2_moving_var: Tensor[(512,), float32], %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32], %stage4_unit2_bn1_gamma: Tensor[(512,), float32], %stage4_unit2_bn1_beta: Tensor[(512,), float32], %stage4_unit2_bn1_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn1_moving_var: Tensor[(512,), float32], %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit2_bn2_gamma: Tensor[(512,), float32], %stage4_unit2_bn2_beta: Tensor[(512,), float32], %stage4_unit2_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn2_moving_var: Tensor[(512,), float32], %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32], %bn1_gamma: Tensor[(512,), float32], %bn1_beta: Tensor[(512,), float32], %bn1_moving_mean: Tensor[(512,), float32], %bn1_moving_var: Tensor[(512,), float32], %fc1_weight: Tensor[(1000, 512), float32], %fc1_bias: Tensor[(1000,), float32]) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05, scale=False)\n",
      "  %1 = %0.0\n",
      "  %2 = nn.conv2d(%1, %conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7])\n",
      "  %3 = on_device(%2, meta[relay.attrs.OnDeviceAttrs][0])\n",
      "  %4 = nn.batch_norm(%3, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05)\n",
      "  %5 = %4.0\n",
      "  %6 = nn.relu(%5)\n",
      "  %7 = nn.max_pool2d(%6, pool_size=[3, 3], strides=[2, 2], padding=[1, 1])\n",
      "  %8 = nn.batch_norm(%7, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %9 = %8.0\n",
      "  %10 = nn.relu(%9)\n",
      "  %11 = nn.conv2d(%10, %stage1_unit1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %12 = on_device(%11, meta[relay.attrs.OnDeviceAttrs][1])\n",
      "  %13 = nn.batch_norm(%12, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %14 = %13.0\n",
      "  %15 = nn.relu(%14)\n",
      "  %16 = nn.conv2d(%15, %stage1_unit1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %17 = on_device(%16, meta[relay.attrs.OnDeviceAttrs][2])\n",
      "  %18 = nn.conv2d(%10, %stage1_unit1_sc_weight, channels=64, kernel_size=[1, 1])\n",
      "  %19 = on_device(%18, meta[relay.attrs.OnDeviceAttrs][3])\n",
      "  %20 = add(%17, %19)\n",
      "  %21 = nn.batch_norm(%20, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %22 = %21.0\n",
      "  %23 = nn.relu(%22)\n",
      "  %24 = nn.conv2d(%23, %stage1_unit2_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %25 = on_device(%24, meta[relay.attrs.OnDeviceAttrs][4])\n",
      "  %26 = nn.batch_norm(%25, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %27 = %26.0\n",
      "  %28 = nn.relu(%27)\n",
      "  %29 = nn.conv2d(%28, %stage1_unit2_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %30 = on_device(%29, meta[relay.attrs.OnDeviceAttrs][5])\n",
      "  %31 = add(%30, %20)\n",
      "  %32 = nn.batch_norm(%31, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %33 = %32.0\n",
      "  %34 = nn.relu(%33)\n",
      "  %35 = nn.conv2d(%34, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %36 = on_device(%35, meta[relay.attrs.OnDeviceAttrs][6])\n",
      "  %37 = nn.batch_norm(%36, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %38 = %37.0\n",
      "  %39 = nn.relu(%38)\n",
      "  %40 = nn.conv2d(%39, %stage2_unit1_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %41 = on_device(%40, meta[relay.attrs.OnDeviceAttrs][7])\n",
      "  %42 = nn.conv2d(%34, %stage2_unit1_sc_weight, strides=[2, 2], channels=128, kernel_size=[1, 1])\n",
      "  %43 = on_device(%42, meta[relay.attrs.OnDeviceAttrs][8])\n",
      "  %44 = add(%41, %43)\n",
      "  %45 = nn.batch_norm(%44, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %46 = %45.0\n",
      "  %47 = nn.relu(%46)\n",
      "  %48 = nn.conv2d(%47, %stage2_unit2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %49 = on_device(%48, meta[relay.attrs.OnDeviceAttrs][9])\n",
      "  %50 = nn.batch_norm(%49, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %51 = %50.0\n",
      "  %52 = nn.relu(%51)\n",
      "  %53 = nn.conv2d(%52, %stage2_unit2_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %54 = on_device(%53, meta[relay.attrs.OnDeviceAttrs][10])\n",
      "  %55 = add(%54, %44)\n",
      "  %56 = nn.batch_norm(%55, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %57 = %56.0\n",
      "  %58 = nn.relu(%57)\n",
      "  %59 = nn.conv2d(%58, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %60 = on_device(%59, meta[relay.attrs.OnDeviceAttrs][11])\n",
      "  %61 = nn.batch_norm(%60, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %62 = %61.0\n",
      "  %63 = nn.relu(%62)\n",
      "  %64 = nn.conv2d(%63, %stage3_unit1_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %65 = on_device(%64, meta[relay.attrs.OnDeviceAttrs][12])\n",
      "  %66 = nn.conv2d(%58, %stage3_unit1_sc_weight, strides=[2, 2], channels=256, kernel_size=[1, 1])\n",
      "  %67 = on_device(%66, meta[relay.attrs.OnDeviceAttrs][13])\n",
      "  %68 = add(%65, %67)\n",
      "  %69 = nn.batch_norm(%68, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %70 = %69.0\n",
      "  %71 = nn.relu(%70)\n",
      "  %72 = nn.conv2d(%71, %stage3_unit2_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %73 = on_device(%72, meta[relay.attrs.OnDeviceAttrs][14])\n",
      "  %74 = nn.batch_norm(%73, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %75 = %74.0\n",
      "  %76 = nn.relu(%75)\n",
      "  %77 = nn.conv2d(%76, %stage3_unit2_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %78 = on_device(%77, meta[relay.attrs.OnDeviceAttrs][15])\n",
      "  %79 = add(%78, %68)\n",
      "  %80 = nn.batch_norm(%79, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %81 = %80.0\n",
      "  %82 = nn.relu(%81)\n",
      "  %83 = nn.conv2d(%82, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %84 = on_device(%83, meta[relay.attrs.OnDeviceAttrs][16])\n",
      "  %85 = nn.batch_norm(%84, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %86 = %85.0\n",
      "  %87 = nn.relu(%86)\n",
      "  %88 = nn.conv2d(%87, %stage4_unit1_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %89 = on_device(%88, meta[relay.attrs.OnDeviceAttrs][17])\n",
      "  %90 = nn.conv2d(%82, %stage4_unit1_sc_weight, strides=[2, 2], channels=512, kernel_size=[1, 1])\n",
      "  %91 = on_device(%90, meta[relay.attrs.OnDeviceAttrs][18])\n",
      "  %92 = add(%89, %91)\n",
      "  %93 = nn.batch_norm(%92, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %94 = %93.0\n",
      "  %95 = nn.relu(%94)\n",
      "  %96 = nn.conv2d(%95, %stage4_unit2_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %97 = on_device(%96, meta[relay.attrs.OnDeviceAttrs][19])\n",
      "  %98 = nn.batch_norm(%97, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %99 = %98.0\n",
      "  %100 = nn.relu(%99)\n",
      "  %101 = nn.conv2d(%100, %stage4_unit2_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %102 = on_device(%101, meta[relay.attrs.OnDeviceAttrs][20])\n",
      "  %103 = add(%102, %92)\n",
      "  %104 = nn.batch_norm(%103, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05)\n",
      "  %105 = %104.0\n",
      "  %106 = nn.relu(%105)\n",
      "  %107 = nn.global_avg_pool2d(%106)\n",
      "  %108 = nn.batch_flatten(%107)\n",
      "  %109 = nn.dense(%108, %fc1_weight, units=1000)\n",
      "  %110 = nn.bias_add(%109, %fc1_bias, axis=-1)\n",
      "  nn.softmax(%110)\n",
      "}\n",
      "// meta data omitted. you can use show_meta_data=True to include meta data\n"
     ]
    }
   ],
   "source": [
    "resnet = schedule_conv2d_on_gpu(resnet)\n",
    "print(resnet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can later rewrite away the device annotations to insert the copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.1\n",
      "fn (%data: Tensor[(1, 3, 224, 224), float32], %bn_data_gamma: Tensor[(3,), float32], %bn_data_beta: Tensor[(3,), float32], %bn_data_moving_mean: Tensor[(3,), float32], %bn_data_moving_var: Tensor[(3,), float32], %conv0_weight: Tensor[(64, 3, 7, 7), float32], %bn0_gamma: Tensor[(64,), float32], %bn0_beta: Tensor[(64,), float32], %bn0_moving_mean: Tensor[(64,), float32], %bn0_moving_var: Tensor[(64,), float32], %stage1_unit1_bn1_gamma: Tensor[(64,), float32], %stage1_unit1_bn1_beta: Tensor[(64,), float32], %stage1_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn1_moving_var: Tensor[(64,), float32], %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_bn2_gamma: Tensor[(64,), float32], %stage1_unit1_bn2_beta: Tensor[(64,), float32], %stage1_unit1_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit1_bn2_moving_var: Tensor[(64,), float32], %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32], %stage1_unit2_bn1_gamma: Tensor[(64,), float32], %stage1_unit2_bn1_beta: Tensor[(64,), float32], %stage1_unit2_bn1_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn1_moving_var: Tensor[(64,), float32], %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit2_bn2_gamma: Tensor[(64,), float32], %stage1_unit2_bn2_beta: Tensor[(64,), float32], %stage1_unit2_bn2_moving_mean: Tensor[(64,), float32], %stage1_unit2_bn2_moving_var: Tensor[(64,), float32], %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage2_unit1_bn1_gamma: Tensor[(64,), float32], %stage2_unit1_bn1_beta: Tensor[(64,), float32], %stage2_unit1_bn1_moving_mean: Tensor[(64,), float32], %stage2_unit1_bn1_moving_var: Tensor[(64,), float32], %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32], %stage2_unit1_bn2_gamma: Tensor[(128,), float32], %stage2_unit1_bn2_beta: Tensor[(128,), float32], %stage2_unit1_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit1_bn2_moving_var: Tensor[(128,), float32], %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32], %stage2_unit2_bn1_gamma: Tensor[(128,), float32], %stage2_unit2_bn1_beta: Tensor[(128,), float32], %stage2_unit2_bn1_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn1_moving_var: Tensor[(128,), float32], %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit2_bn2_gamma: Tensor[(128,), float32], %stage2_unit2_bn2_beta: Tensor[(128,), float32], %stage2_unit2_bn2_moving_mean: Tensor[(128,), float32], %stage2_unit2_bn2_moving_var: Tensor[(128,), float32], %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage3_unit1_bn1_gamma: Tensor[(128,), float32], %stage3_unit1_bn1_beta: Tensor[(128,), float32], %stage3_unit1_bn1_moving_mean: Tensor[(128,), float32], %stage3_unit1_bn1_moving_var: Tensor[(128,), float32], %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32], %stage3_unit1_bn2_gamma: Tensor[(256,), float32], %stage3_unit1_bn2_beta: Tensor[(256,), float32], %stage3_unit1_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit1_bn2_moving_var: Tensor[(256,), float32], %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32], %stage3_unit2_bn1_gamma: Tensor[(256,), float32], %stage3_unit2_bn1_beta: Tensor[(256,), float32], %stage3_unit2_bn1_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn1_moving_var: Tensor[(256,), float32], %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit2_bn2_gamma: Tensor[(256,), float32], %stage3_unit2_bn2_beta: Tensor[(256,), float32], %stage3_unit2_bn2_moving_mean: Tensor[(256,), float32], %stage3_unit2_bn2_moving_var: Tensor[(256,), float32], %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage4_unit1_bn1_gamma: Tensor[(256,), float32], %stage4_unit1_bn1_beta: Tensor[(256,), float32], %stage4_unit1_bn1_moving_mean: Tensor[(256,), float32], %stage4_unit1_bn1_moving_var: Tensor[(256,), float32], %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32], %stage4_unit1_bn2_gamma: Tensor[(512,), float32], %stage4_unit1_bn2_beta: Tensor[(512,), float32], %stage4_unit1_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit1_bn2_moving_var: Tensor[(512,), float32], %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32], %stage4_unit2_bn1_gamma: Tensor[(512,), float32], %stage4_unit2_bn1_beta: Tensor[(512,), float32], %stage4_unit2_bn1_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn1_moving_var: Tensor[(512,), float32], %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit2_bn2_gamma: Tensor[(512,), float32], %stage4_unit2_bn2_beta: Tensor[(512,), float32], %stage4_unit2_bn2_moving_mean: Tensor[(512,), float32], %stage4_unit2_bn2_moving_var: Tensor[(512,), float32], %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32], %bn1_gamma: Tensor[(512,), float32], %bn1_beta: Tensor[(512,), float32], %bn1_moving_mean: Tensor[(512,), float32], %bn1_moving_var: Tensor[(512,), float32], %fc1_weight: Tensor[(1000, 512), float32], %fc1_bias: Tensor[(1000,), float32]) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05, scale=False)\n",
      "  %1 = %0.0\n",
      "  %2 = device_copy(%1, meta[relay.attrs.DeviceCopyAttrs][0])\n",
      "  %3 = nn.conv2d(%2, %conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7])\n",
      "  %4 = device_copy(%3, meta[relay.attrs.DeviceCopyAttrs][1])\n",
      "  %5 = nn.batch_norm(%4, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05)\n",
      "  %6 = %5.0\n",
      "  %7 = nn.relu(%6)\n",
      "  %8 = nn.max_pool2d(%7, pool_size=[3, 3], strides=[2, 2], padding=[1, 1])\n",
      "  %9 = nn.batch_norm(%8, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %10 = %9.0\n",
      "  %11 = nn.relu(%10)\n",
      "  %12 = device_copy(%11, meta[relay.attrs.DeviceCopyAttrs][2])\n",
      "  %13 = nn.conv2d(%12, %stage1_unit1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %14 = device_copy(%13, meta[relay.attrs.DeviceCopyAttrs][3])\n",
      "  %15 = nn.batch_norm(%14, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %16 = %15.0\n",
      "  %17 = nn.relu(%16)\n",
      "  %18 = device_copy(%17, meta[relay.attrs.DeviceCopyAttrs][4])\n",
      "  %19 = nn.conv2d(%18, %stage1_unit1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %20 = device_copy(%19, meta[relay.attrs.DeviceCopyAttrs][5])\n",
      "  %21 = device_copy(%11, meta[relay.attrs.DeviceCopyAttrs][6])\n",
      "  %22 = nn.conv2d(%21, %stage1_unit1_sc_weight, channels=64, kernel_size=[1, 1])\n",
      "  %23 = device_copy(%22, meta[relay.attrs.DeviceCopyAttrs][7])\n",
      "  %24 = add(%20, %23)\n",
      "  %25 = nn.batch_norm(%24, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %26 = %25.0\n",
      "  %27 = nn.relu(%26)\n",
      "  %28 = device_copy(%27, meta[relay.attrs.DeviceCopyAttrs][8])\n",
      "  %29 = nn.conv2d(%28, %stage1_unit2_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %30 = device_copy(%29, meta[relay.attrs.DeviceCopyAttrs][9])\n",
      "  %31 = nn.batch_norm(%30, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %32 = %31.0\n",
      "  %33 = nn.relu(%32)\n",
      "  %34 = device_copy(%33, meta[relay.attrs.DeviceCopyAttrs][10])\n",
      "  %35 = nn.conv2d(%34, %stage1_unit2_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3])\n",
      "  %36 = device_copy(%35, meta[relay.attrs.DeviceCopyAttrs][11])\n",
      "  %37 = add(%36, %24)\n",
      "  %38 = nn.batch_norm(%37, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %39 = %38.0\n",
      "  %40 = nn.relu(%39)\n",
      "  %41 = device_copy(%40, meta[relay.attrs.DeviceCopyAttrs][12])\n",
      "  %42 = nn.conv2d(%41, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %43 = device_copy(%42, meta[relay.attrs.DeviceCopyAttrs][13])\n",
      "  %44 = nn.batch_norm(%43, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %45 = %44.0\n",
      "  %46 = nn.relu(%45)\n",
      "  %47 = device_copy(%46, meta[relay.attrs.DeviceCopyAttrs][14])\n",
      "  %48 = nn.conv2d(%47, %stage2_unit1_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %49 = device_copy(%48, meta[relay.attrs.DeviceCopyAttrs][15])\n",
      "  %50 = device_copy(%40, meta[relay.attrs.DeviceCopyAttrs][16])\n",
      "  %51 = nn.conv2d(%50, %stage2_unit1_sc_weight, strides=[2, 2], channels=128, kernel_size=[1, 1])\n",
      "  %52 = device_copy(%51, meta[relay.attrs.DeviceCopyAttrs][17])\n",
      "  %53 = add(%49, %52)\n",
      "  %54 = nn.batch_norm(%53, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %55 = %54.0\n",
      "  %56 = nn.relu(%55)\n",
      "  %57 = device_copy(%56, meta[relay.attrs.DeviceCopyAttrs][18])\n",
      "  %58 = nn.conv2d(%57, %stage2_unit2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %59 = device_copy(%58, meta[relay.attrs.DeviceCopyAttrs][19])\n",
      "  %60 = nn.batch_norm(%59, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %61 = %60.0\n",
      "  %62 = nn.relu(%61)\n",
      "  %63 = device_copy(%62, meta[relay.attrs.DeviceCopyAttrs][20])\n",
      "  %64 = nn.conv2d(%63, %stage2_unit2_conv2_weight, padding=[1, 1], channels=128, kernel_size=[3, 3])\n",
      "  %65 = device_copy(%64, meta[relay.attrs.DeviceCopyAttrs][21])\n",
      "  %66 = add(%65, %53)\n",
      "  %67 = nn.batch_norm(%66, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %68 = %67.0\n",
      "  %69 = nn.relu(%68)\n",
      "  %70 = device_copy(%69, meta[relay.attrs.DeviceCopyAttrs][22])\n",
      "  %71 = nn.conv2d(%70, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %72 = device_copy(%71, meta[relay.attrs.DeviceCopyAttrs][23])\n",
      "  %73 = nn.batch_norm(%72, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %74 = %73.0\n",
      "  %75 = nn.relu(%74)\n",
      "  %76 = device_copy(%75, meta[relay.attrs.DeviceCopyAttrs][24])\n",
      "  %77 = nn.conv2d(%76, %stage3_unit1_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %78 = device_copy(%77, meta[relay.attrs.DeviceCopyAttrs][25])\n",
      "  %79 = device_copy(%69, meta[relay.attrs.DeviceCopyAttrs][26])\n",
      "  %80 = nn.conv2d(%79, %stage3_unit1_sc_weight, strides=[2, 2], channels=256, kernel_size=[1, 1])\n",
      "  %81 = device_copy(%80, meta[relay.attrs.DeviceCopyAttrs][27])\n",
      "  %82 = add(%78, %81)\n",
      "  %83 = nn.batch_norm(%82, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %84 = %83.0\n",
      "  %85 = nn.relu(%84)\n",
      "  %86 = device_copy(%85, meta[relay.attrs.DeviceCopyAttrs][28])\n",
      "  %87 = nn.conv2d(%86, %stage3_unit2_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %88 = device_copy(%87, meta[relay.attrs.DeviceCopyAttrs][29])\n",
      "  %89 = nn.batch_norm(%88, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %90 = %89.0\n",
      "  %91 = nn.relu(%90)\n",
      "  %92 = device_copy(%91, meta[relay.attrs.DeviceCopyAttrs][30])\n",
      "  %93 = nn.conv2d(%92, %stage3_unit2_conv2_weight, padding=[1, 1], channels=256, kernel_size=[3, 3])\n",
      "  %94 = device_copy(%93, meta[relay.attrs.DeviceCopyAttrs][31])\n",
      "  %95 = add(%94, %82)\n",
      "  %96 = nn.batch_norm(%95, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05)\n",
      "  %97 = %96.0\n",
      "  %98 = nn.relu(%97)\n",
      "  %99 = device_copy(%98, meta[relay.attrs.DeviceCopyAttrs][32])\n",
      "  %100 = nn.conv2d(%99, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %101 = device_copy(%100, meta[relay.attrs.DeviceCopyAttrs][33])\n",
      "  %102 = nn.batch_norm(%101, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05)\n",
      "  %103 = %102.0\n",
      "  %104 = nn.relu(%103)\n",
      "  %105 = device_copy(%104, meta[relay.attrs.DeviceCopyAttrs][34])\n",
      "  %106 = nn.conv2d(%105, %stage4_unit1_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %107 = device_copy(%106, meta[relay.attrs.DeviceCopyAttrs][35])\n",
      "  %108 = device_copy(%98, meta[relay.attrs.DeviceCopyAttrs][36])\n",
      "  %109 = nn.conv2d(%108, %stage4_unit1_sc_weight, strides=[2, 2], channels=512, kernel_size=[1, 1])\n",
      "  %110 = device_copy(%109, meta[relay.attrs.DeviceCopyAttrs][37])\n",
      "  %111 = add(%107, %110)\n",
      "  %112 = nn.batch_norm(%111, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05)\n",
      "  %113 = %112.0\n",
      "  %114 = nn.relu(%113)\n",
      "  %115 = device_copy(%114, meta[relay.attrs.DeviceCopyAttrs][38])\n",
      "  %116 = nn.conv2d(%115, %stage4_unit2_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %117 = device_copy(%116, meta[relay.attrs.DeviceCopyAttrs][39])\n",
      "  %118 = nn.batch_norm(%117, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05)\n",
      "  %119 = %118.0\n",
      "  %120 = nn.relu(%119)\n",
      "  %121 = device_copy(%120, meta[relay.attrs.DeviceCopyAttrs][40])\n",
      "  %122 = nn.conv2d(%121, %stage4_unit2_conv2_weight, padding=[1, 1], channels=512, kernel_size=[3, 3])\n",
      "  %123 = device_copy(%122, meta[relay.attrs.DeviceCopyAttrs][41])\n",
      "  %124 = add(%123, %111)\n",
      "  %125 = nn.batch_norm(%124, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05)\n",
      "  %126 = %125.0\n",
      "  %127 = nn.relu(%126)\n",
      "  %128 = nn.global_avg_pool2d(%127)\n",
      "  %129 = nn.batch_flatten(%128)\n",
      "  %130 = nn.dense(%129, %fc1_weight, units=1000)\n",
      "  %131 = nn.bias_add(%130, %fc1_bias, axis=-1)\n",
      "  nn.softmax(%131)\n",
      "}\n",
      "// meta data omitted. you can use show_meta_data=True to include meta data\n"
     ]
    }
   ],
   "source": [
    "resnet = relay.ir_pass.rewrite_annotated_ops(resnet, 0)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will look at a couple case studies of what can be built using Relay. We will first look at how Relay is used as a backend in PyTorch integration, then how Relay can be used to compile a model down to traditional hardware, and finally how it can be used to support a custom accelerator, VTA, which we will dicuss in detail today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahead of time compilation\n",
    "\n",
    "An example of what can be built using Relay can be found with the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPK5HmW30Nun"
   },
   "source": [
    "## VTA\n",
    "TODO TALK WITH THIERRY"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_TVM_Tutorial_Relay.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
