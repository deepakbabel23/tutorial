{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MicroTVM iPython Notebook",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ_LgheWhovH",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/06_TVM_Tutorial_MicroTVM.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFoF4FhyYcwE",
        "colab_type": "text"
      },
      "source": [
        "Please run the following block to ensure TVM is setup for *this notebook*.  Each notebook may have its own runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce5eshWvUiyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! gsutil cp \"gs://tvm-fcrc-binariesd5fce43e-8373-11e9-bfb6-0242ac1c0002/tvm.tar.gz\" /tmp/tvm.tar.gz\n",
        "! mkdir -p /tvm\n",
        "! tar -xf /tmp/tvm.tar.gz --strip-components=4 --directory /tvm\n",
        "! ls -la /tvm\n",
        "# Move this block after we are done with pkg step\n",
        "! bash /tvm/package.sh\n",
        "import sys\n",
        "sys.path.append('/tvm/python')\n",
        "sys.path.append('/tvm/topi/python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHFxmiOzjFF2",
        "colab_type": "text"
      },
      "source": [
        "# MicroTVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV9BBxi6uR4t",
        "colab_type": "text"
      },
      "source": [
        "#### TODO: should we add some basic info about MicroTVM itself? People might miss things during the talk.\n",
        "\n",
        "First, we run some necessary imports.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHHOBXwRuJGl",
        "colab_type": "code",
        "outputId": "0d463f9d-d2a3-4e5f-aa6a-419fdc9dc252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm.contrib import graph_runtime, util\n",
        "from tvm import relay\n",
        "import tvm.micro as micro"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/env/python\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-e8e2fe8846eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_runtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmicro\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmicro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tvm.contrib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERvCOpVjsn_U",
        "colab_type": "text"
      },
      "source": [
        "## C Codegen\n",
        "\n",
        "Let's take a look at the C codegen backend for a simple function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAozo7Slus7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we construct the function.\n",
        "ty = relay.TensorType(shape=(1024,), dtype=\"float32\")\n",
        "x = relay.var(\"x\", ty)\n",
        "y = relay.var(\"y\", ty)\n",
        "func = relay.Function([x], relay.add(x, y))\n",
        "\n",
        "# Then build it with the appropriate configuration.\n",
        "with tvm.build_config(disable_vectorize=True):\n",
        "  _, src_mod, _ = relay.build(func, target=\"c\", params={})\n",
        "\n",
        "# Now, we can see the source that was generated.\n",
        "print(src_mod.get_source())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEGvx5OVymcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_c_module(func):\n",
        "  with tvm.build_config(disable_vectorize=True):\n",
        "    _, src_mod, _ = relay.build(func, target=\"c\", params={})\n",
        "  return src_mod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSJcyuD-0AJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func = relay.Function([], relay.const(1.0))\n",
        "print(build_c_module(func).get_source())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjayGmPKynSH",
        "colab_type": "text"
      },
      "source": [
        "Try building some other functions and see what source is generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJbJDEaqtv5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Try another function.\n",
        "func = ...\n",
        "print(build_c_module(func).get_source())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITy9wnt1WsN_",
        "colab_type": "text"
      },
      "source": [
        "## ResNet-18 Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAxIkBheYrOp",
        "colab_type": "text"
      },
      "source": [
        "Before we get into the mechanics of MicroTVM, we start with a motivating example.  In the code block below, we perform image recognition on a picture of a cat using ResNet-18.\n",
        "\n",
        "First, we import the model from MxNet's model zoo and use TVM's MxNet model importer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrTSYq4wqc_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet.gluon.model_zoo.vision import get_model\n",
        "\n",
        "# Fetch a mapping from class IDs to human-readable labels.\n",
        "synset_url = \"\".join([\"https://gist.githubusercontent.com/zhreshold/\",\n",
        "                      \"4d0b62f3d01426887599d4f7ede23ee5/raw/\",\n",
        "                      \"596b27d23537e5a1b5751d2b0481ef172f58b539/\",\n",
        "                      \"imagenet1000_clsid_to_human.txt\"])\n",
        "synset_name = \"synset.txt\"\n",
        "download(synset_url, synset_name)\n",
        "with open(synset_name) as f:\n",
        "    synset = eval(f.read())\n",
        "    \n",
        "block = get_model(\"resnet18_v1\", pretrained=True)\n",
        "func, params = relay.frontend.from_mxnet(\n",
        "    block, shape={\"data\": image.shape})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OjQ4rdBtSer",
        "colab_type": "text"
      },
      "source": [
        "Now, we download a picture of a cat and convert it to a format the model can understand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKH4Hmp6WwPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from mxnet.gluon.utils import download\n",
        "from PIL import Image\n",
        "\n",
        "dtype = \"float32\"\n",
        "\n",
        "# Read raw image and preprocess into the format ResNet can work on.\n",
        "img_name = \"cat.png\"\n",
        "download(\"https://github.com/dmlc/mxnet.js/blob/master/data/cat.png?raw=true\",\n",
        "         img_name)\n",
        "image = Image.open(img_name).resize((224, 224))\n",
        "image = np.array(image) - np.array([123., 117., 104.])\n",
        "image /= np.array([58.395, 57.12, 57.375])\n",
        "image = image.transpose((2, 0, 1))\n",
        "image = image[np.newaxis, :]\n",
        "image = tvm.nd.array(image.astype(dtype))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EEuEtrjtcRj",
        "colab_type": "text"
      },
      "source": [
        "With that, we can create a MicroTVM session, build a graph runtime module, then run the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqmbMcmga4Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE_TYPE = \"host\"\n",
        "BINUTIL_PREFIX = \"\"\n",
        "\n",
        "def relay_micro_build(func, binutil_prefix, params=None):\n",
        "    with tvm.build_config(disable_vectorize=True):\n",
        "        graph, c_mod, params = relay.build(func, target=\"c\", params=params)\n",
        "\n",
        "    micro_mod = create_micro_mod(c_mod, BINUTIL_PREFIX)\n",
        "    ctx = tvm.micro_dev(0)\n",
        "    mod = graph_runtime.create(graph, micro_mod, ctx)\n",
        "    return mod, params\n",
        "  \n",
        "\n",
        "with micro.Session(DEVICE_TYPE, BINUTIL_PREFIX) as sess:\n",
        "    mod, params = relay_micro_build(func, BINUTIL_PREFIX, params=params)\n",
        "    # Set model weights.\n",
        "    mod.set_input(**params)\n",
        "    # Execute with `image` as the input.\n",
        "    mod.run(data=image)\n",
        "    # Get output.\n",
        "    tvm_output = mod.get_output(0)\n",
        "\n",
        "    prediction_idx = np.argmax(tvm_output.asnumpy()[0])\n",
        "    prediction = synset[prediction_idx]\n",
        "    assert prediction == \"tiger cat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJJZRRnr0gGw",
        "colab_type": "text"
      },
      "source": [
        "## The Low-Level Device Interface\n",
        "\n",
        "The low-level device interface is used by TVM to communicate with MicroDevices. It exposes three important functions to interact with the MicroDevice: \n",
        "- Read from device memory.\n",
        "- Write to device memory.\n",
        "- Start function execution.\n",
        "\n",
        "\n",
        "Below is an example which uses an allocated region of memory on the host machine to simulate a MicroDevice. This HostLowLevelDevice provides MicroTVM users with an easy test setup to experiment with, without having to communicate and debug external MicroDevices. However, the LowLevelDevice interface can be implemented for any MicroDevice, for example over JTAG or a network connection, which will enable you to run TVM on your own MicroDevice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lJQxAUopDSmu",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title \n",
        "#include <sys/mman.h>\n",
        "#include <cstring>\n",
        "#include \"low_level_device.h\"\n",
        "#include \"micro_common.h\"\n",
        "\n",
        "namespace tvm {\n",
        "namespace runtime {\n",
        "/*!\n",
        " * \\brief emulated low-level device on host machine\n",
        " */\n",
        "class HostLowLevelDevice final : public LowLevelDevice {\n",
        " public:\n",
        "  /*!\n",
        "   * \\brief constructor to initialize on-host memory region to act as device\n",
        "   * \\param num_bytes size of the emulated on-device memory region\n",
        "   */\n",
        "  explicit HostLowLevelDevice(size_t num_bytes)\n",
        "    : size_(num_bytes) {\n",
        "    size_t size_in_pages = (num_bytes + kPageSize - 1) / kPageSize;\n",
        "    int mmap_prot = PROT_READ | PROT_WRITE | PROT_EXEC;\n",
        "    int mmap_flags = MAP_ANONYMOUS | MAP_PRIVATE;\n",
        "    base_addr_ = DevBaseAddr(\n",
        "      (reinterpret_cast<std::uintptr_t>(\n",
        "        mmap(nullptr, size_in_pages * kPageSize, mmap_prot, mmap_flags, -1, 0))));\n",
        "  }\n",
        "\n",
        "  /*!\n",
        "   * \\brief destructor to deallocate on-host device region\n",
        "   */\n",
        "  ~HostLowLevelDevice() {\n",
        "    munmap(base_addr_.cast_to<void*>(), size_);\n",
        "  }\n",
        "\n",
        "  void Write(DevBaseOffset offset,\n",
        "             void* buf,\n",
        "             size_t num_bytes) final {\n",
        "    void* addr = (offset + base_addr_).cast_to<void*>();\n",
        "    std::memcpy(addr, buf, num_bytes);\n",
        "  }\n",
        "\n",
        "  void Read(DevBaseOffset offset,\n",
        "            void* buf,\n",
        "            size_t num_bytes) final {\n",
        "    void* addr = (offset + base_addr_).cast_to<void*>();\n",
        "    std::memcpy(buf, addr, num_bytes);\n",
        "  }\n",
        "\n",
        "  void Execute(DevBaseOffset func_offset, DevBaseOffset breakpoint) final {\n",
        "    DevAddr func_addr = func_offset + base_addr_;\n",
        "    reinterpret_cast<void (*)(void)>(func_addr.value())();\n",
        "  }\n",
        "\n",
        "  DevBaseAddr base_addr() const final {\n",
        "    return base_addr_;\n",
        "  }\n",
        "\n",
        "  const char* device_type() const final {\n",
        "    return \"host\";\n",
        "  }\n",
        "\n",
        " private:\n",
        "  /*! \\brief base address of the micro device memory region */\n",
        "  DevBaseAddr base_addr_;\n",
        "  /*! \\brief size of memory region */\n",
        "  size_t size_;\n",
        "};\n",
        "\n",
        "const std::shared_ptr<LowLevelDevice> HostLowLevelDeviceCreate(size_t num_bytes) {\n",
        "  std::shared_ptr<LowLevelDevice> lld =\n",
        "      std::make_shared<HostLowLevelDevice>(num_bytes);\n",
        "  return lld;\n",
        "}\n",
        "}  // namespace runtime\n",
        "}  // namespace tvm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8dibeuWH8Nt",
        "colab_type": "text"
      },
      "source": [
        "# Extra Credit: RISC-V\n",
        "\n",
        "TODO: Fill in steps to download and install RISC-V tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXfurqUC5Xmb",
        "colab_type": "text"
      },
      "source": [
        "# Graveyard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqGxOMFp0NsB",
        "colab_type": "text"
      },
      "source": [
        "## Graph Runtime Execution\n",
        "\n",
        "The primary execution strategy for running models with MicroTVM is the graph runtime.  Here's a helper function for building a graph runtime module from a Relay function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoAwLH1YuBlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def micro_build_graph_runtime(func, device_type, params={}):\n",
        "    \"\"\"Create a graph runtime module with a micro device context.\"\"\"\n",
        "    with tvm.build_config(disable_vectorize=True):\n",
        "        with relay.build_config(opt_level=3):\n",
        "            graph, host_mod, params = relay.build(func, target=\"c\",\n",
        "                                                  params=params)\n",
        "\n",
        "    micro_mod = micro.from_source_module(host_mod, device_type)\n",
        "    ctx = tvm.micro_dev(0)\n",
        "    graph_mod = graph_runtime.create(graph, micro_mod, ctx)\n",
        "    return graph_mod, params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ppoQiyb2HcK",
        "colab_type": "text"
      },
      "source": [
        "Being able to construct a graph runtime module means we can now plug in existing models and they just work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "looZwQcl2D9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tvm.relay.testing import resnet\n",
        "\n",
        "resnet_func, params = resnet.get_workload(num_classes=10,\n",
        "                                          num_layers=18,\n",
        "                                          image_shape=(3, 32, 32))\n",
        "# Remove the final softmax layer, because uTVM does not currently support\n",
        "# it.\n",
        "resnet_func_no_sm = relay.Function(resnet_func.params,\n",
        "                                   resnet_func.body.args[0],\n",
        "                                   resnet_func.ret_type)\n",
        "\n",
        "# For now, we use the \"host\" emulated device for execution.  In the next\n",
        "# section, we'll implement our own simple low-level device.\n",
        "device_type = \"host\"\n",
        "micro.init(device_type)\n",
        "mod, params = micro_build_graph_runtime(resnet_func_no_sm, device_type,\n",
        "                                        params=params)\n",
        "# Set the model weights.\n",
        "mod.set_input(**params)\n",
        "# Generate random input.\n",
        "data = np.random.uniform(size=mod.get_input(0).shape)\n",
        "mod.run(data=data)\n",
        "result = mod.get_output(0).asnumpy()\n",
        "# We gave a random input, so all we want is a result with some nonzero\n",
        "# entries.\n",
        "assert result.sum() != 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}