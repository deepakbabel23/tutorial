{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_TVM_Tutorial_MicroTVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uwsampl/tutorial/blob/master/notebook/06_TVM_Tutorial_MicroTVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFoF4FhyYcwE",
        "colab_type": "text"
      },
      "source": [
        "Please run the following block to ensure TVM is setup for *this notebook*.  Each notebook may have its own runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce5eshWvUiyN",
        "colab_type": "code",
        "outputId": "62eee10d-64b7-4f0a-d63f-f225d853cab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1635
        }
      },
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    ! gsutil cp \"gs://tvm-fcrc-binariesd5fce43e-8373-11e9-bfb6-0242ac1c0002/tvm.tar.gz\" /tmp/tvm.tar.gz\n",
        "    ! mkdir -p /tvm\n",
        "    ! tar -xf /tmp/tvm.tar.gz --strip-components=4 --directory /tvm\n",
        "    ! ls -la /tvm\n",
        "    ! bash /tvm/package.sh\n",
        "    # Add TVM to the Python path.\n",
        "    import sys\n",
        "    sys.path.append('/tvm/python')\n",
        "    sys.path.append('/tvm/topi/python')\n",
        "    ! pip install mxnet\n",
        "else:\n",
        "    print('Notebook executing locally, skipping Colab setup ...')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://tvm-fcrc-binariesd5fce43e-8373-11e9-bfb6-0242ac1c0002/tvm.tar.gz...\n",
            "- [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "total 164\n",
            "drwxr-xr-x 21 root root  4096 Jun 21 14:56 .\n",
            "drwxr-xr-x  1 root root  4096 Jun 21 14:53 ..\n",
            "drwx------  8 root root  4096 May 31 08:14 3rdparty\n",
            "drwx------ 12 root root  4096 May 31 08:14 apps\n",
            "drwx------  3 root root  4096 Jun 19 07:58 build\n",
            "drwx------  4 root root  4096 May 31 08:14 cmake\n",
            "-rw-------  1 root root 11053 Jun 19 04:54 CMakeLists.txt\n",
            "drwx------  6 root root  4096 May 31 08:14 conda\n",
            "-rw-------  1 root root  5736 Jun 19 04:54 CONTRIBUTORS.md\n",
            "drwx------  3 root root  4096 May 31 08:14 docker\n",
            "drwx------ 11 root root  4096 May 31 08:14 docs\n",
            "drwx------  4 root root  4096 May 31 08:14 golang\n",
            "drwx------  3 root root  4096 May 31 08:14 include\n",
            "-rw-------  1 root root 10607 Jun 19 04:54 Jenkinsfile\n",
            "drwx------  6 root root  4096 May 31 08:14 jvm\n",
            "-rw-------  1 root root 11357 Jun 19 04:54 LICENSE\n",
            "-rw-------  1 root root  4267 Jun 19 04:54 Makefile\n",
            "-rw-------  1 root root 10476 Jun 19 04:54 NEWS.md\n",
            "drwx------  9 root root  4096 May 31 08:14 nnvm\n",
            "-rw-------  1 root root    61 Jun 19 04:54 NOTICE\n",
            "-rwx------  1 root root   374 Jun 19 04:57 package.sh\n",
            "drwx------  3 root root  4096 May 31 08:14 python\n",
            "-rw-------  1 root root  2705 Jun 19 04:54 README.md\n",
            "drwx------  6 root root  4096 May 31 08:14 rust\n",
            "drwx------ 14 root root  4096 May 31 08:14 src\n",
            "drwx------  9 root root  4096 May 31 08:14 tests\n",
            "drwx------  7 root root  4096 May 31 08:14 topi\n",
            "drwx------  8 root root  4096 May 31 08:14 tutorials\n",
            "-rw-------  1 root root  2902 Jun 19 05:04 version.py\n",
            "drwx------ 10 root root  4096 May 31 08:14 vta\n",
            "drwx------  2 root root  4096 May 31 08:14 web\n",
            "Installing Dependencies ...\n",
            "deb https://dl.bintray.com/sbt/debian /\n",
            "Executing: /tmp/apt-key-gpghome.pKgWEkiWTh/gpg.1.sh --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823\n",
            "gpg: key 99E82A75642AC823: \"sbt build tool <scalasbt@gmail.com>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Ign:10 https://dl.bintray.com/sbt/debian  InRelease\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Get:13 https://dl.bintray.com/sbt/debian  Release [815 B]\n",
            "Fetched 815 B in 1s (670 B/s)\n",
            "Reading package lists... Done\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:2\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:3\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:2\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:3\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libffi-dev is already the newest version (3.2.1-8).\n",
            "llvm-6.0 is already the newest version (1:6.0-1ubuntu2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "clinfo is already the newest version (2.2.18.03.26-1).\n",
            "tree is already the newest version (1.7.0-5).\n",
            "libtinfo-dev is already the newest version (6.1-1ubuntu1.18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:2\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:3\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "verilator is already the newest version (3.916-1build1).\n",
            "sbt is already the newest version (1.2.8).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:2\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/sbt.list:1 and /etc/apt/sources.list.d/sbt.list:3\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.14.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet) (2019.3.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHFxmiOzjFF2",
        "colab_type": "text"
      },
      "source": [
        "# μTVM\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHHOBXwRuJGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm.contrib import graph_runtime, util\n",
        "from tvm import relay\n",
        "import tvm.micro as micro"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLTjoVHpW3ex",
        "colab_type": "text"
      },
      "source": [
        "The proliferation of low-cost, AI-powered consumer devices has lead to widespread interest in \"bare-metal\" (low-power, often without an operating system) devices among ML researchers and practitioners.\n",
        "\n",
        "μTVM brings deep learning code generated by TVM to bare-metal devices that lack mature software stacks or do not have an operating system. Here's a high-level overview of how μTVM operates:\n",
        "\n",
        "This tutorial aims to provide a broad understanding of how μTVM works, and primarily focuses on how you can use μTVM to run TVM-generated code on your own bare-metal device.\n",
        "\n",
        "In this notebook, we're going to cover:\n",
        "\n",
        "*   the C code generation backend\n",
        "*   the cross-compiler interface\n",
        "*   the low-level device interface\n",
        "*   the graph runtime\n",
        "*   a demo of ResNeT-18 using the graph runtime\n",
        "\n",
        "\n",
        "There are three requirements for using μTVM:\n",
        "- A TVM model written in Python\n",
        "- A low-level device interface to the target device\n",
        "- A cross-compiler for the target device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-jpZPaMcVX8",
        "colab_type": "text"
      },
      "source": [
        "**Note**: We have only tested μTVM using a Linux host machine.  It may or may not work on Mac.\n",
        "\n",
        "**Disclaimer**: μTVM is still experimental and its API may change in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERvCOpVjsn_U",
        "colab_type": "text"
      },
      "source": [
        "## C Codegen\n",
        "\n",
        "If we're going to work with bare-metal devices, we need some type of code generation backend that targets them.  At first glance, LLVM seems like a great option, but unfortunately, we can't use it.  Bare-metal devices often lack support for common languages and IRs.\n",
        "\n",
        "However, most bare-metal devices ***do*** support C.  We have taken advantage of this fact by developing a C code generation backend for TVM.  With this backend, any programs expressible in TVM's low-level IR can be compiled into C.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEGvx5OVymcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_c_module(func):\n",
        "  \"\"\"Builds a C source module by compiling `func` with Relay.\"\"\"\n",
        "  # Note: μTVM currently does not support vectorized instructions.\n",
        "  with tvm.build_config(disable_vectorize=True):\n",
        "    # We set `target` to \"c\", and the build is now routed to the C backend.\n",
        "    _, src_mod, _ = relay.build(func, target='c', params={})\n",
        "  return src_mod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKCijhKQFFOi",
        "colab_type": "text"
      },
      "source": [
        "Now, let's write a simple Relay program and examine the generated code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAozo7Slus7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we use Relay to construct our function which computes `x + y`.\n",
        "ty = relay.TensorType(shape=(1024,), dtype='float32')\n",
        "x = relay.var('x', ty)\n",
        "y = relay.var('y', ty)\n",
        "func = relay.Function([x, y], relay.add(x, y))\n",
        "print(func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWh8sKdU3ecf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then build it into a C source module.\n",
        "src_mod = build_c_module(func)\n",
        "# Now, we can see the source that was generated.\n",
        "print(src_mod.get_source())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Bm6r-FfyMQ",
        "colab_type": "text"
      },
      "source": [
        "## The Cross-Compiler Interface\n",
        "With the ability to generate C, we need access to a cross-compiler toolchain for our device, in order to create binaries for it.\n",
        "\n",
        "How you obtain the toolchain will vary, depending on the device you're targetting.  Once you have a toolchain, you need to make sure it's accessible from a terminal by adding it to your system's PATH variable.\n",
        "\n",
        "All of the binaries in the toolchain should have a common prefix.  For example, if you're targetting RISC-V, you might want \"gcc\" to be named \"riscv-gcc\", \"ld\" to be named \"riscv-ld\", etc., and in this case, the prefix is \"riscv-\".  Having a common prefix is important, because we use this prefix to tell μTVM which binaries to use for binary compilation/manipulation.\n",
        "\n",
        "In the example below, we create a session using the host emulated device type, which creates a region of memory on the host machine to emulate device memory.  Because this device type is running on the host machine, we don't need a cross-compiler, and in fact, we can use plain old \"gcc\".  In this case, there is no prefix on the toolchain, so we use the empty string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGtxTXRYfGlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_type = 'host'\n",
        "toolchain_prefix = ''\n",
        "with micro.Session(device_type, toolchain_prefix) as sess:\n",
        "  # Do μTVM things...\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJJZRRnr0gGw",
        "colab_type": "text"
      },
      "source": [
        "## The Low-Level Device Interface\n",
        "Now we have the ability to generate binaries for our device, but we don't yet have a method of loading and running these binaries onto the device.  And even if we could run it, we couldn't read the outputs.  \n",
        "\n",
        "To satisfy these requirements, we require an implementation of a low-level device interface for every device in μTVM.  The low-level device interface exposes three important operations to interact with the MicroDevice: \n",
        "- Reading from device memory\n",
        "- Writing to device memory\n",
        "- Beginning function execution\n",
        "\n",
        "This interface appears in C++ as\n",
        "\n",
        "<img src=\"https://i.imgur.com/beF6Rm3.png\" alt=\"low-level device interface\" width=\"500\"/>\n",
        "\n",
        "In the above interface, `DevBaseOffset` is a wrapper type for a `uintptr_t` that represents an offset from the base address of the device.  The full definition of the inteface can be found [here](https://github.com/uwsampl/tvm/blob/tutorial/src/runtime/micro/low_level_device.h).\n",
        "\n",
        "To add support for your own MicroDevice in μTVM, you simply need to implement the low-level device interface for your MicroDevice.  Doing so will require some form of communication with the device.  For instance, communication may occur over [JTAG](https://en.wikipedia.org/wiki/JTAG) or over a network connection.\n",
        "\n",
        "### Host Low-Level Device\n",
        "To give an example of an implementation of this interface, we will walk through the already-existing `HostLowLevelDevice` (found [here](https://github.com/uwsampl/tvm/blob/tutorial/src/runtime/micro/host_low_level_device.cc)), because it's implementation is relatively simple.\n",
        "\n",
        "This device uses an allocated region of memory on the host machine to simulate a MicroDevice. This device provides μTVM users with an easy setup to experiment with, without having to communicate with and debug external MicroDevices.\n",
        "\n",
        "#### Constructor\n",
        "To create a host device, we call `mmap` to allocate a memory region that is at least as large as the requested device size, and we assign read/write/execute permissions to that region.  The base address of the device is just the start address of the region.\n",
        "\n",
        "<img src=\"https://i.imgur.com/FVNSVnV.png\" alt=\"constructor implementation\" width=\"700\"/>\n",
        "\n",
        "#### Destructor\n",
        "To destroy a host device, we simply unmap the `mmap`'d region.\n",
        "\n",
        "<img src=\"https://i.imgur.com/rthH1Cv.png\" alt=\"destructor implementation\" width=\"400\"/>\n",
        "\n",
        "#### Read\n",
        "To read from the host device, we convert the device offset into a host virtual address, then use `memcpy` to transfer from the mapped memory into the output buffer `buf`.\n",
        "\n",
        "<img src=\"https://i.imgur.com/77lRlzZ.png\" alt=\"read implementation\" width=\"500\"/>\n",
        "\n",
        "#### Write\n",
        "Writing to the host device is similar to reading, except now `buf` serves as an input buffer.\n",
        "\n",
        "<img src=\"https://i.imgur.com/SEm4UWQ.png\" alt=\"write implementation\" width=\"500\"/>\n",
        "\n",
        "#### Execute\n",
        "For function execution, we are given an offset to the target function, but also a breakpoint indicating the memory offset at which code execution should stop.\n",
        "\n",
        "We don't need to use `breakpoint` here, because with the host device, control flow never leaves the host machine, so we can simply call the function as we would any other function.\n",
        "\n",
        "For real devices, we may need to use `breakpoint` to stop execution, because otherwise, the device may continue executing indefinitely.\n",
        "\n",
        "<img src=\"https://i.imgur.com/psuYqrt.png\" alt=\"execute implementation\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqGxOMFp0NsB",
        "colab_type": "text"
      },
      "source": [
        "## Graph Runtime Execution\n",
        "\n",
        "The primary execution strategy for running models with μTVM is the graph runtime.\n",
        "\n",
        "When we use the graph runtime, the host drives the control flow of the model.  For each node in the graph, the host calls out to the device to execute the corresponding operator for that node.\n",
        "\n",
        "Note that this means models do not run entirely on the device (i.e., they aren't self-hosted).  Fully self-hosted models are not currently supported, as this would require using the Relay ahead-of-time compiler, which is still experimental.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "looZwQcl2D9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape = (1024,)\n",
        "dtype = 'float32'\n",
        "    \n",
        "# Construct Relay program.\n",
        "x = relay.var('x', relay.TensorType(shape=shape, dtype=dtype))\n",
        "xx = relay.multiply(x, x)\n",
        "z = relay.add(xx, relay.const(1.0))\n",
        "func = relay.Function([x], z)\n",
        "print(func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISYiPHYZWSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with micro.Session('host', '') as sess:\n",
        "  mod, params = sess.build(func)\n",
        "  mod.set_input(**params)\n",
        "\n",
        "  x_in = np.random.uniform(size=shape[0]).astype(dtype)\n",
        "  print(f'input:\\t\\t\\t{x_in}')\n",
        "  # Run with `x_in` as the input. \n",
        "  mod.run(x=x_in)\n",
        "  result = mod.get_output(0).asnumpy()\n",
        "\n",
        "  print(f'expected result:\\t{(x_in * x_in) + 1.0}')\n",
        "  print(f'uTVM result:\\t\\t{result}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITy9wnt1WsN_",
        "colab_type": "text"
      },
      "source": [
        "## ResNet-18 Demo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk61wn9jvJDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import mxnet as mx\n",
        "from mxnet.gluon.model_zoo.vision import get_model\n",
        "from mxnet.gluon.utils import download\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "\n",
        "RESNET_INPUT_IMG_SHAPE = (1, 3, 224, 224)\n",
        "\n",
        "def get_cat_image():\n",
        "  img_name = 'cat.png'\n",
        "  download('https://github.com/dmlc/mxnet.js/blob/master/data/cat.png?raw=true',\n",
        "           img_name)\n",
        "  image = Image.open(img_name)\n",
        "  return image\n",
        "\n",
        "\n",
        "def show_image(image):\n",
        "  img_byte_arr = io.BytesIO()\n",
        "  image.save(img_byte_arr, format='png')\n",
        "  img_byte_arr = img_byte_arr.getvalue()\n",
        "  IPython.display.display(IPython.display.Image(img_byte_arr))\n",
        "\n",
        "\n",
        "def convert_image(image):\n",
        "  dtype = 'float32'\n",
        "  image = image.resize(RESNET_INPUT_IMG_SHAPE[2:])\n",
        "  image = np.array(image) - np.array([123., 117., 104.])\n",
        "  image /= np.array([58.395, 57.12, 57.375])\n",
        "  image = image.transpose((2, 0, 1))\n",
        "  image = image[np.newaxis, :]\n",
        "  image = tvm.nd.array(image.astype(dtype))\n",
        "  return image\n",
        "\n",
        "\n",
        "def get_resnet():    \n",
        "  block = get_model('resnet18_v1', pretrained=True)\n",
        "  module, params = relay.frontend.from_mxnet(\n",
        "    block, shape={'data': RESNET_INPUT_IMG_SHAPE})\n",
        "  func = module['main']\n",
        "  return func, params\n",
        "  \n",
        "  \n",
        "# Fetch a mapping from class IDs to human-readable labels.\n",
        "synset_url = ''.join(['https://gist.githubusercontent.com/zhreshold/',\n",
        "                      '4d0b62f3d01426887599d4f7ede23ee5/raw/',\n",
        "                      '596b27d23537e5a1b5751d2b0481ef172f58b539/',\n",
        "                      'imagenet1000_clsid_to_human.txt'])\n",
        "synset_name = 'synset.txt'\n",
        "download(synset_url, synset_name)\n",
        "with open(synset_name) as f:\n",
        "  synset = eval(f.read())\n",
        "\n",
        "    \n",
        "def get_prediction(mod):\n",
        "  tvm_output = mod.get_output(0)\n",
        "  prediction_idx = np.argmax(tvm_output.asnumpy()[0])\n",
        "  prediction = synset[prediction_idx]\n",
        "  return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAxIkBheYrOp",
        "colab_type": "text"
      },
      "source": [
        "It's great that we can prototype models and immediately run them on a device, but the function we just ran was pretty simple.  Let's try a more interesting example.\n",
        "\n",
        "In this section, we will run ResNet-18 on μTVM to perform image recognition.  And our example input is..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrTSYq4wqc_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = get_cat_image()\n",
        "show_image(image)\n",
        "# Convert image to a format the model can understand.\n",
        "image = convert_image(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EEuEtrjtcRj",
        "colab_type": "text"
      },
      "source": [
        "...a cat!\n",
        "\n",
        "Luckily, MxNet is one of the many frameworks that TVM can import models from, so we can use a pretrained ResNet-18 model from the Gluon Model Zoo.\n",
        "\n",
        "Below, we grab a relay function that expresses our model, along with its set of pretrained parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t52Cr6rd7n81",
        "colab_type": "code",
        "outputId": "d632b965-fce2-4722-bf10-8d35f35d1ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3386
        }
      },
      "source": [
        "resnet, params = get_resnet()\n",
        "print(resnet)\n",
        "print()\n",
        "pprint.pprint(list(params.keys()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/resnet18_v1-a0666292.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v1-a0666292.zip...\n",
            "v0.0.1\n",
            "fn (%data: Tensor[(1, 3, 224, 224), float32], %resnetv10_conv0_weight: Tensor[(64, 3, 7, 7), float32], %resnetv10_batchnorm0_gamma: Tensor[(64,), float32], %resnetv10_batchnorm0_beta: Tensor[(64,), float32], %resnetv10_batchnorm0_running_mean: Tensor[(64,), float32], %resnetv10_batchnorm0_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv0_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm0_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm0_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm0_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm0_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm1_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm1_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm1_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm1_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm2_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm2_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm2_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm2_running_var: Tensor[(64,), float32], %resnetv10_stage1_conv3_weight: Tensor[(64, 64, 3, 3), float32], %resnetv10_stage1_batchnorm3_gamma: Tensor[(64,), float32], %resnetv10_stage1_batchnorm3_beta: Tensor[(64,), float32], %resnetv10_stage1_batchnorm3_running_mean: Tensor[(64,), float32], %resnetv10_stage1_batchnorm3_running_var: Tensor[(64,), float32], %resnetv10_stage2_conv2_weight: Tensor[(128, 64, 1, 1), float32], %resnetv10_stage2_batchnorm2_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm2_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm2_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm2_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv0_weight: Tensor[(128, 64, 3, 3), float32], %resnetv10_stage2_batchnorm0_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm0_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm0_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm0_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %resnetv10_stage2_batchnorm1_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm1_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm1_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm1_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv3_weight: Tensor[(128, 128, 3, 3), float32], %resnetv10_stage2_batchnorm3_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm3_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm3_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm3_running_var: Tensor[(128,), float32], %resnetv10_stage2_conv4_weight: Tensor[(128, 128, 3, 3), float32], %resnetv10_stage2_batchnorm4_gamma: Tensor[(128,), float32], %resnetv10_stage2_batchnorm4_beta: Tensor[(128,), float32], %resnetv10_stage2_batchnorm4_running_mean: Tensor[(128,), float32], %resnetv10_stage2_batchnorm4_running_var: Tensor[(128,), float32], %resnetv10_stage3_conv2_weight: Tensor[(256, 128, 1, 1), float32], %resnetv10_stage3_batchnorm2_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm2_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm2_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm2_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv0_weight: Tensor[(256, 128, 3, 3), float32], %resnetv10_stage3_batchnorm0_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm0_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm0_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm0_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv1_weight: Tensor[(256, 256, 3, 3), float32], %resnetv10_stage3_batchnorm1_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm1_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm1_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm1_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv3_weight: Tensor[(256, 256, 3, 3), float32], %resnetv10_stage3_batchnorm3_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm3_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm3_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm3_running_var: Tensor[(256,), float32], %resnetv10_stage3_conv4_weight: Tensor[(256, 256, 3, 3), float32], %resnetv10_stage3_batchnorm4_gamma: Tensor[(256,), float32], %resnetv10_stage3_batchnorm4_beta: Tensor[(256,), float32], %resnetv10_stage3_batchnorm4_running_mean: Tensor[(256,), float32], %resnetv10_stage3_batchnorm4_running_var: Tensor[(256,), float32], %resnetv10_stage4_conv2_weight: Tensor[(512, 256, 1, 1), float32], %resnetv10_stage4_batchnorm2_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm2_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm2_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm2_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv0_weight: Tensor[(512, 256, 3, 3), float32], %resnetv10_stage4_batchnorm0_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm0_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm0_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm0_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv1_weight: Tensor[(512, 512, 3, 3), float32], %resnetv10_stage4_batchnorm1_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm1_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm1_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm1_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv3_weight: Tensor[(512, 512, 3, 3), float32], %resnetv10_stage4_batchnorm3_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm3_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm3_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm3_running_var: Tensor[(512,), float32], %resnetv10_stage4_conv4_weight: Tensor[(512, 512, 3, 3), float32], %resnetv10_stage4_batchnorm4_gamma: Tensor[(512,), float32], %resnetv10_stage4_batchnorm4_beta: Tensor[(512,), float32], %resnetv10_stage4_batchnorm4_running_mean: Tensor[(512,), float32], %resnetv10_stage4_batchnorm4_running_var: Tensor[(512,), float32], %resnetv10_dense0_weight: Tensor[(1000, 512), float32], %resnetv10_dense0_bias: Tensor[(1000,), float32]) -> Tensor[(1, 1000), float32] {\n",
            "  %0 = nn.conv2d(%data, %resnetv10_conv0_weight, strides=[2, 2], padding=[3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
            "  %1 = nn.batch_norm(%0, %resnetv10_batchnorm0_gamma, %resnetv10_batchnorm0_beta, %resnetv10_batchnorm0_running_mean, %resnetv10_batchnorm0_running_var) /* ty=(Tensor[(1, 64, 112, 112), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
            "  %2 = %1.0\n",
            "  %3 = nn.relu(%2) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
            "  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %5 = nn.conv2d(%4, %resnetv10_stage1_conv0_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %6 = nn.batch_norm(%5, %resnetv10_stage1_batchnorm0_gamma, %resnetv10_stage1_batchnorm0_beta, %resnetv10_stage1_batchnorm0_running_mean, %resnetv10_stage1_batchnorm0_running_var) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
            "  %7 = %6.0\n",
            "  %8 = nn.relu(%7) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %9 = nn.conv2d(%8, %resnetv10_stage1_conv1_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %10 = nn.batch_norm(%9, %resnetv10_stage1_batchnorm1_gamma, %resnetv10_stage1_batchnorm1_beta, %resnetv10_stage1_batchnorm1_running_mean, %resnetv10_stage1_batchnorm1_running_var) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
            "  %11 = %10.0\n",
            "  %12 = add(%4, %11) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %13 = nn.relu(%12) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %14 = nn.conv2d(%13, %resnetv10_stage1_conv2_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %15 = nn.batch_norm(%14, %resnetv10_stage1_batchnorm2_gamma, %resnetv10_stage1_batchnorm2_beta, %resnetv10_stage1_batchnorm2_running_mean, %resnetv10_stage1_batchnorm2_running_var) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
            "  %16 = %15.0\n",
            "  %17 = nn.relu(%16) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %18 = nn.conv2d(%17, %resnetv10_stage1_conv3_weight, padding=[1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %19 = nn.batch_norm(%18, %resnetv10_stage1_batchnorm3_gamma, %resnetv10_stage1_batchnorm3_beta, %resnetv10_stage1_batchnorm3_running_mean, %resnetv10_stage1_batchnorm3_running_var) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64,), float32], Tensor[(64,), float32]) */\n",
            "  %20 = %19.0\n",
            "  %21 = add(%13, %20) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %22 = nn.relu(%21) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
            "  %23 = nn.conv2d(%22, %resnetv10_stage2_conv2_weight, strides=[2, 2], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %24 = nn.batch_norm(%23, %resnetv10_stage2_batchnorm2_gamma, %resnetv10_stage2_batchnorm2_beta, %resnetv10_stage2_batchnorm2_running_mean, %resnetv10_stage2_batchnorm2_running_var) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
            "  %25 = %24.0\n",
            "  %26 = nn.conv2d(%22, %resnetv10_stage2_conv0_weight, strides=[2, 2], padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %27 = nn.batch_norm(%26, %resnetv10_stage2_batchnorm0_gamma, %resnetv10_stage2_batchnorm0_beta, %resnetv10_stage2_batchnorm0_running_mean, %resnetv10_stage2_batchnorm0_running_var) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
            "  %28 = %27.0\n",
            "  %29 = nn.relu(%28) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %30 = nn.conv2d(%29, %resnetv10_stage2_conv1_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %31 = nn.batch_norm(%30, %resnetv10_stage2_batchnorm1_gamma, %resnetv10_stage2_batchnorm1_beta, %resnetv10_stage2_batchnorm1_running_mean, %resnetv10_stage2_batchnorm1_running_var) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
            "  %32 = %31.0\n",
            "  %33 = add(%25, %32) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %34 = nn.relu(%33) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %35 = nn.conv2d(%34, %resnetv10_stage2_conv3_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %36 = nn.batch_norm(%35, %resnetv10_stage2_batchnorm3_gamma, %resnetv10_stage2_batchnorm3_beta, %resnetv10_stage2_batchnorm3_running_mean, %resnetv10_stage2_batchnorm3_running_var) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
            "  %37 = %36.0\n",
            "  %38 = nn.relu(%37) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %39 = nn.conv2d(%38, %resnetv10_stage2_conv4_weight, padding=[1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %40 = nn.batch_norm(%39, %resnetv10_stage2_batchnorm4_gamma, %resnetv10_stage2_batchnorm4_beta, %resnetv10_stage2_batchnorm4_running_mean, %resnetv10_stage2_batchnorm4_running_var) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128,), float32], Tensor[(128,), float32]) */\n",
            "  %41 = %40.0\n",
            "  %42 = add(%34, %41) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %43 = nn.relu(%42) /* ty=Tensor[(1, 128, 28, 28), float32] */\n",
            "  %44 = nn.conv2d(%43, %resnetv10_stage3_conv2_weight, strides=[2, 2], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %45 = nn.batch_norm(%44, %resnetv10_stage3_batchnorm2_gamma, %resnetv10_stage3_batchnorm2_beta, %resnetv10_stage3_batchnorm2_running_mean, %resnetv10_stage3_batchnorm2_running_var) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
            "  %46 = %45.0\n",
            "  %47 = nn.conv2d(%43, %resnetv10_stage3_conv0_weight, strides=[2, 2], padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %48 = nn.batch_norm(%47, %resnetv10_stage3_batchnorm0_gamma, %resnetv10_stage3_batchnorm0_beta, %resnetv10_stage3_batchnorm0_running_mean, %resnetv10_stage3_batchnorm0_running_var) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
            "  %49 = %48.0\n",
            "  %50 = nn.relu(%49) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %51 = nn.conv2d(%50, %resnetv10_stage3_conv1_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %52 = nn.batch_norm(%51, %resnetv10_stage3_batchnorm1_gamma, %resnetv10_stage3_batchnorm1_beta, %resnetv10_stage3_batchnorm1_running_mean, %resnetv10_stage3_batchnorm1_running_var) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
            "  %53 = %52.0\n",
            "  %54 = add(%46, %53) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %55 = nn.relu(%54) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %56 = nn.conv2d(%55, %resnetv10_stage3_conv3_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %57 = nn.batch_norm(%56, %resnetv10_stage3_batchnorm3_gamma, %resnetv10_stage3_batchnorm3_beta, %resnetv10_stage3_batchnorm3_running_mean, %resnetv10_stage3_batchnorm3_running_var) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
            "  %58 = %57.0\n",
            "  %59 = nn.relu(%58) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %60 = nn.conv2d(%59, %resnetv10_stage3_conv4_weight, padding=[1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %61 = nn.batch_norm(%60, %resnetv10_stage3_batchnorm4_gamma, %resnetv10_stage3_batchnorm4_beta, %resnetv10_stage3_batchnorm4_running_mean, %resnetv10_stage3_batchnorm4_running_var) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256,), float32], Tensor[(256,), float32]) */\n",
            "  %62 = %61.0\n",
            "  %63 = add(%55, %62) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %64 = nn.relu(%63) /* ty=Tensor[(1, 256, 14, 14), float32] */\n",
            "  %65 = nn.conv2d(%64, %resnetv10_stage4_conv2_weight, strides=[2, 2], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %66 = nn.batch_norm(%65, %resnetv10_stage4_batchnorm2_gamma, %resnetv10_stage4_batchnorm2_beta, %resnetv10_stage4_batchnorm2_running_mean, %resnetv10_stage4_batchnorm2_running_var) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
            "  %67 = %66.0\n",
            "  %68 = nn.conv2d(%64, %resnetv10_stage4_conv0_weight, strides=[2, 2], padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %69 = nn.batch_norm(%68, %resnetv10_stage4_batchnorm0_gamma, %resnetv10_stage4_batchnorm0_beta, %resnetv10_stage4_batchnorm0_running_mean, %resnetv10_stage4_batchnorm0_running_var) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
            "  %70 = %69.0\n",
            "  %71 = nn.relu(%70) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %72 = nn.conv2d(%71, %resnetv10_stage4_conv1_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %73 = nn.batch_norm(%72, %resnetv10_stage4_batchnorm1_gamma, %resnetv10_stage4_batchnorm1_beta, %resnetv10_stage4_batchnorm1_running_mean, %resnetv10_stage4_batchnorm1_running_var) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
            "  %74 = %73.0\n",
            "  %75 = add(%67, %74) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %76 = nn.relu(%75) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %77 = nn.conv2d(%76, %resnetv10_stage4_conv3_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %78 = nn.batch_norm(%77, %resnetv10_stage4_batchnorm3_gamma, %resnetv10_stage4_batchnorm3_beta, %resnetv10_stage4_batchnorm3_running_mean, %resnetv10_stage4_batchnorm3_running_var) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
            "  %79 = %78.0\n",
            "  %80 = nn.relu(%79) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %81 = nn.conv2d(%80, %resnetv10_stage4_conv4_weight, padding=[1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %82 = nn.batch_norm(%81, %resnetv10_stage4_batchnorm4_gamma, %resnetv10_stage4_batchnorm4_beta, %resnetv10_stage4_batchnorm4_running_mean, %resnetv10_stage4_batchnorm4_running_var) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512,), float32], Tensor[(512,), float32]) */\n",
            "  %83 = %82.0\n",
            "  %84 = add(%76, %83) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %85 = nn.relu(%84) /* ty=Tensor[(1, 512, 7, 7), float32] */\n",
            "  %86 = nn.global_avg_pool2d(%85) /* ty=Tensor[(1, 512, 1, 1), float32] */\n",
            "  %87 = nn.batch_flatten(%86) /* ty=Tensor[(1, 512), float32] */\n",
            "  %88 = nn.dense(%87, %resnetv10_dense0_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */\n",
            "  nn.bias_add(%88, %resnetv10_dense0_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */\n",
            "}\n",
            "\n",
            "['resnetv10_conv0_weight',\n",
            " 'resnetv10_batchnorm0_gamma',\n",
            " 'resnetv10_batchnorm0_beta',\n",
            " 'resnetv10_batchnorm0_running_mean',\n",
            " 'resnetv10_batchnorm0_running_var',\n",
            " 'resnetv10_stage1_conv0_weight',\n",
            " 'resnetv10_stage1_batchnorm0_gamma',\n",
            " 'resnetv10_stage1_batchnorm0_beta',\n",
            " 'resnetv10_stage1_batchnorm0_running_mean',\n",
            " 'resnetv10_stage1_batchnorm0_running_var',\n",
            " 'resnetv10_stage1_conv1_weight',\n",
            " 'resnetv10_stage1_batchnorm1_gamma',\n",
            " 'resnetv10_stage1_batchnorm1_beta',\n",
            " 'resnetv10_stage1_batchnorm1_running_mean',\n",
            " 'resnetv10_stage1_batchnorm1_running_var',\n",
            " 'resnetv10_stage1_conv2_weight',\n",
            " 'resnetv10_stage1_batchnorm2_gamma',\n",
            " 'resnetv10_stage1_batchnorm2_beta',\n",
            " 'resnetv10_stage1_batchnorm2_running_mean',\n",
            " 'resnetv10_stage1_batchnorm2_running_var',\n",
            " 'resnetv10_stage1_conv3_weight',\n",
            " 'resnetv10_stage1_batchnorm3_gamma',\n",
            " 'resnetv10_stage1_batchnorm3_beta',\n",
            " 'resnetv10_stage1_batchnorm3_running_mean',\n",
            " 'resnetv10_stage1_batchnorm3_running_var',\n",
            " 'resnetv10_stage2_conv0_weight',\n",
            " 'resnetv10_stage2_batchnorm0_gamma',\n",
            " 'resnetv10_stage2_batchnorm0_beta',\n",
            " 'resnetv10_stage2_batchnorm0_running_mean',\n",
            " 'resnetv10_stage2_batchnorm0_running_var',\n",
            " 'resnetv10_stage2_conv1_weight',\n",
            " 'resnetv10_stage2_batchnorm1_gamma',\n",
            " 'resnetv10_stage2_batchnorm1_beta',\n",
            " 'resnetv10_stage2_batchnorm1_running_mean',\n",
            " 'resnetv10_stage2_batchnorm1_running_var',\n",
            " 'resnetv10_stage2_conv2_weight',\n",
            " 'resnetv10_stage2_batchnorm2_gamma',\n",
            " 'resnetv10_stage2_batchnorm2_beta',\n",
            " 'resnetv10_stage2_batchnorm2_running_mean',\n",
            " 'resnetv10_stage2_batchnorm2_running_var',\n",
            " 'resnetv10_stage2_conv3_weight',\n",
            " 'resnetv10_stage2_batchnorm3_gamma',\n",
            " 'resnetv10_stage2_batchnorm3_beta',\n",
            " 'resnetv10_stage2_batchnorm3_running_mean',\n",
            " 'resnetv10_stage2_batchnorm3_running_var',\n",
            " 'resnetv10_stage2_conv4_weight',\n",
            " 'resnetv10_stage2_batchnorm4_gamma',\n",
            " 'resnetv10_stage2_batchnorm4_beta',\n",
            " 'resnetv10_stage2_batchnorm4_running_mean',\n",
            " 'resnetv10_stage2_batchnorm4_running_var',\n",
            " 'resnetv10_stage3_conv0_weight',\n",
            " 'resnetv10_stage3_batchnorm0_gamma',\n",
            " 'resnetv10_stage3_batchnorm0_beta',\n",
            " 'resnetv10_stage3_batchnorm0_running_mean',\n",
            " 'resnetv10_stage3_batchnorm0_running_var',\n",
            " 'resnetv10_stage3_conv1_weight',\n",
            " 'resnetv10_stage3_batchnorm1_gamma',\n",
            " 'resnetv10_stage3_batchnorm1_beta',\n",
            " 'resnetv10_stage3_batchnorm1_running_mean',\n",
            " 'resnetv10_stage3_batchnorm1_running_var',\n",
            " 'resnetv10_stage3_conv2_weight',\n",
            " 'resnetv10_stage3_batchnorm2_gamma',\n",
            " 'resnetv10_stage3_batchnorm2_beta',\n",
            " 'resnetv10_stage3_batchnorm2_running_mean',\n",
            " 'resnetv10_stage3_batchnorm2_running_var',\n",
            " 'resnetv10_stage3_conv3_weight',\n",
            " 'resnetv10_stage3_batchnorm3_gamma',\n",
            " 'resnetv10_stage3_batchnorm3_beta',\n",
            " 'resnetv10_stage3_batchnorm3_running_mean',\n",
            " 'resnetv10_stage3_batchnorm3_running_var',\n",
            " 'resnetv10_stage3_conv4_weight',\n",
            " 'resnetv10_stage3_batchnorm4_gamma',\n",
            " 'resnetv10_stage3_batchnorm4_beta',\n",
            " 'resnetv10_stage3_batchnorm4_running_mean',\n",
            " 'resnetv10_stage3_batchnorm4_running_var',\n",
            " 'resnetv10_stage4_conv0_weight',\n",
            " 'resnetv10_stage4_batchnorm0_gamma',\n",
            " 'resnetv10_stage4_batchnorm0_beta',\n",
            " 'resnetv10_stage4_batchnorm0_running_mean',\n",
            " 'resnetv10_stage4_batchnorm0_running_var',\n",
            " 'resnetv10_stage4_conv1_weight',\n",
            " 'resnetv10_stage4_batchnorm1_gamma',\n",
            " 'resnetv10_stage4_batchnorm1_beta',\n",
            " 'resnetv10_stage4_batchnorm1_running_mean',\n",
            " 'resnetv10_stage4_batchnorm1_running_var',\n",
            " 'resnetv10_stage4_conv2_weight',\n",
            " 'resnetv10_stage4_batchnorm2_gamma',\n",
            " 'resnetv10_stage4_batchnorm2_beta',\n",
            " 'resnetv10_stage4_batchnorm2_running_mean',\n",
            " 'resnetv10_stage4_batchnorm2_running_var',\n",
            " 'resnetv10_stage4_conv3_weight',\n",
            " 'resnetv10_stage4_batchnorm3_gamma',\n",
            " 'resnetv10_stage4_batchnorm3_beta',\n",
            " 'resnetv10_stage4_batchnorm3_running_mean',\n",
            " 'resnetv10_stage4_batchnorm3_running_var',\n",
            " 'resnetv10_stage4_conv4_weight',\n",
            " 'resnetv10_stage4_batchnorm4_gamma',\n",
            " 'resnetv10_stage4_batchnorm4_beta',\n",
            " 'resnetv10_stage4_batchnorm4_running_mean',\n",
            " 'resnetv10_stage4_batchnorm4_running_var',\n",
            " 'resnetv10_dense0_weight',\n",
            " 'resnetv10_dense0_bias']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIGStzjDx8bx",
        "colab_type": "text"
      },
      "source": [
        "With that, we can create a μTVM session, build a graph runtime module, then run the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAEJ7ceR7aF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "985cad34-76a9-4f21-b5aa-d473243351b1"
      },
      "source": [
        "with micro.Session('host', '') as sess:\n",
        "  module, params = sess.build(resnet, params=params)\n",
        "  module.set_input(**params)\n",
        "  # Execute with `image` as the input.\n",
        "  module.run(data=image)\n",
        "  print(get_prediction(module))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 3, 224, 224, 'float32'), (64, 3, 7, 7, 'float32'), (2, 2), (3, 3), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 64, 56, 56, 'float32'), (64, 64, 3, 3, 'float32'), (1, 1), (1, 1), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 64, 56, 56, 'float32'), (128, 64, 1, 1, 'float32'), (2, 2), (0, 0), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 64, 56, 56, 'float32'), (128, 64, 3, 3, 'float32'), (2, 2), (1, 1), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 128, 28, 28, 'float32'), (128, 128, 3, 3, 'float32'), (1, 1), (1, 1), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 128, 28, 28, 'float32'), (256, 128, 1, 1, 'float32'), (2, 2), (0, 0), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 128, 28, 28, 'float32'), (256, 128, 3, 3, 'float32'), (2, 2), (1, 1), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 256, 14, 14, 'float32'), (256, 256, 3, 3, 'float32'), (1, 1), (1, 1), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 256, 14, 14, 'float32'), (512, 256, 1, 1, 'float32'), (2, 2), (0, 0), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 256, 14, 14, 'float32'), (512, 256, 3, 3, 'float32'), (2, 2), (1, 1), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('conv2d', (1, 512, 7, 7, 'float32'), (512, 512, 3, 3, 'float32'), (1, 1), (1, 1), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
            "WARNING:autotvm:Cannot find config for target=c, workload=('dense', (1, 512, 'float32'), (1000, 512, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tiger cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8dibeuWH8Nt",
        "colab_type": "text"
      },
      "source": [
        "# Homework: RISC-V\n",
        "\n",
        "To use RISC-V as a target device, there are some extra steps that can't be done within this notebook.\n",
        "\n",
        "First, you will need to download and compile [TVM](https://github.com/dmlc/tvm) on your own machine.\n",
        "\n",
        "Next, you will need [Spike](https://github.com/riscv/riscv-isa-sim) (a RISC-V ISA simulator) and [OpenOCD](https://github.com/ntfreak/openocd) (provides a high-level debugging interface to compatible devices).\n",
        "\n",
        "TODO: Flesh out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azzGhNPY2QIJ",
        "colab_type": "text"
      },
      "source": [
        "# Additional Resources\n",
        "\n",
        "For more details on how μTVM is implemented, you can look into the following pull requests on the [TVM GitHub](https://github.com/dmlc/tvm) repository: \n",
        "\n",
        "- [C code generation backend](https://github.com/dmlc/tvm/pull/2161)\n",
        "- [μTVM RFC](https://github.com/dmlc/tvm/issues/2563) (somewhat outdated)\n",
        "- [μTVM on host-emulated device](https://github.com/dmlc/tvm/pull/3227)\n",
        "- μTVM on RISC-V: Will be upstreamed in a few weeks!\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}